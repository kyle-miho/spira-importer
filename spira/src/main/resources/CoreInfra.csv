Component,Component,Test Case,TC Identifier,Test Type,Estimated Duration (min),Priority,Pass/Fail,LPS Ticket,Tester,Date,Test Name,Test Steps
Bundle Blacklist,Bundle Blacklist,,,,,,,,,,,
Bundle Blacklist,,Test Group 1 - Blacklisting Modules,,,,,,,,,,
Bundle Blacklist,,Add LPKGs module to Blacklist through System Setting (UI),1a,Functional,,5,,,,,BundleBlacklist#BlacklistModuleLPKG,"1. Start up a clean Liferay portal bundle (You may want to generate lpkg for the module you want to blacklist if you are not using the release bundle.)
2. Go to [Liferay_home]/osgi/marketplace
3. Find  the LPKG that will be added to the blacklist 
4. Get “App title"" from the name of the the LPKG file  
5. Go to Control Panel > Configuration > System Settings > Module Container > Bundle Blacklist
6. Enter App title into blacklist symbolic name field
7. Save
8. Verify the module is blacklisted in the console 
9. Assert module is STOPPED in the console"
Bundle Blacklist,,Add module JARs to Blacklist through System Setting (UI),1b,Functional,,5,,,,,BundleBlacklist#BlacklistModuleJar,"1. Start up a clean Liferay portal bundle
2. Go to [Liferay_home]/osgi/modules 
3. Find  the module jar that will be added to the blacklist
4. Open and find Bundle-SymbolicName in bnd.bnd or MANIFEST.MF file
5. Copy the bundle symbolic name
6. Go to Control Panel > Configuration > System Settings > Module Container > Bundle Blacklist
7. Enter Bundle-SymbolicName into blacklist symbolic name field
8. Save
9. Verify the module is blacklisted in the console
10. Assert module is STOPPED in the console"
Bundle Blacklist,,Add WARs file to Blacklist through System Setting (UI),1c,Functional,,4,,,,,BundleBlacklist#BlacklistModuleWar,"1. Start up a clean Liferay portal bundle
2. Get the WAR file  that will be added to the blacklist
3. Open and find Servlet context name in liferay-plugin-package.properties file 
4. Copy the  Servlet context name
5. Go to Control Panel > Configuration > System Settings > Module Container > Bundle Blacklist
6. Enter  Servlet context name or WAR file name (minus .war) into blacklist symbolic name field if there is no servlet context name property
7. Save
8. Verify the module is blacklisted in the console
9. Assert module is STOPPED in the console"
Bundle Blacklist,,Remove module from the blacklist through System Settings (UI),1d,Functional,,5,,,,,BundleBlacklist#RemoveModuleFromBlacklist,"1. Go to  Control Panel > Configuration > System Settings > Module Container > Bundle Blacklist
2. Enter bundle symbolic name in the name field
3. Save bundle blacklist configuration
4. Verify the module is blacklisted in the console (uninstalled)
5. Go to  Control Panel > Configuration > System Settings > Module Container > Bundle Blacklist
6. Remove module from blacklist
7. Verify the module is not blacklisted in the console (reinstalled)
8. Assert module is Reinstalling bundle in the console
9. Assert module is STARTED in the console


        Note: The module(s) will be blacklisted again on future restart as this is a temporarily change"
Bundle Blacklist,,Add module to blacklist through OSGi config file at runtime,1e,Manual,,5,,,,,https://issues.liferay.com/browse/LRQA-53831,"1. Start the portal server
2. Go to [liferay_home]/osgi/configs
3. Create config file:
com.liferay.portal.bundle.blacklist.internal.BundleBlacklistConfiguration.config
4. Open the configuration file: com.liferay.portal.bundle.blacklist.internal.BundleBlacklistConfiguration.config
5. Add the bundle symbolic names of any modules that you want to blacklist
6. Save the config file
7. Verify the module is blacklisted in the console (uninstalled)
8. Assert module is STOPPED in the console"
Bundle Blacklist,,Remove module from the blacklist through OSGi config file at runtime,1f,Manual,,5,,,,,https://issues.liferay.com/browse/LRQA-53832,"1. Execute 1e
2. Remove the symbolic names of the module(s) you want to install from the blacklist config file
3. Save the configuration
4. Verify the module is not blacklisted in the console (reinstalled)
5. Assert module is Reinstalling bundle in the console
6. Assert module is STARTED in the console"
Bundle Blacklist,,Add and remove module between restarts,1g,Integration,-,4,,,,,BundleBlacklistTest#testAddToAndRemoveFromBlacklist,1. Execute 1e and 1f with the server shutdown during the adding and removing of the blacklist config file
Bundle Blacklist,,Delete configuration file from the OSGi configs folder at runtime,1h,Manual,,4,,,,,https://issues.liferay.com/browse/LRQA-53833,"1. Execute 1e
2. Delete configuration file from 1e
3. Verify the modules are not blacklisted in the console (reinstalled)
4. Assert module is Reinstalling bundle in the console
5. Assert module is STARTED in the console"
Bundle Blacklist,,Shutdown and delete configuration file from the OSGi configs folder,1i,Integration,-,4,,,,,BundleBlacklistVerifyReinstalledTest,"1. Execute 1e
2. Shutdown the liferay portal server
3. Delete configuration file from 1e
4. Restart the liferay portal server
5. Verify the modules are not blacklisted in the console (reinstalled)
6. Assert module is Reinstalling bundle in the console
7. Assert module is STARTED in the console"
Bundle Blacklist,,Export bundle blacklist config file into OSGi configs folder,1j,Manual,,4,,,,,https://issues.liferay.com/browse/LRQA-53834,"1. Execute steps 1d (1 - 4) 
2. Export: com.liferay.portal.bundle.blacklist.internal.BundleBlacklistConfiguration.config
3. Assert configuration file is exported
4. Copy into [liferay_home]/osgi/configs: com.liferay.portal.bundle.blacklist.internal.BundleBlacklistConfiguration.config
5. Verify the module is still blacklisted in the console
6. Assert module is STOPPED in the console"
Bundle Blacklist,,Reinstall all blacklisted modules,1k,Manual,,3,,,,,,"1. Execute steps 1d (1 - 4)
2. Go to Control Panel > App Manager
3. Search for “com.liferay.portal.bundle.blacklist” and uninstall
4. Assert all the blacklisted modules are reinstalled
5. Assert no console log error"
Bundle Blacklist,,Test Group 2 - Blacklisting Components,,,,,,,,,,
Bundle Blacklist,,Add component to blacklist through System Settings (UI),2a,Functional,,4,,,,,BundleBlacklist#BlacklistComponent,"1. Go to  Control Panel > Configuration > System Settings > Module Container > Component Blacklist
2. In Component Blacklist field, enter component unique name(s) to the blacklist
3. Save component blacklist configuration file
4. Verify the component is blacklisted in the console (uninstalled)
5. Assert component is STOPPED in the console"
Bundle Blacklist,,Remove component from the blacklist through System Settings (UI),2b,Manual,,3,,,,,,"2. Go to  Control Panel > Configuration > System Settings > Module Container > Component Blacklist
3. Remove component unique name from blacklist
4. Verify the component is not blacklisted in the console (installed)
5. Assert component is Reinstalling in the console
6. Assert component is STARTED in the console


Note: The component will be blacklisted again on future restart as this is a temporarily change"
Bundle Blacklist,,Add component to blacklist through OSGi configs file,2c,Manual,,4,,,,,https://issues.liferay.com/browse/LRQA-53835,"1. Start liferay portal server
2. Go to [liferay_home]/osgi/configs
3. Create configuration file
com.liferay.portal.component.blacklist.internal.ComponentBlacklistConfiguration.config
4. Open the configuration file: com.liferay.portal.component.blacklist.internal.ComponentBlacklistConfiguration.config
5. Add the component(s) symbolic names that  you want to blacklist
6. Save the configuration file
7. Verify the component is blacklisted in the console (uninstalled)
8. Assert component is STOPPED in the console"
Bundle Blacklist,,Remove component from blacklist through OSGi configs file,2d,Manual,,3,,,,,,"1. Execute 2c
2. Remove the name(s) of the component(s) you want to reinstall from the blacklist
3. Save the configuration file
4. Verify the component is not blacklisted in the console (reinstalled)
5. Assert component is Reinstalling in the console
6. Assert component is STARTED in the console"
Bundle Blacklist,,Delete component blacklist config file OSGi configs folder,2e,Manual,,3,,,,,,"1. Execute 2c
2. Delete configuration file from 2c
3. Verify the components are not blacklisted in the console (reinstalled)
4. Assert component is Reinstalling in the console
5. Assert component is STARTED in the console"
Bundle Blacklist,,Shutdown and delete component blacklist config file from OSGi configs folder,2f,Manual,,3,,,,,,"1. Execute 2c
2. Shutdown the liferay portal server
3. Delete configuration file from 2c
4. Restart the liferay portal server
5. Verify the components are not blacklisted in the console (reinstalled)
6. Assert component is Reinstalling bundle in the console
7. Assert component is STARTED in the console"
Bundle Blacklist,,Export component blacklist config file into OSGi configs folder,2g,Manual,,3,,,,,,"1. Execute 2a 
2. Export: com.liferay.portal.component.blacklist.internal.ComponentBlacklistConfiguration.config
3. Assert configuration file is exported
4. Copy into [liferay_home]/osgi/configs: com.liferay.portal.component.blacklist.internal.ComponentBlacklistConfiguration.config
5. Verify the component is still blacklisted in the console (uninstalled)
6. Assert component is STOPPED in the console

See 1a for https://issues.liferay.com/browse/LPP-31038 "
Clustering,Clustering,,,,,,,,,,,
Clustering,,Test Group 1 - Cluster Link,,,,,,,,,,
Clustering,,Portal Properties(cluster.link.enabled),1a,Functional,-,5,,,,,ClusteringLink#ClusteringLinkPortalProperties,"1. Set “cluster.link.enabled=false”
2. Start portal and wait for it is fully started
3. Assert console, NO logging like:
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-42240, cluster=liferay-channel-control, physical address=172.16.20.96:42740
-------------------------------------------------------------------
4. Set “cluster.link.enabled=true”
5. Start portal and wait for it is fully started
6. Assert console, there is logging like:
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-42240, cluster=liferay-channel-control, physical address=172.16.20.96:42740
-------------------------------------------------------------------
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-9493, cluster=liferay-channel-transport-0, physical address=172.16.20.96:50413
-------------------------------------------------------------------"
Clustering,,Portal Properties(cluster.link.channel.name),1b,Functional,-,4,,,,,ClusteringLink#ClusteringLinkPortalProperties,"1. Set “cluster.link.enabled=true”
2. Set “cluster.link.channel.name.control=test-control-channel”
3. Set “cluster.link.channel.name.transport.0=test-transport-channel”
4. Start portal and wait for it is fully started
5. Assert console, cluster name is changed to what we have set
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-42240, cluster=test-control-channel, physical address=172.16.20.96:42740
-------------------------------------------------------------------
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-9493, cluster=test-transport-channel, physical address=172.16.20.96:50413
-------------------------------------------------------------------"
Clustering,,Portal Properties(cluster.link.channel.properties),1c,Functional,-,4,,,,,ClusteringLink#ClusteringLinkPortalProperties,"1. Set “cluster.link.enabled=true”
2. Set “cluster.link.channel.properties.control=tcp.xml”
3. Set “cluster.link.channel.properties.transport.0=tcp.xml”
4. Start portal and wait for it is fully started
5. Assert console, TCP is the protocol using, search the following code, there should be two matches, one for control channel, one for transport channel
        Create a new JGroups channel with properties TCP("
Clustering,,Portal Properties(cluster.link.autodetect.address),1d,Functional,-,4,,,,,ClusteringLink#ClusteringLinkPortalProperties,"1. Set “cluster.link.enabled=true”
2. Set “cluster.link.autodetect.address=www.google.com:80”[a]
3. Start portal and wait for it is fully started
4. Assert console, the physical address used by control channel and transport channel are same, and this is an outgoing address which has access to www.google.com.
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-42240, cluster=liferay-channel-control, physical address=172.16.20.96:42740
-------------------------------------------------------------------
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-9493, cluster=liferay-channel-transport-0, physical address=172.16.20.96:50413
-------------------------------------------------------------------
5. Shutdown portal
6. Set “cluster.link.autodetect.address=localhost”
7. Restart portal and wait for it is fully started
8. Assert console, the physical address used by control channel and transport channel are same, and it is an local loopback address
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-42240, cluster=liferay-channel-control, physical address=127.0.0.1:7800
-------------------------------------------------------------------
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-9493, cluster=liferay-channel-transport-0, physical address=127.0.0.1:7801
-------------------------------------------------------------------s
9. Shutdown portal
10. Set “cluster.link.autodetect.address=”
11. Set “cluster.link.bind.addr[""cluster-link-control""]=172.16.23.242” (Note: the IP address is of another network card in the same machine; on my laptop, this is my IP address of wireless network card[b])
12. Set ”cluster.link.bind.addr[""cluster-link-udp""]=172.16.23.242”
13. Start portal
14. Assert console, the physical address used by control channel and transport channel are same, and it is the address configured
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-42240, cluster=liferay-channel-control, physical address=172.16.23.242:54652
-------------------------------------------------------------------
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-9493, cluster=liferay-channel-transport-0, physical address=172.16.23.242:54713
-------------------------------------------------------------------"
Clustering,,Topology Structure 1,1e,Manual,30,3,,,,,,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave
9. On node1, assert result
This node is master node
10. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave
11. On node2, assert result
This node is slave node
12. Shutdown node1
13. On node2, assert console, node1 left
Accepted view [liferay-Precision-5520-30711|2] (1) [liferay-Precision-5520-30711]
14. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave
15. On node2, assert result
This node is master node
16. Restart node1 and wait for it is fully started
17. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave[c]
18. On node1, assert result
This node is slave node"
Clustering,,Topology Structure 2,1f,Manual,30,3,,,,,,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave
9. On node1, assert result
This node is master node
10. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave
11. On node2, assert result
This node is slave node
12. On node1, cut off network connection
13. On node2, assert console, node1 left
Accepted view [liferay-Precision-5520-30711|2] (1) [liferay-Precision-5520-30711]
14. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave
15. On node2, assert result
This node is master node
16. On node1, reconnect network
17. On node1, assert console and find the master node address is liferay-Precision-5520-30711 which is node2.
Accepted view MergeView::[liferay-Precision-5520-30711|3] (2) [liferay-Precision-5520-30711, liferay-Precision-5520-37063], 2 subgroups: [liferay-Precision-5520-30711|2] (1) [liferay-Precision-5520-30711], [liferay-Precision-5520-37063|2] (1) [liferay-Precision-5520-37063]
18. On node2, assert console
Accepted view MergeView::[liferay-Precision-5520-30711|3] (2) [liferay-Precision-5520-30711, liferay-Precision-5520-37063], 2 subgroups: [liferay-Precision-5520-30711|2] (1) [liferay-Precision-5520-30711], [liferay-Precision-5520-37063|2] (1) [liferay-Precision-5520-37063]
19. On master node, go to Control Panel->Configuration->Server Administration->Script, Groovy Scripts/groovy-script-master-slave
20. On master node, assert result
This node is master node
21. On another node, go to Control Panel->Configuration->Server Administration->Script, Groovy Scripts/groovy-script-master-slave
22. On another node, assert result
This node is slave node"
Clustering,,Invoke Methods 1 (Invoke methods in portal kernel),1g,Manual,35,3,,,,,,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Disable automatic browser launching by setting: browser.launcher.url=
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, visit home page
9. On node2, assert console and find port of node1 is updated to 8080
Updated cluster node {bindInetAddress=/172.16.20.96, clusterNodeId=1c9a3276-5c88-1130-55df-3539a13f2ca3, portalInetSocketAddress=/127.0.0.1:8080, portalProtocol=http}
10. On node2, visit home page
11. On node1, assert console and find port of node2 is updated to 8081
Updated cluster node {bindInetAddress=/172.16.20.96, clusterNodeId=0cb6a181-14b4-322b-d4c6-f15b08437cd5, portalInetSocketAddress=/127.0.0.1:8081, portalProtocol=http}
12. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-invoke-method
13. On node1, assert result 
Result of invoke-method-portal is :8081
14. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-invoke-method
15. On node2, assert result
Result of invoke-method-portal is :8080
16. On both nodes, deploy and start module: com.liferay.cluster.test.module.jar
17. On node1, add empty file named “com.liferay.cluster.test.module.configuration.ClusterTestConfiguration.cfg” to “liferay-bundle/osgi/configs”
18. On node1, add the following to “com.liferay.cluster.test.module.configuration.ClusterTestConfiguration.cfg”:
        clusterTestCommand=invoke-method-portal
19. On node1, assert console
        Result of invoke-method-portal is :8081
20. On node2, assert console
        Result of invoke-method-portal is :8080"
Clustering,,Invoke Methods 2 (Invoke methods in modules),1h,Manual,35,3,,,,,,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Disable automatic browser launching by setting: browser.launcher.url=
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, visit home page
9. On node2, assert console and find port of node1 is updated to 8080
Updated cluster node {bindInetAddress=/172.16.20.96, clusterNodeId=1c9a3276-5c88-1130-55df-3539a13f2ca3, portalInetSocketAddress=/127.0.0.1:8080, portalProtocol=http}
10. On node2, visit home page
11. On node1, assert console and find port of node2 is updated to 8081
Updated cluster node {bindInetAddress=/172.16.20.96, clusterNodeId=0cb6a181-14b4-322b-d4c6-f15b08437cd5, portalInetSocketAddress=/127.0.0.1:8081, portalProtocol=http}
12. On both nodes, deploy and start module: com.liferay.cluster.test.module.jar
13. On node1, add empty file named “com.liferay.cluster.test.module.configuration.ClusterTestConfiguration.cfg” to “liferay-bundle/osgi/configs”
14. Add the following to “com.liferay.cluster.test.module.configuration.ClusterTestConfiguration.cfg”:
        clusterTestCommand=invoke-method-module
15. On node1, assert console
Result of invoke-method-module is :8081
16. On node2, assert console
        Result of invoke-method-module is :8080

"
Clustering,,Invoke Methods 3 (Invoke methods of portal kernel on master),1i,Manual,35,3,,,,,,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Disable automatic browser launching by setting: browser.launcher.url=
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, visit home page
9. On node2, assert console and find port of node1 is updated to 8080
Updated cluster node {bindInetAddress=/172.16.20.96, clusterNodeId=1c9a3276-5c88-1130-55df-3539a13f2ca3, portalInetSocketAddress=/127.0.0.1:8080, portalProtocol=http}
10. On node2, visit home page
11. On node1, assert console and find port of node2 is updated to 8081
Updated cluster node {bindInetAddress=/172.16.20.96, clusterNodeId=0cb6a181-14b4-322b-d4c6-f15b08437cd5, portalInetSocketAddress=/127.0.0.1:8081, portalProtocol=http}
12. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-invoke-method-on-master
13. On node1, assert result 
Result of invoke-method-portal-on-master is :8080
14. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-invoke-method-on-master
15. On node2, assert result
Result of invoke-method-portal-on-master is :8080
16. On both nodes, deploy and start module: com.liferay.cluster.test.module.jar
17. On node1, add empty file named “com.liferay.cluster.test.module.configuration.ClusterTestConfiguration.cfg” to “liferay-bundle/osgi/configs”
18. On node1, add the following to “com.liferay.cluster.test.module.configuration.ClusterTestConfiguration.cfg”:
        clusterTestCommand=invoke-method-portal-on-master
19. On node1, assert console
        Result of invoke-method-portal-on-master is :8080
20. On node2, assert console
        Result of invoke-method-portal-on-master is :8080"
Clustering,,Invoke Methods 4 (Invoke methods of modules on master),1j,Manual,30,3,,,,,,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Disable automatic browser launching by setting: browser.launcher.url=
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, visit home page
9. On node2, assert console and find port of node1 is updated to 8080
Updated cluster node {bindInetAddress=/172.16.20.96, clusterNodeId=1c9a3276-5c88-1130-55df-3539a13f2ca3, portalInetSocketAddress=/127.0.0.1:8080, portalProtocol=http}
10. On node2, visit home page
11. On node1, assert console and find port of node2 is updated to 8081
Updated cluster node {bindInetAddress=/172.16.20.96, clusterNodeId=0cb6a181-14b4-322b-d4c6-f15b08437cd5, portalInetSocketAddress=/127.0.0.1:8081, portalProtocol=http}
12. On both nodes, deploy and start module: com.liferay.cluster.test.module.jar
13. On node1, add empty file named “com.liferay.cluster.test.module.configuration.ClusterTestConfiguration.cfg” to “liferay-bundle/osgi/configs”
14. On node1, add the following to “com.liferay.cluster.test.module.configuration.ClusterTestConfiguration.cfg”:
        clusterTestCommand=invoke-method-module-on-master
15. On node1, assert console
Result of invoke-method-module-on-master is :8080
16. On node2, assert console
        Result of invoke-method-module-on-master is :8080"
Clustering,,Test Group 2 - Cluster + Cache Replication,,,,,,,,,,
Clustering,,Replicate by copy,2a,Manual,35,3,,,,,https://issues.liferay.com/browse/LRQA-42939,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Configure “test.cache” to use replicate by copy by setting:
                ehcache.replicator.properties.test.cache=replicatePutsViaCopy=true
4. Enable debugging for “test.cache” by copying file log4j/com.liferay.portal.cache.ehcache.impl-log4j-ext.xml to liferay-bundle/osgi/log4j
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
9. On node1, assert result
        test.cache is empty
10. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
11. On node2, assert result
        test.cache is empty
12. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-put
13. On node1, assert console
        Put test.key into test.cache
14. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
15. On node1, assert result
        test.key=test.value
16. On node2, assert console
        Put test.key into test.cache
17. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
18. On node2, assert result
        test.key=test.value
19. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-remove
20. On node1, assert console
Removed test.key from test.cache
21. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
22. On node1, assert result
        test.cache is empty
23. On node2, assert console
Removed test.key from test.cache
24. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
25. On node2, assert result
        test.cache is empty"
Clustering,,Replicate by remove,2b,Manual,35,3,,,,,https://issues.liferay.com/browse/LRQA-42944,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Configure “test.cache” to use replicate by copy by setting:
                ehcache.replicator.properties.test.cache=replicatePutsViaCopy=false
4. Enable debugging for “test.cache” by copying file log4j/com.liferay.portal.cache.ehcache.impl-log4j-ext.xml to liferay-bundle/osgi/log4j
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
9. On node1, assert result
        test.cache is empty
10. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
11. On node2, assert result
        test.cache is empty
12. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-put
13. On node1, assert console
        Put test.key into test.cache
14. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
15. On node1, assert result
        test.key=test.value
16. On node2, assert console
        Removed test.key from test.cache
17. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
18. On node2, assert result
        test.cache is empty
19. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-remove-all
20. On node1, assert console
Cleared test.cache
21. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
22. On node1, assert result
        test.cache is empty
23. On node2, assert console
Cleared test.cache
24. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
25. On node2, assert result
        test.cache is empty"
Clustering,,Do not replicate put,2c,Manual,35,3,,,,,,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Configure “test.cache” to use replicate by copy by setting:
                ehcache.replicator.properties.test.cache=replicatePuts=false
4. Enable debugging for “test.cache” by copying file log4j/com.liferay.portal.cache.ehcache.impl-log4j-ext.xml to liferay-bundle/osgi/log4j
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
9. On node1, assert result
        test.cache is empty
10. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
11. On node2, assert result
        test.cache is empty
12. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-put
13. On node1, assert console
        Put test.key into test.cache
14. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
15. On node1, assert result
        test.key=test.value
16. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
17. On node2, assert result
        test.cache is empty
18. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-update
19. On node2, assert console
        Put test.key into test.cache
20. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
21. On node2, assert result
        test.key=test.value.update
22. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
23. On node1, assert result
        test.key=test.value
24. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-remove
25. On node1, assert console
Removed test.key from test.cache
26. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
27. On node1, assert result
        test.cache is empty
28. On node2, assert console
Removed test.key from test.cache
29. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
30. On node2, assert result
        test.cache is empty"
Clustering,,Test Group 3 - REMOVED,,,,,,,,,,
Clustering,,Test Group 4 - Cluster + Scheduler,,,,,,,,,,
Clustering,,Persistent jobs,4a,Manual,30,4,,,,,https://issues.liferay.com/browse/LRQA-53828,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-scheduler-persistent-1
9. On node1, assert result
        Persistent job 1 is added
10. Assert console of node1 and node2, job 1 is running on one node
        Persistent job 1 is triggered at 1502230976061
11. On the node which is NOT running the job 1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-scheduler-persistent-2
12. On the node which is NOT running job 1, assert result
        Persistent job 2 is added
13. Assert console of node1 and node2, job 2 is running on one node
        Persistent job 2 is triggered at 1502230986061
14. Shutdown one of the nodes which are executing jobs
15. On another node, assert console, two jobs are running
Persistent job 1 is triggered at 1502231775812
Persistent job 2 is triggered at 1502231776812
16. Shutdown another node
17. Start both nodes one by one
18. Assert console of node1 and node2, each job is running on either node1 or node2(Two jobs may be running in same node, or running in different nodes)
        Persistent job 1 is triggered at 1502231846797
Persistent job 2 is triggered at 1502231856797"
Clustering,,Memory clustered jobs 1,4b,Manual,30,4,,,,,https://issues.liferay.com/browse/LRQA-42947,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-scheduler-memory-clustered-1
9. On node1, assert result
        Memory clustered job 1 is added
10. On node1, assert console, job 1 is running
        Memory clustered job 1 is triggered at 1502232826800
11. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-scheduler-memory-clustered-2
12. On node2, assert result
        Memory clustered job 2 is added
13. On node1, assert console, job 2 is running
        Memory clustered job 2 is triggered at 1502232836800
14. On node2, assert console, NO job is running
15. Shutdown node1
16. On node2, assert console, two jobs are running
        Memory clustered job 1 is triggered at 1502232846800
        Memory clustered job 2 is triggered at 1502232856800
17. Shutdown node2
18. Restart node1
19. On node1, assert console, NO job is running"
Clustering,,Memory clustered jobs 2,4c,Manual,30,3,,,,,Not automatable,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-scheduler-memory-clustered-1
9. On node1, assert result
        Memory clustered job 1 is added
10. On node1, assert console, job 1 is running
        Memory clustered job 1 is triggered at 1502232826800
11. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-scheduler-memory-clustered-2
12. On node2, assert result
        Memory clustered job 2 is added
13. On node1, assert console, job 2 is running
        Memory clustered job 2 is triggered at 1502232836800
14. On node2, assert console, NO job is running
15. On node1, cut off network connection
16. On node2, assert console, node1 left
Accepted view [liferay-Precision-5520-30711|2] (1) [liferay-Precision-5520-30711]
17. On node2, assert console, two jobs are running
        Memory clustered job 1 is triggered at 1502232846800
        Memory clustered job 2 is triggered at 1502232856800
18. On node1, reconnect network
19. On node1, assert console and find the master node address is liferay-Precision-5520-30711 which is node2.
Accepted view MergeView::[liferay-Precision-5520-30711|3] (2) [liferay-Precision-5520-30711, liferay-Precision-5520-37063], 2 subgroups: [liferay-Precision-5520-30711|2] (1) [liferay-Precision-5520-30711], [liferay-Precision-5520-37063|2] (1) [liferay-Precision-5520-37063]
20. On node2, assert console
Accepted view MergeView::[liferay-Precision-5520-30711|3] (2) [liferay-Precision-5520-30711, liferay-Precision-5520-37063], 2 subgroups: [liferay-Precision-5520-30711|2] (1) [liferay-Precision-5520-30711], [liferay-Precision-5520-37063|2] (1) [liferay-Precision-5520-37063]
21. On master node (use Groovy Scripts/groovy-script-master-slave to determine which node is master), assert console, two jobs are running
        Memory clustered job 1 is triggered at 1502232846800
        Memory clustered job 2 is triggered at 1502232856800
22. On another node, assert console, NO job is running"
Clustering,,Memory jobs,4d,Manual,30,3,,,,,,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-scheduler-memory-1
9. On node1, assert result
        Memory job 1 is added
10. On node1, assert console, job 1 is running
        Memory job 1 is triggered at 1502232826800
11. On node2, assert console, job 1 is running
        Memory job 1 is triggered at 1502232826800
12. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-scheduler-memory-2
13. On node2, assert result
        Memory job 2 is added
14. On node1, assert console, job 2 is running
        Memory job 2 is triggered at 1502232836800
15. On node2, assert console, job 2 is running
        Memory job 2 is triggered at 1502232836800
16. Shutdown node1
17. On node2, assert console, two jobs are running
        Memory job 1 is triggered at 1502232846800
        Memory job 2 is triggered at 1502232856800
18. Shutdown node2
19. Restart node1
20. No node1, asset console, NO job is running"
Clustering,,Test Group 5 - Cluster + Live Users,,,,,,,,,,
Clustering,,Live Users,5a,Functional,-,4,,,,,Clustering#ValidateLiveUsers,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Enable live users by setting: live.users.enabled=true
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, log in as “test”
9. On node1, go to “Control Panel->Users->Monitoring”
10. On node1, assert there is one session entry on page
11. On node2, log in as “test”
12. On node2, go to “Control Panel->Users->Monitoring”
13. On node2, assert there are two session entries on page
14. On node1, refresh page “Control Panel->Users->Monitoring”
15. On node1, assert there are two session entries
16. On node2, log out
17. On node1, refresh page “Control Panel->Users->Monitoring”
18. On node1, assert there is one session entry"
Clustering,,Test Group 6 - Cluster + Search,,,,,,,,,,
Clustering,,INCOMPLETE Search,6,Manual,,2,,,,,,Delay to next round
Clustering,,Test Group 7 - Cluster + OSGi Bundle Configuration,,,,,,,,,,
Clustering,,INCOMPLETE OSGi Bundle Configuration,7,Manual,,2,,,,,,Delay to next round
Clustering,,Test Group 8 - Cluster + Missing Plugins,,,,,,,,,,
Clustering,,Cache replication by copy,8a,Functional,-,4,,,,,ClusteringMissingPlugins#CacheReplicationbyCopy,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Configure “test.cache” to use replicate by copy by setting:
                ehcache.replicator.properties.test.cache=replicatePutsViaCopy=true
4. Enable debugging for “test.cache” by copying file log4j/com.liferay.portal.cache.ehcache.impl-log4j-ext.xml to liferay-bundle/osgi/log4j
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, deploy and start module: com.liferay.cluster.test.module.jar
   1. You can hot deploy to the ogsi/modules folder
9. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-put-modules
10. On node1, assert console
        Put test.key into test.cache
11. On node2, assert console, no exception comes up
12. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
13. On node2, assert result
        test.cache is empty
14. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-remove
15. On node1, assert console
        Removed test.key from test.cache
16. On node2, assert console
        Removed test.key from test.cache
17. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-put-modules
18. On node1, assert console
        Put test.key into test.cache
19. On node2, assert console
        Unable to deserialize object
java.lang.ClassNotFoundException: com.liferay.cluster.test.module.internel.ClusterTestClass
20. On node2, deploy and start module: com.liferay.cluster.test.module.jar
21. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-get
22. On node2, assert result
        test.cache is empty
23. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-remove
24. On node1, assert console
        Removed test.key from test.cache
25. On node2, assert console
        Removed test.key from test.cache
26. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-portal-cache-put-modules
27. On node1, assert console
        Put test.key into test.cache
28. On node2, assert console
        Put test.key into test.cache"
Clustering,,Scheduler 1,8b,Functional,-,4,,,,,ClusteringMissingPlugins#ScheduleJobOnClusterNode1,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Enable debugging for scheduler job by copying file log4j/com.liferay.cluster.test.module-log4j-ext.xml to liferay-bundle/osgi/log4j
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, deploy and start module: com.liferay.cluster.test.module.jar
9. On node1, assert console, job is running
Memory clustered job from modules is triggered at 1502232826800
10. Shutdown node1
11. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave
12. On node2, assert result
This node is master node
13. On node2, assert console, job is NOT running
14. On node2, deploy and start module: com.liferay.cluster.test.module.jar
15. On node2, assert console
Scheduler job com.liferay.cluster.test.module.internel.SchedulerTestMessageListener.com.liferay.cluster.test.module.internel.SchedulerTestMessageListener already exists
16. On node2, assert console, job is running
Memory clustered job from modules is triggered at 1502232826800"
Clustering,,Scheduler 2,8c,Functional,-,4,,,,,ClusteringMissingPlugins#ScheduleJobOnAllClusterNodes,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Enable debugging for scheduler job by copying file log4j/com.liferay.cluster.test.module-log4j-ext.xml to liferay-bundle/osgi/log4j
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node1, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave
9. On node1, assert result
This node is master node
10. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave
11. On node2, assert result
This node is slave node
12. On node2, deploy and start module: com.liferay.cluster.test.module.jar
13. On node1, assert console, job is NOT running
14. On node2, assert console, job is NOT running
15. On node1, deploy and start module: com.liferay.cluster.test.module.jar
16. On node1, assert console, job is running
Memory clustered job from modules is triggered at 1502232826800
17. Shutdown node1
18. On node2, go to Control Panel->Configuration->Server Administration->Script, run Groovy Scripts/groovy-script-master-slave
19. On node2, assert result
This node is master node
20. On node2, assert console
Memory clustered job from modules is triggered at 1502232826800"
Clustering,,Test Group 9 - JGroups Configs,,,,,,,,,,
Clustering,,JDBC_PING,9a,Functional,25,5,,,,,ClusteringConfigs#StartupJDBCPING ,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Modify channel properties to use JDBC_PING by setting[d][e]:                 cluster.link.channel.properties.control[f][g]=UDP(bind_addr=${cluster.link.bind.addr[""cluster-link-control""]};mcast_group_addr=${multicast.group.address[""cluster-link-control""]};mcast_port=${multicast.group.port[""cluster-link-control""]}):JDBC_PING(connection_driver=${jdbc.default.driverClassName};connection_url=${jdbc.default.url};connection_username=${jdbc.default.username};connection_password=${jdbc.default.password}):MERGE3(min_interval=10000;max_interval=30000):FD_SOCK:FD_ALL:VERIFY_SUSPECT(timeout=1500):pbcast.NAKACK2(xmit_interval=500;xmit_table_num_rows=100;xmit_table_msgs_per_row=2000;xmit_table_max_compaction_time=30000;max_msg_batch_size=500;use_mcast_xmit=false;discard_delivered_msgs=true):UNICAST3(xmit_interval=500;xmit_table_num_rows=100;xmit_table_msgs_per_row=2000;xmit_table_max_compaction_time=60000;conn_expiry_timeout=0;max_msg_batch_size=500):pbcast.STABLE(stability_delay=1000;desired_avg_gossip=50000;max_bytes=4M):pbcast.GMS(join_timeout=2000;print_local_addr=true;view_bundling=true):UFC(max_credits=2M;min_threshold=0.4):MFC(max_credits=2M;min_threshold=0.4):FRAG2(frag_size=60K):RSVP(resend_interval=2000;timeout=10000)
2. Start node1 and wait for it is fully started
3. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
4. Start node2 and wait for it is fully started
5. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
6. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
7. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]"
Clustering,,UDP,9b,Manual,25,3,,,,,,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Modify channel properties to use UDP by setting:
                cluster.link.channel.properties.control=udp.xml
cluster.link.channel.properties.transport.0=udp.xml
2. Start node1 and wait for it is fully started
3. Assert on console of node1, udp is the protocol using, search the following code, there should be two matches, one for control channel, one for transport channel
        Create a new JGroups channel with properties UDP(
4. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=172.16.20.96:37714
-------------------------------------------------------------------
5. Start node2 and wait for it is fully started
6. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=172.16.20.96:44936
-------------------------------------------------------------------
7. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]"
Clustering,,TCP,9c,Manual,25,3,,,,,,"1. Configure two nodes as a cluster
1. Enable cluster on both nodes by setting: cluster.link.enabled=true
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Modify channel properties to use TCP by setting:
                cluster.link.channel.properties.control=tcp.xml
cluster.link.autodetect.address=localhost
2. Start node1 and wait for it is fully started
3. Assert on console of node1, tcp is the protocol using, search the following code, there should be one match for control channel
        Create a new JGroups channel with properties TCP(
4. On node1, assert console and find control channel’s address : liferay-Precision-5520-37063
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-37063, cluster=liferay-channel-control, physical address=127.0.0.1:7800
-------------------------------------------------------------------
5. Start node2 and wait for it is fully started
6. On node2, assert console and find control channel’s address: liferay-Precision-5520-30711
-------------------------------------------------------------------
GMS: address=liferay-Precision-5520-30711, cluster=liferay-channel-control, physical address=127.0.0.1:7801
-------------------------------------------------------------------
7. On node1, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]
8. On node2, assert console
Accepted view [liferay-Precision-5520-37063|1] (2) [liferay-Precision-5520-37063,
liferay-Precision-5520-30711]"
Clustering,,TCP_PING,9d,Manual,25,3,,,,,,"1. Configure two nodes as a cluster:
1. Add a parameter to setenv.sh/setenv.bat on both nodes’ JVM:
-Djgroups.bind_addr=[node_address]
2. Configure two nodes to use same database (HSQL is not allowed in cluster environment)
3. Modify channel properties to use TCP by setting in portal-ext.properties:
cluster.link.channel.properties.control=[CONFIG_FILE_PATH]/tcp-control.xml
cluster.link.channel.properties.transport.0=[CONFIG_FILE_PATH]/tcp-transport.xml
4. Add the following properties into portal-ext.properties: 
cluster.link.enabled=true
initial_hosts=""${jgroups.tcpping.initial_hosts}""
5. Download the latest com.liferay.portal.cluster.multiple-[version].jar files from Liferay’s Nexus repository and open it.
6. In this JAR’s lib folder is a file called jgroups-[version].Final.jar. 
7. Open it and find tcp.xml. Extract tcp.xml to  /webapps/ROOT/WEB-INF/classes/ 
8. Make a copy of the tcp.xml, rename both and add both files to each node:
Tcp-control.xml
tcp-transport.xml
9. Edit these files and assign bind ports, for example, first two nodes might assign these bind ports:
* Node 1
        tcp-control.xml bind port: 7800
tcp-transport.xml bind port: 7801
* Node 2
tcp-control.xml bind port: 7802
tcp-transport.xml bind port: 7803
2. Start node1 and wait for it is fully started
3. Assert no “ERROR [TQ-Bundler-8,liferay-channel-control][TCP:99] JGRP000029”
4. Start node 2 and wait for it is fully started
5. Assert no “ERROR [TQ-Bundler-8,liferay-channel-control][TCP:99] JGRP000029”
Test Group 10 - Session Replication"
Clustering,,Test Group 10 - Session Replication,,,,,,,,,,
Clustering,,Session replicated between nodes (LPS-72911),10a,Manual,,3,,,,,,"1. Configure Liferay cluster with two tomcat nodes.
2. Edit *$TOMCAT_HOME/conf/server.xml* of each node and configure the tcp ports to ""8080"" and ""8180""
3. Activate session replication at tomcat level:
   1. Edit $TOMCAT_HOME/conf/server.xml of each node and inside <Engine> tag, add following text:
<Cluster className=""org.apache.catalina.ha.tcp.SimpleTcpCluster""/>
   2. Edit *$TOMCAT_HOME/conf/context.xml* of each node and inside {{Context}} tag, add following text:
<Manager className=""org.apache.catalina.ha.session.DeltaManager""
            expireSessionsOnShutdown=""false""
            notifyListenersOnReplication=""true""/>
   3. Edit *$TOMCAT_HOME/webapps/ROOT/WEB-INF/web.xml* and immediately following the <web-app> tag (inside the tag), add the tag <distributable />
   4. Edit *$TOMCAT_HOME/conf/logging.properties* and add the following lines.
##CLUSTER LOG
5cluster.org.apache.juli.AsyncFileHandler.level = FINER
5cluster.org.apache.juli.AsyncFileHandler.directory = ${catalina.base}/logs
5cluster.org.apache.juli.AsyncFileHandler.prefix = cluster.

# just the clustering logs - all others are stock logging.properties
org.apache.catalina.tribes.MESSAGES.level = FINE
org.apache.catalina.tribes.MESSAGES.handlers = 5cluster.org.apache.juli.AsyncFileHandler

org.apache.catalina.tribes.level = FINE
org.apache.catalina.tribes.handlers = 5cluster.org.apache.juli.AsyncFileHandler

org.apache.catalina.ha.level = FINE
org.apache.catalina.ha.handlers = 5cluster.org.apache.juli.AsyncFileHandler

org.apache.catalina.ha.deploy.level = INFO
org.apache.catalina.ha.deploy.handlers = 5cluster.org.apache.juli.AsyncFileHandler
           5. Also add 5cluster.org.apache.juli.AsyncFileHandler to handlers line at the beginning of the file.
4. Start first tomcat node and wait until startup finish
5. Verify you can login from browser using URL: http://localhost:8080/web/guest
6. Start second tomcat node and wait until startup finish
7. Review LIFERAY_HOME/tomcat-8.0.32/logs/cluster.*.log files of both nodes (configured in previous steps) and verify that tomcat cluster is working.
8. Login and logout in both tomcat cluster nodes using following URLs: http://localhost:8080/web/guest and http://localhost:8180/web/guest
9. Assert no errors thrown in cluster log files (LIFERAY_HOME/tomcat-8.0.32/logs/cluster.*.log )
10. Install test-session-replication-portlet.war in first tomcat node (copy war to liferay deploy directory)
11. Create a page called ""session replication test""
12. Add test session replication portlet to created page
13. Install attached test-session-replication-portlet.war in second tomcat node (copy war to liferay deploy directory)
14. Open created page ""session replication test"" in a new browser using URL of first node
15. Following message will be displayed: 
""No sessionData exists, generated a new one with random string ....""
16. Refresh page: the same generated random string will be displayed again 
17. In the same browser, open the same page but using the second node URL.
18. Assert the same random string generated in the first node is displayed second node (random string is replicated through tomcat session replication) 
19. Check cluster log (LIFERAY_HOME/tomcat-8.0.32/logs/cluster.*.log) files for both nodes
20. Assert no error is displayed"
Clustering,,Shutdown module during replicated session (LPS-73732),10b,Manual,,3,,,,,,"1. Execute 10a (1-6)
2. Navigate to gogo shell for the first node and execute:
   1. lb | grep test-session-replication-portlet
   2. stop <id> (id: number obtained in previous step)
3. Open created page ""session replication test"" in a new browser using URL of second node
4. Assert the same generated random string will be displayed on the second node
5. Assert no error thrown[h][i][j][k] in Liferay console
6. Open cluster log (LIFERAY_HOME/tomcat-8.0.32/logs/cluster.*.log) files for both nodes
7. Assert no error is displayed"
Clustering,,Test Group 11 - Startup Scenarios,,,,,,,,,,
Clustering,,Servers with existing osgi/state (LPS-90295),11a,Manual,,4,,,,,,"1. Download snapshot bundle (or any release bundle that includes osgi/state)
2. Unzip liferay-portal-tomcat-master.7z
3. Setup clustering
   1. Add `cluster.link.enabled=true` into portal-ext.properties
   2. Add to osgi/configs folder
      1. com.liferay.portal.search.elasticsearch6.configuration.ElasticsearchConfiguration.config
         1. operationMode=""REMOTE""
   3. Run ""ant -f build-test-elasticsearch6.xml start-elasticsearch"" on source folder to start a remote elasticsearch
   4. Make a copy of the bundle and set to a different port in tomcat/conf/server.xml
4. Start cluster node 1
5. Assert that node 1 starts without error
6. Start second node
7. Assert that node 2 starts without error"
Clustering,,Test Group 12 - Portal Database Content,,,,,,,,,,
Clustering,,Add and Delete Blog Entries on different nodes,12a,Functional,,4,,,,,Clustering#AddAndDeleteBlogEntriesOnSeparateNodes,"1. Start 2 node cluster
2. Navigate to first node (8080)
3. Create a page
4. Add a Blogs widget to the page
5. Create and publish a blogs entry
6. Navigate to second node (9080)
7. Navigate to previously created page
8. Assert Blog Entry present on second node
9. Add a second page (still on the second node)
10. Add a Blogs widget to the page
11. Assert first blog entry is now present on the second page
12. Add a second blog entry on this page
13. Delete second blog entry (move to Recycle Bin and then clear)
14. Navigate to first node (8080)
15. Go to second created page
16. Assert only first blog entry present
17. Search for deleted blog entry
18. Assert no results return"
Clustering,,View Document on different nodes,12b,Functional,,4,,,,,Clustering#ValidateDocumentOnSeparateNodes,"1. Start 2 node cluster
2. Navigate to first node (8080)
3. Create a page
4. Add a Documents and Media widget to the page
5. Add a document
6. Navigate to second node (9080)
7. Go to created page
8. Assert Document present on the second node"
Config Admin,Config Admin,,,,,,,,,,,
Config Admin,,Test Group 1 - Database (Persistence),,,,,,,,,,
Config Admin,,Confirm bundle activator registration,1a,Integration,-,,,,,,ConfigurationPersistenceManagerTest#testConfigurationPersistenceManager,"1. Start PersistenceManager service
2. Assert class name matches ConfigurationPersistenceManager"
Config Admin,,Assert methods with Factory Configuration,1b,Integration,-,,,,,,ConfigurationPersistenceManagerTest#testCreateFactoryConfiguration,"1. Create factory configuration in ConfigAdmin
2. Add properties dictionary
3. Assert configuration with ""exists""
4. Assert properties with ""load""
5. Assert update properties with ""update"" and ""load""
6. Delete configuration
7. Assert configuration not returned for  ""exists"""
Config Admin,,Exists,1c,Integration,-,,,,,,ConfigurationPersistenceManagerTest#testExists,"1. Create single configuration with pid
2. Assert configuration with ""exists""
3. Delete configuration
4. Assert configuration gone with ""exists"""
Config Admin,,Get Configuration,1d,Integration,-,,,,,,ConfigurationPersistenceManagerTest#testGetConfiguration,"1. Create single configuration using ""getConfiguration""
2. Add properties dictionary
3. Assert configuration with ""exists""
4. Assert properties with ""load""
5. Assert update properties with ""update"" and ""load""
6. Delete configuration
7. Assert configuration not returned for  ""exists"""
Config Admin,,Test Group 2 - Migration tool warnings,,,,,,,,,,
Config Admin,,Migration Tool warning system for portal property,2a,Integration,-,,,,,,VerifyProperties#testModularizedPortalKeys,"1. Add property to portal-ext that has been migrated
2. Assert warning system when portal property has been migrated to config (.cfg/.config) instead of a property"
Config Admin,,Migration Tool warning system for system property,2b,Manual,,3,,,,,,"1. Add property to system-ext that has been migrated
2. Assert warning system when system property has been migrated to config (.cfg/.config) instead of a property"
Config Admin,,Test Group 3 - Configuration Extender,,,,,,,,,,
Config Admin,,Factory Configuration,3a,Integration,-,,,,,,ConfiguratorExtenderTest#testFactoryConfiguration,"1. Create Factory ConfiguratorExtension
2. Assert configuration in ConfigAdmin"
Config Admin,,Factory configuration when another configuration is created,3b,Integration,-,,,,,,ConfiguratorExtenderTest#testFactoryConfigurationCreatesAnother,"1. Create factory configuration in ConfigAdmin and add key
2. Add second factory configuration at extension start
3. Assert both configurations present"
Config Admin,,Factory configuration with clashing factoryPid,3c,Integration,-,,,,,,ConfiguratorExtenderTest#testFactoryConfigurationWithClashingFactoryPid,"1. Add 2 Factory NamedConfigurationContent objects with the same factory pid
2. Assert 2 configurations added to ConfigAdmin"
Config Admin,,Factory configuration with clashing multiple contents,3d,Integration,-,,,,,,ConfiguratorExtenderTest#testFactoryConfigurationWithClashingMultipleContents,"1. Add 2 NamedConfigurationContent objects with the same factory.pid, same pid, and different key values
2. Assert ConfigAdmin only has one configuration and the first key value is saved[b][c][d]."
Config Admin,,Factory configuration with clashing multiple contents and different namespaces,3e,Integration,-,,,,,,ConfiguratorExtenderTest#testFactoryConfigurationWithClashingMultipleContentsAndDifferentNamespaces,"1. Add 2 factory NamedConfigurationContent objects with the same factory.pid, same pid, same key values, and different namespaces
2. Assert ConfigAdmin has 2 configurations"
Config Admin,,Single configuration,3f,Integration,-,,,,,,ConfiguratorExtenderTest#testSingleConfiguration,"1. Add Single NamedConfigurationContent
2. Assert configuration in ConfigAdmin"
Config Admin,,Single configuration respects existing configuration,3g,Integration,-,,,,,,ConfiguratorExtenderTest#testSingleConfigurationRespectsExistingConfiguration,"1. Create single configuration in ConfigAdmin and add key value
2. Add single configuration at extension start with different key value (use the same pid)
3. Assert key value not overwritten in ConfigAdmin 

ConfiguratorExtenderTest#testSingleConfigurationRespectsExistingConfiguration"
Config Admin,,Single configuration with clashing multiple contents,3h,Integration,-,,,,,,ConfiguratorExtenderTest#testSingleConfigurationWithClashingMultipleContents,"1. Add 2 Single NamedConfigurationContent objects with the same pid and different key values
2. Assert only first configuration present in ConfigAdmin (check key value)
        
ConfiguratorExtenderTest#testSingleConfigurationWithClashingMultipleContents"
Config Admin,,Single configuration with clashing multiple contents and different namespaces,3i,Integration,-,,,,,,ConfiguratorExtenderTest#testSingleConfigurationWithClashingMultipleContentsAndDifferentNamespaces,"1. Add 2 Single NamedConfigurationContent objects with the same pid, different key values, and different namespaces
2. Assert only first configuration present in ConfigAdmin (check key value)
        
ConfiguratorExtenderTest#testSingleConfigurationWithClashingMultipleContentsAndDifferentNamespaces
"
Config Admin,,Test single configuration with multiple contents,3j,Integration,-,,,,,,ConfiguratorExtenderTest#testSingleConfigurationWithMultipleContents,"1. Add 2 Single NamedConfigurationContent objects with the different pid and same key values
2. Assert 2 configurations present in ConfigAdmin"
Config Admin,,Exception in supplier does stop configuration extension,3k,Integration,-,,,,,,ConfiguratorExtenderTest#testExceptionInSupplierDoesNotStopExtension,"1. Create ConfiguratorExtension with runtime exception in ConfigurationDescriptionFactory
2. Assert configuration still present in ConfigAdmin"
Config Admin,,Create Factory Configuration,3l,Integration,-,,,,,,ConfigurationDescriptionFactoryImplTest#testCreateFactoryConfiguration,"1. Create Factory ConfigurationDescription object with 2 keys
2. Assert factory.pid and config.pid
3. Assert both key values"
Config Admin,,Returns null when not properties file named configuration content,3m,Integration,-,,,,,,ConfigurationDescriptionFactoryImplTest#testCreateReturnsNullWhenNotPropertiesFileNamedConfigurationContent,"1. Attempt to create NamedConfigurationContent object with no InputStream
2. Assert no ConfigurationDescription created
        
ConfigurationDescriptionFactoryImplTest#testCreateReturnsNullWhenNotPropertiesFileNamedConfigurationContent
"
Config Admin,,Create Single Configuration,3n,Integration,-,,,,,,ConfigurationDescriptionFactoryImplTest#testCreateSingleConfiguration,"1. Create Single ConfigurationDescription object with 2 keys
2. Assert config.pid
3. Assert both key values
        
Path Content"
Config Admin,,Create configuration path content factory,3o,Integration,-,,,,,,NamedConfigurationPathContentFactoryTest#testCreate,"1. Create bundleStorage object with properties file and key values
2. Create NamedConfigurationContent object with the bundleStorage object
3. Assert properties file and key values in NamedConfigurationContent"
Config Admin,,Test configuration with multiple files path,3p,Integration,-,,,,,,NamedConfigurationPathContentFactoryTest#testCreateWithMultipleFiles,"1. Execute 3n with 2 different files and key values
2. Assert both properties file and key values"
Config Admin,,Test configuration with nested directory,3q,Integration,-,,,,,,NamedConfigurationPathContentFactoryTest#testCreateWithNestedDirectory,"1. Execute 3n with 2 different files and key values. Put second file in a nested directory.
2. Assert both properties file and key values"
Config Admin,,Test Group 4 - Configuration Cluster,,,,,,,,,,
Config Admin,,SynchronousConfigurationListener,4a,Manual,,3,,,,,,"1. TBD - Assert final message sent to cluster link
2. How do we bootstrap the cluster to test this?"
Config Admin,,Test Group 5 - Persistence Manager Implementation,,,,,,,,,,
Config Admin,,Store,5a,Manual,-,3,,,,,Needs unit test,1. Assert Store implementation code
Config Admin,,Get Dictionaries,5b,Manual,-,3,,,,,Needs unit test,1. Assert getDictionaries implementation code
Config Admin,,Exists,5c,Manual,-,3,,,,,Needs unit test,2. Assert exists implementation code
Config Admin,,Delete,5d,Manual,-,3,,,,,Needs unit test,3. Assert delete implementation code
Config Admin,,Load,5e,Manual,-,3,,,,,Needs unit test,4. Assert load implementation code
Config Admin,,Reload,5f,Manual,-,3,,,,,Needs unit test,5. Assert reload implementation code
Config Admin,,Test Group 6 - Configuration Under Load,,,,,,,,,,
Config Admin,,Creat full load,6a,Manual,20,3,,,,,,"1. Start portal
2. Access gogo shell
3. Execute ""getPossibleConfigurations"" 
4. Get full list of configurations in use (all pids)
5. Shutdown portal
6. Add all pids to single bundle configuration
7. Add bundle to the portal
8. Start portal on a fresh database
9. Assert portal starts successfully without significant slowdown"
Config Admin,,Test Group 7 - Upgrade,,,,,,,,,,
Config Admin,,Upgrade configuration files,7a,Manual,,4,,,,,,"1. Create configuration with an old pid and a service.pid in dictionary
2. Add config files with both .cfg and .config extensions
3. Execute createUpgradeSteps with old pid and new pid
4. Assert new pid and new dictionary service.pid in database
5. Assert old pid removed from database
6. Assert both config files updated


        


Notes:
Config files are managed by felix file install, dictionary contains file name property, this is not updated by the existing code. Does not handle configuration factory, has a factory.pid (name of the file is also not connected to the service.pid, could be different file name scheme). What happens if dictionary file name and system path file name are not in sync?"
Config Admin,,Upgrade configuration table (LPS-89497),7b,Manual,,4,,,,,Bug still open,"1. Start 7.0.x or 7.1.x
2. Create a new instance for an arbitrary factory config, for example AnonymousUserConfiguration, OpenIdConnectProviderConfiguration, DestinationWorkerConfiguration etc.
3. This creates a config instance like com.xxx.OpenIdConnectProviderConfiguration-bab76645-06b9-44d0-8a5d-7b49802b1d43.config
4. Stop portal
5. Write a new upgrade step for the affected module like this on 7.1.x or master:
package com.your.package;


import com.liferay.portal.configuration.persistence.upgrade.ConfigurationUpgradeStepFactory;
import com.liferay.portal.upgrade.registry.UpgradeStepRegistrator;


import org.osgi.service.component.annotations.Component;
import org.osgi.service.component.annotations.Reference;


@Component(immediate = true, service = UpgradeStepRegistrator.class)
public class TestUpgrade implements UpgradeStepRegistrator {


        @Override
        public void register(Registry registry) {
                registry.register(
                        ""a.b.c"", ""x.y.z"",
                        _configurationUpgradeStepFactory.createUpgradeStep(
                                ""com.old.factory.config.ClassName"",
                                ""com.new.factory.config.ClassName""));
        }


        @Reference
        private ConfigurationUpgradeStepFactory _configurationUpgradeStepFactory;


}
6. Build and deploy the updated module
7. Run the upgrade tool: java -jar LIFERAY_HOME/tools/portal-tools-db-upgrade-client/com.liferay.portal.tools.db.upgrade.client.jar
8. Wait until it finishes the upgrade
9. Assert the Configuration_ table contains the renamed factory and instance."
Config Admin,,Test Group 8 - Viewing Properties,,,,,,,,,,
Config Admin,, View all Portal Properties in Portal UI,8a,Functional,,4,,,,,Serveradministration#ViewSystemAndPortalProperties,"1. Navigate to Server Administration > Properties > Portal Properties
2. Assert portal properties are displayed with property name and value"
Config Admin,, View all System Properties in Portal UI,8b,Functional,,4,,,,,Serveradministration#ViewSystemAndPortalProperties,"1. Navigate to Server Administration > Properties > System Properties
2. Assert system properties are displayed with property name and val"
DB Upgrade Client,DB Upgrade Client,,,,,,,,,,,
DB Upgrade Client,,Test Group 1 - Run DB Upgrade Client with specific properties set,,,,,,,,,,
DB Upgrade Client,,Run DB Upgrade client with no properties set,1a,Functional,-,5,,,,,ant > check-upgrade-properties-none-set,"1. Preconditions:
   1. No properties files set
2. Execution:
   1. db_upgrade.sh or db_upgrade.bat
3. Expected results:
   1. The tool should ask for entering the following properties:
      1. dir
      2. global.lib.dir
      3. portal.dir
      4. server.detector.server.id
      5. extra.lib.dirs
      6. jdbc.default.url
      7. jdbc.default.driverClassName
      8. jdbc.default.username
      9. jdbc.default.password (verify that the password is masked while we enter the characters)
      10. liferay.home
   2. The should create three files with previous properties:
      1. app-server.properties
      2. portal-upgrade-database.properties
      3. portal-upgrade-ext.properties
   3. The tool should run the upgrade for core and modules."
DB Upgrade Client,,Run DB Upgrade client with only app-server and portal-upgrade-database properties set,1b,Functional,-,4,,,,,ant > check-upgrade-properties-app-db-set,"1. Preconditions:
   1. The following properties are set:
      1. Open App-server.properties and uncomment properties for specific appserver:
         1. dir
         2. Global.lib.dir
         3. portal.dir
         4. server.detector.server.id
         5. extra.lib.dirs
      2. Portal-upgrade-database.properties:
         1. jdbc.default.url
         2. jdbc.default.driverClassName
         3. jdbc.default.username
         4. jdbc.default.password
2. Execution:
   1. db_upgrade.sh or db_upgrade.bat
3. Expected results:
   1. The tool should ask for entering the following properties:
      1. liferay.home
   2. The should create one file with previous properties:
      1. portal-upgrade-ext.properties
   3. The tool should run the upgrade for core and modules."
DB Upgrade Client,,Run DB Upgrade client with only portal-upgrade-ext and portal-upgrade-database properties set,1c,Functional,-,3,,,,,ant > check-upgrade-properties-db-ext-set,"1. Preconditions:
   1. The following properties are set:
      1. portal-upgrade-ext.properties:
         1. liferay.home
      2. Portal-upgrade-database.properties:
         1. jdbc.default.url
         2. jdbc.default.driverClassName
         3. jdbc.default.username
         4. jdbc.default.password
2. Execution:
   1. db_upgrade.sh or db_upgrade.bat 
3. Expected results:
   1. The tool should ask for entering the following properties:
      1. dir
      2. global.lib.dir
      3. portal.dir
      4. server.detector.server.id
      5. extra.lib.dirs
   2. The should create three files with previous properties:
      1. app-server.properties
   3. The tool should run the upgrade for core and modules."
DB Upgrade Client,,Run DB Upgrade client with only portal-upgrade-ext and app-server properties set,1d,Functional,-,3,,,,,ant > check-upgrade-properties-app-ext-set,"1. Preconditions:
   1. The following properties are set:
      1. portal-upgrade-ext.properties:
         1. liferay.home
      2. Open App-server.properties and uncomment properties for specific appserver:
         1. dir
         2. global.lib.dir
         3. portal.dir
         4. server.detector.server.id
         5. extra.lib.dirs
2. Execution:
   1. db_upgrade.sh or db_upgrade.bat 
3. Expected results:
   1. The tool should ask for entering the following properties:
      1. jdbc.default.url
      2. jdbc.default.driverClassName
      3. jdbc.default.username
      4. Jdbc.default.password (we should verify that the password is masked while we enter the characters)
   2. The should create this file with previous properties:
      1. Portal-upgrade-database.properties
   3. The tool should run the upgrade for core and modules."
DB Upgrade Client,,Test Group 2 - Run DB Upgrade Client in specific environments,,,,,,,,,,
DB Upgrade Client,,Run DB Upgrade client in Java 7,2a,Functional,-,4,,,,,ant > check-upgrade-client-java-version,"1. Preconditions:
   1. Set all properties files properly.
   2. Set Java 7 or below as java version.
2. Execution:
   1. db_upgrade.sh or db_upgrade.bat 
3. Expected results:
   1. An error should be shown saying that Java 8 is required."
DB Upgrade Client,,Run DB Upgrade client in JBoss,2b,Functional,-,4,,,,,PortalSmokeUpgrade.testcase,"1. Preconditions:
   1. Use Jboss as app server
   2. Set all properties files properly.
2. Execution:
   1. db_upgrade.sh or db_upgrade.bat 
3. Expected results:
   1. The tool should run the upgrade for core and modules."
DB Upgrade Client,,Run DB Upgrade client in WebSphere,2c,Functional,-,4,,,,,PortalSmokeUpgrade.testcase,"1. Preconditions:
   1. Use Websphere as app server
   2. Set all properties files properly.
2. Execution:
   1. db_upgrade.sh or db_upgrade.bat 
3. Expected results:
   1. The tool should run the upgrade for core and modules."
DB Upgrade Client,,Run DB Upgrade client in WebLogic,2d,Functional,-,4,,,,,PortalSmokeUpgrade.testcase,"1. Preconditions:
   1. Use Weblogic as app server
   2. Set all properties files properly.
2. Execution:
   1. db_upgrade.sh or db_upgrade.bat 
3. Expected results:
   1. The tool should run the upgrade for core and modules.

"
DB Upgrade Client,,Run DB Upgrade client in Tomcat,2e,Functional,-,5,,,,,PortalSmokeUpgrade.testcase,"1. Preconditions:
   1. Use Linux as operating system.
   2. Use Tomcat as app server
   3. Set all properties files properly.
2. Execution:
   1. db_upgrade.sh or db_upgrade.bat 
3. Expected results:
   1. The tool should run the upgrade for core and modules."
DB Upgrade Client,,Run DB Upgrade client in Wildfly,2f,Functional,-,4,,,,,PortalSmokeUpgrade.testcase,"4. Preconditions:
   1. Use Wildfly as app server
   2. Set all properties files properly.
5. Execution:
   1. db_upgrade.sh or db_upgrade.bat 
6. Expected results:
   1. The tool should run the upgrade for core and modules."
DB Upgrade Client,,Run DB Upgrade client in tcServer (<= 7.1),2g,Functional,-,3,,,,,PortalSmokeUpgrade.testcase,"7. Preconditions:
   1. Use Wildfly as app server
   2. Set all properties files properly.
8. Execution:
   1. db_upgrade.sh or db_upgrade.bat 
9. Expected results:
   1. The tool should run the upgrade for core and modules."
DB Upgrade Client,,Test Group 3 - Run DB Upgrade client with specific parameters,,,,,,,,,,
DB Upgrade Client,,Run DB Upgrade client with help parameter,3a,Functional,-,3,,,,,ant > check-upgrade-client-help,"1. Preconditions:
   1. None
2. Execution:
   1. db_upgrade.sh -h or db_upgrade.bat -h
3. Expected results:
   1. The tool show the help menu"
DB Upgrade Client,,Run DB Upgrade client with JVM parameters,3b,Functional,-,4,,,,,ant > check-upgrade-client-additional-settings,"1. Preconditions:
   1. Set all properties files properly
2. Execution:
   1. java -jar com.liferay.portal.tools.db.upgrade.client.jar -j “-Dfile.encoding=UTF8 -Duser.country=US -Duser.language=en -Duser.timezone=GMT -Xmx4096m""
3. Expected results:
   1. Verify that the java virtual machine runs with those parameters"
DB Upgrade Client,,Run DB Upgrade client with log file parameter,3c,Functional,-,4,,,,,ant > check-upgrade-client-custom-log,"1. Preconditions:
   1. Set all properties files properly
2. Execution:
   1. Db_upgrade.sh -l “log_file.txt” or db_upgrade.bat -l “log_file.txt”
3. Expected results:
   1. Verify that the the log output is written in log_file.txt"
DB Upgrade Client,,Run DB Upgrade client with shell parameter using the jar,3d,Functional,-,4,,,,,ant > check-upgrade-client-gogoshell,"1. Preconditions:
   1. Set all properties files properly
2. Execution:
   1. db_upgrade.sh -s
3. Expected results:
   1. Verify that the Gogo shell is automatically connected at the end of the upgrade"
DB Upgrade Client,,Run DB Upgrade script with shell parameter on Windows,3e,Manual,10,4,,,,,https://issues.liferay.com/browse/LRQA-53826,"4. Preconditions:
   1. Set all properties files properly
5. Execution:
   1. db_upgrade.bat -s
6. Expected results:
   1. Verify that the Gogo shell is automatically connected at the end of the upgrade"
DB Upgrade Client,,Test Group 4 - Run DB Upgrade client with specific configurations,,,,,,,,,,
DB Upgrade Client,,Run DB Upgrade client configured to run module upgrades individually,4a,Functional,-,5,,,,,ant > check-upgrade-client-upgrade-core-only,"1. Preconditions:
   1. Set all properties files properly.
   2. Set the config admin property to run module upgrades individually[a] (see https://dev.liferay.com/discover/deployment/-/knowledge_base/7-0/running-the-upgrade-process#upgrading-modules-individually)
2. Execution:
   1. db_upgrade.sh or db_upgrade.bat
3. Expected results:
   1. The tool should run the upgrade for core but not for the modules (check release_ table)"
DB Upgrade Client,,Test Group 5 - Gogo shell,,,,,,,,,,
DB Upgrade Client,,Check for help output ,5a,Manual,10,4,,,,,https://issues.liferay.com/browse/LRQA-53823,"1. Preconditions:
   1. Set all properties files properly.
2. Execute the db upgrade tool with ""-s"" parameter to start the gogo shell
3. Assert messages in gogo shell after upgrade:
   1. Type ""help"" to get available upgrade and verify commands.
   2. Type ""help {command}"" to get additional information about the command. For example, ""help upgrade:list"".
4. Execute the following commands and assert information is returned.
   1. upgrade:check
   2. upgrade:execute
   3. upgrade:executeAll
   4. upgrade:list
   5. verify:execute
   6. verify:executeAll
   7. verify:list
   8. verify:show
   9. verify:showReports"
DB Upgrade Client,,Gogo shell connection after failed upgrade,5b,Functional,,4,,,,,ant > check-upgrade-client-gogoshell-failed-upgrade,"1. Remove a jar from osgi/modules to simulate a modules upgrade failure (.e.g. com.liferay.journal.api.jar)
2. Start an upgrade with the db upgrade tool
3. Wait the upgrade to fail
4. Assert connection to gogo shell due to upgrade failure"
DB Upgrade Client,,Gogo shell command output,5c,Manual,,4,,,,,https://issues.liferay.com/browse/LRQA-53825,"1. Execute the upgrade client with “./db_upgrade.sh -s” command
2. After upgrade finished and gogo shell console is opened, execute the following commands:
1. Execute “upgrade:check”
2. Enter to execute an empty command
3. Execute “exit”
3. Assert command is not printed twice after its execution
4. Assert no white line is printed
5. Open upgrade.log in the upgrade log folder
6. Confirm that the prefix g! for previous commands do not exist"
DB Upgrade Client,,Test Group 6 - Upgrade over SSH connection,,,,,,,,,,
DB Upgrade Client,,Disconnect and Reconnect to running upgrade,6a,Functional,-,5,,,,,ant > check-upgrade-client-sh-disconnect,"1. Connect via SSH to a system with a Unix OS where Liferay is installed
2. Start an upgrade with the db upgrade tool
3. Stop the SSH connection (bash db_upgrade.sh & exit)
4. Connect via SSH again
5. Confirm the process is still running (ps -ef | grep db_upgrade)
6. Wait for upgrade to complete
7. View upgrade.log to confirm upgrade completed successfully"
DB Upgrade Client,,Gogo shell connection closed after failed upgrade,6b,Manual,20,2,,,,,,"5. Connect via SSH to a system with a Unix OS where Liferay is installed
6. Use the following to drop Journal table from database to simulate a module upgrade failure 
1. Go to mysql command line
2. Enter use lportal;
3. Show tables;
4. Alter table JournalArticle drop companyId;
7. Start an upgrade with the db upgrade tool
8. Stop the SSH connection (bash db_upgrade.sh & exit)
9. Wait the expected amount of time for the upgrade to complete
10. Connect via SSH again
11. View upgrade.log to confirm upgrade shows failed attempt to connect to gogo shell (""Unable to open Gogo shell"")
12. Attempt to access gogo shell to confirm process has been stopped (telnet localhost 11311)"
DB Upgrade Client,,Disconnect and Attempt to start a second upgrade process,6c,Functional,20,3,,,,,ant > check-upgrade-client-second-process,"13. Connect via SSH to a system with a Unix OS where Liferay is installed
14. Start an upgrade with the db upgrade tool
15. Stop the SSH connection (bash db_upgrade.sh & exit)
16. Connect via SSH again
17. Start a second upgrade with the db upgrade tool
18. Confirm message given that an existing process is ongoing, 
19. Confirm no new process starts"
DB Upgrade Client,,Test Group 7 - Upgrade client distribution,,,,,,,,,,
DB Upgrade Client,,Upgrade with standalone Upgrade client,7a,Functional,-,4,,,,,ant > check-upgrade-client-zip-content,"1. Download Standalone Upgrade Client (Help Center Download Link)
2. Extract the zip to LIFERAY_HOME/tools/ 
3. Navigate to portal-tools-db-upgrade-client directory
4. Assert content in the root folder
   1. portal-upgrade-ext.properties
   2. portal-upgrade-database.properties
   3. db_upgrade.sh
   4. db_upgrade.bat
   5. com.liferay.portal.tools.db.upgrade.client.jar
   6. app-server.properties
5. execute ./db_upgrade.sh
6. Confirm upgrade can be executed with standalone client"
DB Upgrade Client,,Upgrade with build-in Upgrade client,7b,Functional,-,5,,,,,PortalSmokeUpgrade.testcase,"1. Download tomcat bundle
2. Navigate to LIFERAY_HOME/tools/portal-tools-db-upgrade-client
3. execute ./db_upgrade.sh
4. Confirm upgrade can be executed with built-in client"
DL Stores,DL Stores,,,,,,,,,,,
DL Stores,,Test Group 1 - Local Document Library Store,,,,,,,,,,
DL Stores,,Advanced File System Store,1a,Functional,,,,,,,DocumentLibraryStore#AdvancedFileSystemStoreSmoke,"1. Set this property in the portal-ext.properties
1. dl.store.impl=com.liferay.portal.store.file.system.AdvancedFileSystemStore
2. Create the  file  below in the  osgi/configs folder: 
1. com.liferay.portal.store.file.system.configuration.AdvancedFileSystemStoreConfiguration.config
2. Open add “rootDir=&quot;data/document_library1&quot;” into the file
3. Start liferay portal
4. Go to Site Administration => Content and Data => Documents and Media
5. Add  a document
6. Verify document is created
7. Delete the document
8. Verify document is moved to recycle bin"
DL Stores,,DBStore,1b,Functional,,,,,,,DocumentLibraryStore#DBStoreSmoke,"1. Set this property in the portal-ext.properties
1. dl.store.impl=com.liferay.portal.store.db.DBStore
2. Start liferay portal
3. Confirm that “java.lang.IllegalStateException: Store is not available” is not present in the console
4. Repeat Test Case 1a steps (4 - 8)"
DL Stores,,File System Store,1c,Functional,,,,,,,DocumentLibraryStore#FileSystemStoreSmoke,"1. Set this property in the portal-ext.properties
1. dl.store.impl=com.liferay.portal.store.file.system.FileSystemStore
2. Create the  file below in the  osgi/configs folder:
1. com.liferay.portal.store.file.system.configuration.FileSystemStoreConfiguration.config
2. Open and add ""rootDir=&quot;data/document_library1&quot;"" into the file above
3. Repeat steps Test Case 1a(3 - 8)"
DL Stores,,Test Group 2 - Cloud Stores,,,,,,,,,,
DL Stores,,Amazon S3 Store,2a,Manual,,3,,,,,,"1. Configure Amazon S3 store per setup instructions
2. Repeat steps Test Case 1a(3 - 8)"
DL Stores,,Google Cloud Store (LPS-89224),2b,Manual,,3,,,,,,1. TODO - Story pending
Friendly URL,Friendly URL,,,,,,,,,,,
Friendly URL,,Test Group 1 - Smoke Test Friendly URL,,,,,,,,,,
Friendly URL,,Add Friendly URL,1a,Manual,,3,,,,,,"1. Add Friendly URL
2. Verify navigating to site shows Friendly URL in address bar
3. Copy paste Friendly URL into address navigates to site page"
Friendly URL,,Edit Friendly URL,1b,Manual,,4,,,,,FriendlyURL#EditFriendlyURL,"1. Add Friendly URL
2. Copy paste Friendly URL into address navigates to site page
3. Edit Friendly URL
4. Copy paste edited Friendly URL into address navigates to site page
5. Paste OLD Friendly URL into address bar
6. Assert no page found

"
Friendly URL,,Delete Friendly URL,1c,Functional,,5,,,,,Sites#DeleteSiteFriendlyURL,"1. Testcase 1a
2. Copy Friendly URL
3. Delete the created Friendly URL
4. Paste Friendly URL into address
5. Assert Friendly URL does not work and 404 page is shown
6. Assert no errors on console
"
Friendly URL,,Test Group 2 - Validate Semantics Rules,,,,,,,,,,
Friendly URL,,Verify Friendly URL with Special characters is normalized,2a,Functional,,3,,,,,Staging#ValidateFriendlyURLWithSpecialCharacters,"1. Add Friendly URL with  lowercase alphanumeric characters and special characters
2. Assert alphanumeric characters persist in friendlyURL
3. Assert special characters (see _REPLACE_CHARS in FriendlyURLNormalizerImpl) are replaced with dashes (""-"")

"
Friendly URL,,Verify Uppercase Friendly URL auto generates lowercase,2b,Manual,,2,,,,,,"1. Add Friendly URL with uppercase letters
2. Save
3. Verify friendly URL becomes lowercase
4. Enter into address bar Friendly URL with uppercase letters
5. Verify user is navigated to page
6. Verify no errors
7. Enter into address bar Friendly URL with uppercase and lowercase letters
8. Verify user is navigated to page
9. Verify no errors"
Friendly URL,,Add Friendly URL with unicode characters,2c,Functional,,4,,,,,FriendlyURL#ViewFriendlyURLWithUnicodeChars,"1. Add Friendly URL with unicode characters
2. Enter into address bar Friendly URL
3. Verify user is navigated to correct page
4. Verify no errors"
Friendly URL,,Test Group 3 - Friendly URL Alias Redirection,,,,,,,,,,
Friendly URL,,Alias Redirection,3a,Manual,,4,Skip,,,,https://issues.liferay.com/browse/LRQA-53819,"1. Prepare environment
   1. Custom properties
      1. locale.prepend.friendly.url.style=2
2. Access localhost:8080
3. Open developer console to network tab (or equivalent)
4. Assert 302, 301 redirect codes[a]
5. Assert user is redirected to localhost:8080/en/web/guest/home"
Friendly URL,,Test Group 4 - Friendly URL in different Locale/Language Variations,,,,,,,,,,
Friendly URL,,Verify FriendlyURLs in unavailable locales without default locale return a 404 response code,4a,Manual,,3,,,,,,"1. Prepare environment
   1. Custom properties
      1. From the list of available locales, select some to the enabled by default (set locales.enabled=... in portal-ext.properties)
      2. Define a default user language from the list of default enabled languages (set user.country and user.language in system-ext.properties)
   2. Default properties
      1. locale.use.default.if.not.available=false in portal-ext.properties to ensure HTTP 404 response when accessing locale that is not enabled
2. Access FriendlyURL for locales that are in list of enabled languages
3. Verify user is redirected to page with text localized to the requested locale
4. Access FriendlyURL for locales that are in the list of available languages but not in the list of enabled languages
5. Verify HTTP 404 response code is returned, and user is redirected to Not Found page"
Friendly URL,,Verify FriendlyURLs redirect to default locale when locale is available but not enabled (LPS-79309),4b,Functional,,4,,,,,Locale#VerifyFriendlyURLRedirectToEnableDefualtLocale,"1. Prepare environment
   1. Custom properties
      1. From the list of available locales, select some to the enabled by default (set locales.enabled=... in portal-ext.properties)
      2. Define a default user language from the list of default enabled languages (set user.country and user.language in system-ext.properties)
      3. Set locale.use.default.if.not.available=true in portal-ext.properties so that accessing disabled locales will redirect to the default locale
2. Access FriendlyURLs for locales that are in list of enabled languages
3. Verify user is redirected to page with text localized to the requested locale
4. Access FriendlyURL for locales that are in the list of available locales but not in the list of enabled locales
5. Verify user is redirected to the FriendlyURL for the default locale
6. Verify page is localized to the default locale"
Friendly URL,,Verify FriendlyURLs always display the requested locale when locale.prepend.friendly.url.style is set to 2,4c,Manual,,3,,,,,,"1. Prepare environment
   1. Custom properties
      1. From the list of available locales, select some to the enabled by default (set locales.enabled=... in portal-ext.properties)
      2. Define a default user language from the list of default enabled languages (set user.country and user.language in system-ext.properties)
      3. Set locale.prepend.friendly.url.style=2 in portal-ext.properties
2. Access portal without the providing a locale
3. Assert FriendlyURL with the default locale is used
4. Assert user is redirected to page localized to default locale"
Friendly URL,,Verify locales for FriendlyURLs when locale is shared but languages are different (LPS-77681),4d,Manual,,4,,,,,https://issues.liferay.com/browse/LRQA-53821,"1. Prepare environment
   1. Custom properties
      1. Limit list of enabled locales to the following: 
         1. locales.enabled=en_US,en_AU,en_GB in portal-ext.properties
      2. Set locale.prepend.friendly.url.style=2 in portal-ext.properties
   2. Create three sites
      1. US site with default locale as en_US
      2. GB site with default locale as en_GB
      3. AU site with default locale as en_AU
2. Access FriendlyURL by providing only the locale for each of the three sites
3. Verify /en redirects to each of the specific languages on each site (en = en_US for US site, en = en_GB for GB site, and en = en_AU for AU site)
4. Access FriendlyURL by providing the default locale and language for each of the three sites
5. Verify the default locale and language for each of the three sites redirects to /en"
Friendly URL,,Verify FriendlyURLs only display locale once (LPS-81758),4e,Manual,,4,,,,,https://issues.liferay.com/browse/LRQA-53822,"1. Add a public page named “Test”
2. Edit the public page
3. Add a friendlyURL for Hungarian (hu-HU) as “/teszt”
4. Save the changes
5. Access the the friendlyURL: [portalURL]/hu/web/[site-name]/test
6. Verify page name in friendlyURL is translated to teszt
7. Verify locale only displays once in the FriendlyURL"
Friendly URL,,Test Group 5 - Robustness,,,,,,,,,,
Friendly URL,,Verify FriendlyURL copied from Forms page redirects to the Forms page,5a,Functional,,5,,,,,Forms.testcase,"1. Create a form
2. Copy the friendlyURL that is generated from the form
3. Paste the form page friendlyURL into the URL field and navigate to it
4. Assert user is redirected to form page"
Friendly URL,,Verify FriendlyURL can be generated from web content articles and accessed (covered by WEM team),5b,Functional,,5,,,,,PGStaging#PublishWCWithFriendlyURL,"1. Add a page
2. Add an Asset Publisher widget onto the page
3. Configure the Asset Publisher widget to be the default Asset Publisher widget for the page
4. Create a web content article
5. Publish the web content article
6. Edit the web content article and copy the friendlyURL for the web content article
7. Navigate to the FriendlyURL for the web content article
8. Verify user is redirected to the page with the Asset Publisher widget, and the web content article is displayed in the Asset Publisher widget"
Friendly URL,,Verify FriendlyURL can be generated from blog entries and accessed (covered by Collaboration team),5c,Functional,,5,,,,,Ask Collab,"1. Create a blog entry
2. Publish the blog entry
3. Edit the blog entry and copy the friendlyURL for the blog entry
4. Create a page
5. Add a Blogs widget onto the page
6. Navigate to the FriendlyURL for the blog entry
7. Verify blog entry is displayed in the Blogs widget"
Friendly URL,,Verify FriendlyURL can be generated from pages and accessed,5d,Functional,,5,,,,,WidgetPages.testcase,"1. Create a page
2. Add a widget on the page
3. Copy the friendlyURL of the page
4. Navigate to the friendlyURL
5. Assert that the user is redirected to the page, and the widget displays on the page"
Friendly URL,,Test Group 6 - High Priority SEO,,,,,,,,,,
Friendly URL,,Verify canonical url when using a localized friendlyURL,6a,Functional,,5,,,,,FriendlyURL#ViewCanonicalURLWithLocalizedFriendlyURL,"1. Ensure user is logged out
2. Navigate to home page of the default site using the following pattern: (http|https)://{hostname}:{port}/web/{site-friendly-url}
3. Open the developer console
4. Open the <head> element to view metadata
5. Assert canonical url is the url from step 2
6. Navigate to (http|https)://{hostname}:{port}/es/web/{site-friendly-url}
7. View the <head> element to view metadata
8. Assert canonical url is still (http|https)://{hostname}:{port}/web/{site-friendly-url}"
Gogo Shell,Gogo Shell,,,,,,,,,,,
Gogo Shell,,Test Group 1 - Gogo Shell Access (Terminal),,,,,,,,,,
Gogo Shell,, No default access to gogo shell,1a,Functional,,5,,,,,ant > no-default-access-to-gogo-shell-command,"1. No gogo shell property is enabled in the portal-ext-properties
2. Start Liferay portal application server
3. Open a terminal
4. Execute “telnet localhost 11311”
5. Confirm Gogo shell fails to connect   "
Gogo Shell,,Access gogo shell command,1b,Functional,,5,,,,,ant > enable-access-to-gogo-shell-command,"1. Enable telnet on your machine
   2. Add “include-and-override=portal-developer.properties” into portal-ext.properties
   1. or set ""module.framework.properties.osgi.console=localhost:11311""
   3. Start Liferay portal application server
   4. Open a terminal
   5. Execute “telnet localhost 11311”
   6. Confirm gogo shell is connected"
Gogo Shell,,Test Group 2 - Gogo Shell Access (UI),,,,,,,,,,
Gogo Shell,,Access gogo shell command via portlet,2a,Functional,,5,,,,,Gogoshell#AccessGogoShellCommandViaPortlet,"1. Start Liferay portal application server
   2. Go to Control panel > Configuration
   3. Gogo Shell
   4. Confirm gogo shell access in (UI) command    


      5. Execute system:check command
      6. Confirm output  
      7. Execute scr:list command (LPS-90372 )
      8. Confirm scr output"
Gogo Shell,,Site Admin cannot access Gogo Shell,2b,Functional,,4,,,,,Gogoshell#SiteAdminCannotAccessGogoShellPortlet,"1. Create user with site administrator role
         2. Login to created user
         3. Go to Control Panel > Configuration
         4. Confirm user has no access to Gogo Shell portlet"
Gogo Shell,,OmniAdmin can access Gogo Shell (LPS-101101),2c,Functional,,4,,,,,Gogoshell#OmniAdminCanAccessGogoShellCommandViaPortlet,"1. Create a user with an administrator
         2. Sign in as a new administrator user
         3. Go to Control panel > Configuration 
         4. Verify Gogo Shell portlet is displayed"
Gogo Shell,,Output only displays in UI (LPS-92669),2d,Manual,,3,,,,,,"1. Start Liferay portal application server
         2. Go to Control panel > Configuration > Gogo Shell
         3. Type lb and execute the command
         4. Confirm gogo shell output display on the page
         5. Type lb | grep Liferay and execute the command
         6. Confirm gogo shell output display on the page
         7. Verify no gogo shell output display in the Liferay app server console"
Gogo Shell,,Gogo shell portlet only on main instance (LPS-88256),2e,Functional,,4,,,,,Gogoshell#GogoShellPortletOnlyOnMainInstance,"1. Start Liferay portal application server
         2. Create a new portal instance
         3. Sign in as instance admin
         4. Go to Control panel > Configuration 
         5. Verify gogo shell portlet is missing"
Gogo Shell,,Concurrent connections,2f,Manual,,4,,,,,https://issues.liferay.com/browse/LRQA-53803,"1. Create 2 users with administrator roles
         2. Concurrently sign in with both user
         3. Both users navigate to Control panel > Configuration > Gogo Shell
         4. Verify both users can concurrently use gogo shell without connections error"
Gogo Shell,,Disconnect command is not supported (LPS-83660),2g,Manual,,4,,,,,https://issues.liferay.com/browse/LRQA-53804,"1. Go to Control panel > Configuration > Gogo Shell
         2. Type “disconnect” and execute the command
         3. Verify the disconnect command is not supported."
Gogo Shell,,Test Group 3 - Cluster,,,,,,,,,,
Gogo Shell,,Gogo Shell session attributes never replicate across cluster (LPS-89651),3a,Manual,,3,,,,,,"1. Start 2 cluster nodes with session replication enabled
         2. On node 1, go to Control panel > Configuration 
         3. Verify Gogo Shell portlet is displayed
         4. Click Gogo Shell
         5. Verify gogo shell is available for use
         6. Assert no console error
         7. Repeat steps (2-6)  for node 2"
IPV6,IPV6,,,,,,,,,,,
IPV6,,Test Group 1 - IPV6 Configuration,,,,,,,,,,
IPV6,,Configure Liferay bundle to run portal on IPV6,1a,Functional,,5,,,,,IPAddress#RunPortalOnIPV6,"1. Add the following properties into portal-ext.properties
1. redirect.url.ips.allowed=127.0.0.1,SERVER_IP,0:0:0:0:0:0:0:1
2. tunnel.servlet.hosts.allowed=[0:0:0:0:0:0:0:1]
2. In application servers like Tomcat or Wildfly
1. Go to tomcat-9.0.10/bin/
1. Open “setenv.sh” or “setenv.bat” in a text editor
2. Set -Djava.net.-Djava.net.preferIPv4Stack=false
3. Save and close
2. Go to wildfly-11/bin/
1. Open “standalone.conf” or “standalone.conf.bat” in a text editor
2. Set “-Djava.net.-Djava.net.preferIPv4Stack” to false
3. Save and close
3. Start Liferay portal instance
4. Use http://[0:0:0:0:0:0:0:1]:8080 instead of http:// localhost:8080
5. Assert user access portal instance using IPV6
6. Sign in as Test
7. Assert portal URL still displayed IPV6
8. Assert successful login
9. Assert no console error"
IPV6,,Create a virtual instance with IPV6,1b,Manual,,4,,,,,https://issues.liferay.com/browse/LRQA-53787,"1. Repeat Steps 1a (1-6)
2. Go to Control Panel > Configuration > Virtual Instances
3. Create virtual instance
1. Web ID: 0:0:0:0:0:0:0:1
2. Virtual Host: 0:0:0:0:0:0:0:1
3. Mail Domain: liferay.com
4. Save
5. Assert virtual instance successfully created
6. Assert no error message or console error"
IPV6,,Configure and validate remote live staging with IPV6,1c,Manual,,4,,,,,https://issues.liferay.com/browse/LRQA-53788,"1. Add the following properties into portal-ext.properties for local server and remote server
1. redirect.url.ips.allowed=127.0.0.1,SERVER_IP,0:0:0:0:0:0:0:1
2. tunnel.servlet.hosts.allowed=[0:0:0:0:0:0:0:1]
3. tunneling.servlet.shared.secret=6162636465666768696a6b6c6d6e6f70
4. tunneling.servlet.shared.secret.hex=true
5. auth.verifier.TunnelingServletAuthVerifier.hosts.allowed=[IP Address here]
6. auth.verifier.pipeline=com.liferay.portal.security.auth.TunnelingServletAuthVerifier,com.liferay.portal.security.auth.BasicAuthHeaderAutoLogin,com.liferay.portal.security.auth.DigestAuthenticationAuthVerifier,com.liferay.portal.security.auth.ParameterAutoLogin,com.liferay.portal.security.auth.PortalSessionAuthVerifier
2. Repeat Steps 1a (2 - 6) for both local and remote servers
3. To update TunnelAuthVerfierConfiguration of your both local and remote Liferay instances:
1.  Control Panel → Configuration → System Settings → API Authentication → Tunnel Authentication
2. Click /api/liferay/do
3. In a hosts allowed field, add your ip address e.g 127.0.0.1,SERVER_IP,[IP Address here]
4. Save and restart your liferay instances
5. Sign In and activate remote staging
6. Add a page or web content article
7. Publish to remote live
8. Validate that both local and remote servers are using IPV6"
Locales,Locales,,,,,,,,,,,
Locales,,Test group 1 - Locale configurations for instances,,,,,,,,,,
Locales,,Validate default language,1a,Functional,,5,,,,,General functional testing covers,"1. Navigate to Control Panel → Configuration → Instance Settings
   2. Navigate to Miscellaneous (Localization 7.2+) tab
   3. Assert English (United States) is selected under Default Language
   4. Navigate to the guest site
   5. Navigate to Site Administration → Content → Web Content
   6. Add a web content article
   7. In the title field, assert the language selector shows en-US as the default language"
Locales,,Validate default enabled languages,1b,Functional,,5,,,,,LocalizationUsecase#MoveCurrentLanguagesToAvailable,"1. Navigate to Control Panel → Configuration → Instance Settings
   2. Navigate to Miscellaneous (Localization 7.2+) tab
   3. Assert there are languages available in the Current column"
Locales,,Validate default available languages,1c,Functional,,5,,,,,LocalizationUsecase#MoveCurrentLanguagesToAvailable,"1. Navigate to Control Panel → Configuration → Instance Settings
   2. Navigate to Miscellaneous (Localization 7.2+) tab
   3. Assert there are languages available in the Available column"
Locales,,Test group 2 - Locale configurations made by portal properties,,,,,,,,,,
Locales,,Restrict available locales,2a,Functional,,4,,,,,Locale#RestrictAvailableLocales,"1. Set locales=ca_ES,zh_CN,nl_NL,en_AU,en_GB,en_US,fi_FI,fr_FR,de_DE,it_IT,iw_IL,hu_HU,ja_JP,pt_BR,es_ES
   2. Execute testcase 1b
   3. Assert the following languages display in the Available column
   1. English (Australia)
   2. English (United Kingdom)
   3. Italian (Italy)"
Locales,,Restrict enabled locales,2b,Functional,,4,,,,,Locale#RestrictEnabledLocales,"1. Set locales.enabled=zh_CN,en_US,fr_FR,de_DE,es_ES
   2. Set locales=zh_CN-en_US,fr_FR,de_DE,es_ES,pt_BR,hu_HU
   3. Navigate to Control Panel → Configuration → Instance Settings
   4. Navigate to Miscellaneous (Localization 7.2+) tab
   5. Assert the following languages under the Current column
   1. Chinese (China)
   2. English (United States)
   3. French (France)
   4. German (Germany)
   5. Spanish (Spain)
   6. Execute testcase 1c
   7. Assert the following additional languages under the Available column
   1. Hungarian (Hungary)
   2. Portuguese (Brazil)"
Locales,,Restrict default language,2c,Functional,,5,,,,,Locale#RestrictDefaultLocale,"1. Set company.default.locale=es_ES
   2. Navigate to Control Panel → Configuration → Instance Settings
   3. Navigate to Miscellaneous (Localization 7.2+) tab
   4. Assert Spanish (Spain) is selected as the default language
   5. Navigate to the guest site
   6. Navigate to Site Administration → Content → Web Content
   7. Add a web content article
   8. Assert es-ES is displayed as the default language in the language selector"
Locales,,Test group 3 - Locale configurations for sites,,,,,,,,,,
Locales,,Default enabled locales configuration,3a,Functional,,4,,,,,Locale#ViewDefaultEnabledLocales,"1. Navigate to guest site
   2. Navigate to Site Administration → Configuration → Site Settings
   3. Navigate to Languages tab
   4. Assert Use the default language options radio is flagged
   5. Navigate to Site Administration → Content → Web Content
   6. Add a web content article
   7. Assert the locales in the language selector match the languages in testcase 1b"
Locales,,Test group 4 - Locale configurations for users,,,,,,,,,,
Locales,,User preferred languages configuration,4a,Functional,,5,,,,,Locale#ViewUserPreferredLocale,"1. Create a site with default language as Spanish
   2. Create a user with preferred language as Chinese
   3. Add the user as a member of the site
   4. Log in as the created user
   5. Navigate to the created site
   6. Assert site displays in Chinese"
Locales,,View site language without user preferred languages,4b,Functional,,5,,,,,Locale#ViewSiteLocaleWithoutUserPreferredLocale,"1. Create a site with default language as Spanish
   2. Log out
   3. View the site as a guest user
   4. Assert user displays in Spanish"
Locales,,Test group 5 - FriendlyURL localization,,,,,,,,,,
Locales,,Assert friendlyURL changes current locale,5a,Functional,,4,,,,,Locale#ViewUserPreferredLocalePersistsFriendlyURL,"1. Create a site with default language as English
   1. Add Chinese and Spanish to the Current column when configuring site languages
   2. Create a user with the preferred language of Chinese
   3. Add user as a member of the created site
   4. Log in as the created user
   5. Navigate to the site
   6. Assert site is displayed in the user’s preferred language
   7. Change the site to use es_ES as its locale through the friendlyURL
   8. Assert site displays in Spanish"
Locales,,Assert friendlyURL change to locale does not persist for user with a preferred locale,5b,Functional,,5,,,,,Locale#ViewUserPreferredLocalePersistsFriendlyURL,"1. Execute testcase 5a
   2. Remove the locale from the friendlyURL
   3. Assert site displays in the user’s preferred locale"
Locales,,Assert friendlyURL change to locale does not persist for guest user / site default locale,5c,Functional,,5,,,,,Locale#GuestUserViewSiteChangedLocalePersistsFriendlyURL,"1. Create a site with default language as English
   1. Add Spanish to the Current column when configuring site languages
   2. Log out
   3. View the site as the guest user
   4. Assert site displays in English
   5. Use a localized friendlyURL: es_ES
   6. Assert site is localized to Spanish
   7. Remove the locale from the friendlyURL
   8. Assert site displays in its default locale (English) to the guest user"
Locales,,Test group 6 - Configure available time zones,,,,,,,,,,
Locales,,View default available time zones for instances,6a,Functional,,3,,,,,Locale#ViewDefaultAvailableTimeZonesForInstancesAndUsers,"1. Navigate to Control Panel → Configuration → Instance Settings
   2. Navigate to Miscellaneous (Localization 7.2+) tab
   3. Assert list of time zones under Time Zone in Display Settings"
Locales,,View default available time zones for users,6b,Functional,,4,,,,,Locale#ViewDefaultAvailableTimeZonesForInstancesAndUsers,"1. Navigate to Control Panel → Users → Users and Organizations
   2. Edit a user
   3. Navigate to the Preferences tab
   4. Navigate to the Display Settings screen
   5. Assert list of time zones under Time Zone matches list from 6a"
Locales,,Restrict instance available time zones by portal properties,6c,Manual,,2,,,,,,"1. Set time.zones=America/Los Angeles,UTC,Asia/Tokyo
   2. Execute 6a and assert available time zones as follows:
   1. (UTC -8:00) Pacific Standard Time
   2. (UTC) Coordinated Universal Time
   3. (UTC +9:00) Japan Standard Time

"
Locales,,User available time zones restricted by instance available time zones,6d,Manual,,2,,,,,,"1. Execute 6c
   2. Navigate to Control Panel → Users → Users and Organizations
   3. Edit a user
   4. Navigate to the Preferences tab
   5. Navigate to the Display Settings screen
   6. Assert list of time zones under Time Zone matches the list from 6c"
Locales,,Test group 7 - Configure default time zones,,,,,,,,,,
Locales,,Configure instance default time zone,7a,Functional,,3,,,,,Locale#ChangesToInstanceTimeZoneDoNotPropagateToExistingUser,"1. Set company.default.time.zone=America/Los_Angeles
   2. Navigate to Control Panel → Configuration → Instance Settings
   3. Navigate to Miscellaneous (Localization 7.2+) tab
   4. Assert current selected time zone is (UTC -8:00) Pacific Standard Time"
Locales,,Created user inherits instance default time zone,7b,Functional,,4,,,,,Locale#ChangesToInstanceTimeZoneDoNotPropagateToExistingUser,"1. Execute 7a
   2. Navigate to Control Panel → Users → Users and Organizations
   3. Create a user
   4. Navigate to the Preferences tab
   5. Navigate to the Display Settings screen
   6. Assert current selected user time zone is (UTC -8:00) Pacific Standard Time"
Locales,,Changes to instance time zone do not propagate to existing users,7c,Functional,,5,,,,,Locale#ChangesToInstanceTimeZoneDoNotPropagateToExistingUser,"1. Execute testcase 7b
   2. Navigate to Control Panel → Configuration → Instance Settings
   3. Navigate to Miscellaneous (Localization 7.2+) tab
   4. Change the time zone to UTC (Coordinated Universal Time)
   5. Navigate to Control Panel → Users → Users and Organizations
   6. Edit a user
   7. Navigate to the Preferences tab
   8. Navigate to the Display Settings screen
   9. Assert current selected user time zone is (UTC -8:00) Pacific Standard Time"
LPKG,LPKG,,,,,,,,,,,
LPKG,,Test Group 1 - Deployment,,,,,,,,,,
LPKG,,Deploy LPKG (LPKG can be hot deployed),1a,Integration,-,5,,,,,LPKGDeployerCleanStartupTest,"1. Start release bundle
2. Assert all bundles are in started state in a deployed LPKG through the gogo shell"
LPKG,,Deploy upgraded LPKG,1b,Integration,-,5,,,,,"LPKGUpgradeTest (Unit)
LPKGDeployerUpgradeTest(Int)","1. Assert portal is shutdown
2. Bump up version in liferay-marketplace.properties for the LPKG
3. Redeploy LPKG (can be hot deployed)
4. Start Portal
5. Assert all bundles are in started state
6. Assert LPKG is at the updated version "
LPKG,,Deploy downgraded LPKG,1c,Integration,-,4,,,,,"LPKGDowngradeTest (Unit)
LPKGDeployerDowngradeTest (Int)","1. Assert portal is shutdown
2. Bump down version in liferay-marketplace.properties for the LPKG
3. Redeploy LPKG (can be hot deployed)
4. Start Portal
5. Assert all bundles are in started state
6. Assert LPKG is at the downgraded version"
LPKG,,Uninstall LPKG,1d,Integration,-,5,,,,,LPKGControllerVerifyTest,"1. Uninstall LPKG either by deleting the LPKG or through the gogo shell
2. Assert the following are uninstalled in the gogo shell
   1. LPKG
   2. Jar
   3. War
   4. War wrapper
3. Assert portlets are undeployed in Liferay"
LPKG,,‘restart-required’ property in liferay-marketplace.properties will log that a restart is needed in order to deploy the LPKG (defaults to true),1e,Manual,,3,,,,,,"1. Set ‘restart-required=false’ for a module in liferay-marketplace.properties
2. Assert log does that state a restart is required
3. Set ‘restart-required=true’
4. Redeploy the LPKG and assert log states a restart is needed to deploy LPKG"
LPKG,,Deploy supercedes LPKG,1f,Manual,,2,,,,,,"7. Assert portal is shutdown
8. Create a copy of an LPKG
9. Edit liferay-marketplace.properties
   1. Change title={New_App_Title}
   2. Change remote-app-id={NEW_ID}
   3. Add supersedes-remote-app-ids={Original_remote-app-id}
10. Start Portal
11. Assert LPKG App is at the updated version
12. Assert Original LPKG contains marker file "".lfr-outdated"""
LPKG,,Deploy upgraded LPKG with Restart Required,1g,Integration,,5,,,,,LPKGPersistenceVerifyUpgradeTest,"1. Go to [source_dir folder]/modules directory and run:
1. ant build-app-lpkg -verbose -Dapp.name=[appName] -Dosgi.dir=[bundles_osgi_directory] -Dliferay.home=[bundles_directory] -Dproject.dir=[portal_source_modules_directory]
2. Make a copy of lpkgs from osgi/marketplace into a different folder
3. Go to that new folder
4. Edit “liferay-marketplace.properties” and increase the version number (Note, also if restart require is set to false, change it to true.)
5. Start up liferay portal
6. Navigate to Control Panel > Configuration > Gogo Shell
7. Run “lb {appName}”
8. Assert LPKG App version numbers
9. Now, copy the edited (version increase lpkgs) and  paste them into deploy folder
10. Assert that restart is required
11. Restart the server
12. Assert that no error in the console
13. Navigate to Control Panel > Configuration > Gogo Shell
14. Run “lb {appName}”
15. Assert LPKG App version is updated
16. Assert LPKG App older version is uninstalled
17. Assert the older bundle is uninstalled (only the newer bundle is displayed)"
LPKG,,Test Group 2 - Resolving,,,,,,,,,,
LPKG,,2a - Undeploy implementation,2a,Manual,,3,,,,,,"1. Undeploy 10% of all implementation (non api bundle)
2. Assert all bundles can still be resolved"
LPKG,,Test Group 3 - Overriding,,,,,,,,,,
LPKG,,Assert lpkg overrides persist subsequent startups (Used for patches/testing),3a,Integration,-,4,,,,,"LPKGOverrideTest (Unit)
LPKGOverrideVerifySecondStartupTest (Int)","1. Startup and shutdown portal so the osgi ‘state’ folder is created
2. Create override (refer to https://github.com/liferay/liferay-portal/blob/master/tools/osgi-marketplace-override-README.markdown)
3. Take a jar from inside the LPKG e.g. com.liferay.wiki.prototypeTemplate.1.0.17.jar
4. Modify the jar by bumping the micro version
5. Strip versioning from jar file name
From
com.liferay.wiki.prototypeTemplate.1.0.17.jar
To
com.liferay.wiki.prototypeTemplate.jar
6. Put it in the osgi/marketplace/override folder (do not hot deploy)
7. Startup portal
8. Verify portal is using the newer version via gogo shell"
LPKG,,Assert LPKG overrides work on first startup,3b,Integration,-,5,,,,,LPKGOverrideVerifyCleanStartupTest,"1. Create overrides and startup portal
2. Assert override loads with no errors"
LPKG,,Revert LPKG override,3c,Integration,-,4,,,,,LPKGRevertOverrideVerifyTest,"1. Deploy LPKG override (test 2b)
2. Shutdown
3. Clear override folders and startup
4. Assert original jars are still being used"
LPKG,,Test Group 4 - Framework - Persistence,,,,,,,,,,
LPKG,,Assert stopped persistence,4a,Integration,-,4,,,,,"LPKGPersistenceTest (Unit)
LPKGPersistenceStopBundleTest (Int)
LPKGPersistenceVerifyTest (Int)","1. Deploy LPKG (has only one jar)
2. Startup portal
3. Stop the inner bundle in the gogo shell
4. Shutdown portal
5. Startup portal
6. Assert inner bundle persist resolved state (or stopped)"
LPKG,,Test Group 5 - Framework - Controller,,,,,,,,,,
LPKG,,Refresh LPKG with stopped inner jar,5a,Integration,-,4,,,,,"LPKGControllerTest (Unit)
LPKGControllerVerifyTest (Int)","1. LPKG deployed
2. Startup portal
3. Stop inner jar (will show as resolved)
4. Refresh LPKG bundle via refresh command in gogo shell
5. Assert inner jar is now active "
LPKG,,Refresh LPKG with uninstalled inner jar,5b,Integration,-,4,,,,,LPKGControllerVerifyTest (Int),"1. LPKG deployed
2. Startup portal
3. Uninstall inner jar
4. Refresh LPKG bundle via refresh command in gogo shell
5. Assert inner jar is now active "
LPKG,,Refresh LPKG with uninstalled war wrapper bundle (subsequently the war bundle),5c,Integration,-,4,,,,,LPKGControllerVerifyTest (Int),"1. LPKG deployed
2. Startup portal
3. Uninstall war wrapper bundle (and by default the war will be uninstalled)
4. Assert war wrapper bundle and war is uninstalled
5. Refresh LPKG bundle via refresh command in gogo shell
6. Assert war wrapper and war are now active"
LPKG,,Refresh war wrapper bundle with stopped war bundle,5d,Integration,-,4,,,,,LPKGControllerVerifyTest (Int),"1. LPKG deployed
2. Startup portal
3. Stop war bundle (this will not stop the war wrapper bundle)
4. Assert war bundle is inactive
5. Refresh war wrapper bundle
6. Assert war bundle is active"
LPKG,,Refresh war wrapper bundle with uninstalled war bundle,5e,Integration,-,4,,,,,LPKGControllerVerifyTest (Int),"1. LPKG deployed
2. Startup portal
3. Uninstall war bundle (this will not stop the war wrapper bundle)
4. Assert war bundle is not shown in gogo shell
5. Refresh war wrapper bundle
6. Assert war bundle is active"
LPKG,,Test Group 6 - Release,,,,,,,,,,
LPKG,,Released bundles,6a,Integration,-,5,,,,,LPKGDeployerCleanStartupTest,"1. Build LPKG that are bundled in release
   1. In app.bnd if liferay-Releng-Bundle is set to true we build it.
2. Delete osgi/modules portal static and war
3. Startup portal
4. Refer to 1a"
LPKG,,Released bundles after moving location,6b,Manual,,,,,,,LPS-90703,"1. Execute testcase 6a
2. Shut down portal
3. Move portal to a different location
4. Execute testcase 1a"
LPKG,,Test Group 7 - Aggregate LPKG (LPKG within LPKG),,,,,,,,,,
LPKG,,Deploying Aggregate LPKG,7a,Integration,-,4,,,,,"LPKGContainerTest
LPKGContainerVerifyTest","1. Deploy aggregated bundle
2. Assert all inner LPKG are installed
3. Assert aggregate is gone (the actual file)"
LPKG,,Test Group 8 - Static LPKG,,,,,,,,,,
LPKG,,Create a new static bundle,8a,Manual,,3,,,,,,"1. Create a new Static LPKG
   1. StaticLPKGResolver class in kernel provide the list of static lpkg
2. Override these two properties so you can define a new static LPKG
   1. static.lpkg.bundle.symbolic.names
   2. static.lpkg.file.names
3. Modify system-ext.properties
4. Deploy into marketplace osgi folder
5. Assert in gogo shell
6. Assert on startup the log below in the URL
   1.  Static LPKG that are deployed will be displayed in the stacktrace before the ‘Passed integrity check’
   2.  https://gist.github.com/alee8888/dbef588781608e55665eb7223f0975e2"
LPKG,,Test Group 9 - Core vs Non-Core LPKGs,,,,,,,,,,
LPKG,,Deploy Only Core LPKG,9a,Integration,-,5,,,,,ant > lpkg-base-jdk8,"1. Build only Core apps as LPKGs (ant build-app-lpkg-base)
   1. Check ""Liferay-Releng-Suite"" property
2. Delete the following directories
   1. osgi/deploy
   2. osgi/modules
   3. osgi/portal
   4. osgi/static
   5. osgi/war
3. Start portal and assert clean startup"
LPKG,,Hot Deploy Non-Core LPKGs,9b,Manual,,5,,,,,https://issues.liferay.com/browse/LRQA-53836,"1. Build all apps as LPKGs
2. Remove non-Core LPKGs from the portal osgi directory
3. Add ""restart-required=false"" to all the non-Core LPKGs in liferay-marketplace.properties
4. Delete osgi/modules (dangling jars)
5. Start portal
6. Hot Deploy all non-Core LPKGs
7. Assert no deployment errors
Additional Scenarios/TODO
Anyone should feel free to add suggestions to this list"
Mobile Device Rules,Mobile Device Rules,,,,,,,,,,,
Mobile Device Rules,,Test Group 1 - Basic MDR UI,,,,,,,,,,
Mobile Device Rules,,Assert user can add MDR Family,1a,Functional,,5,,,,,MobileDeviceFamilies#AssertMobileDeviceRuleActionOnSitePage,"1. Add MDR Family
2. Add name
3. Add description
4. Assert creation"
Mobile Device Rules,,Assert user can edit MDR Family,1b,Manual,,5,,,,,,"1. Testcase 1a
2. Change name
3. Change description
4. Assert changes"
Mobile Device Rules,,Assert user can delete MDR Family,1c,Manual,,4,,,,,,"1. Testcase 1a - 
2. Delete MDR
3. Assert deletion
4. Recycle"
Mobile Device Rules,,Assert user can add MDF Classification Rule,1d,Functional,,5,,,,,MobileDeviceFamilies#AssertMobileDeviceRuleActionOnSitePage,"1. Testcase 1 a
2. Add Classification rule
3. View rule"
Mobile Device Rules,,Assert user can edit MDF Classification Rule,1e,Manual,,5,,,,,,"1. Testcase 1d
2. Edit rule
3. Assert changes"
Mobile Device Rules,,Assert user can delete MDF Classification Rule,1f,Manual,,4,,,,,,"1. Testcase 1d
2. Delete rule
3. Assert deletion"
Mobile Device Rules,,Test Group 2 - MDR Configuration on Site Page,,,,,,,,,,
Mobile Device Rules,,Verify MDR Action Redirect to Site,2a,Functional,,4,,,,,MobileDeviceFamilies#AssertMobileDeviceRuleActionOnSitePage,"1. Test case 1d
2. Apply Redirect to Site config
3. Use mobile device and navigate to configured page"
Mobile Device Rules,,Verify MDR Action Layout Template Modification,2b,Manual,,,,,,,,1. Execute 2a with Layout Template Modification
Mobile Device Rules,,Verify MDR Action Redirect to URL,2c,Manual,,,,,,,,2. Execute 2a with Redirect to URL
Mobile Device Rules,,Verify MDR Action Theme Modification,2d,Manual,,,,,,,,3. Execute 2a with Theme Modification
Mobile Device Rules,,Verify MDR Rule applied to single page,2e,Manual,,,,,,,,"1. Test case 1d
2. Create two public pages
3. Apply rule to one page
4. Use mobile device and navigate to configured page
5. Assert rule applied
6. Navigate to other page
7. Assert rule is not applied"
Mobile Device Rules,,Verify Multiple MDR Actions applied on page,2f,Manual,,,,,,,,"1. Test case 1d
2. Layout Template Mod
3. Theme Mod
4. Verify Layout changed
5. Verify Theme changed"
Mobile Device Rules,,Verify MDR Action applied to all public pages,2g,Manual,,,,,,,,"1. Test case 1d
2. Apply rule to all pages (3 pages)
3. Assert all pages"
Mobile Device Rules,,Verify MDR Action applied to all public pages minus select page,2h,Manual,,,,,,,,"1. Test case 1d
2. Apply rule to all pages (3 pages)
3. Configure one pages to not inherit MDR rule/action
4. Assert pages with expected behavior"
Mobile Device Rules,,Verify MDR Action Prioritization,2i,Manual,,,,,,,,"1. Test case 1d
2. Apply on a page
3. Add two actions 
4. Assert first created action is administered
5. Assign higher priority to second created action 
6. Assert second created action is administered"
Mobile Device Rules,,Test Group 3 - Export/Import,,,,,,,,,,
Mobile Device Rules,,Export Import Mobile Device Rule,3a,Manual,,,,,,,,"1. Testcase 1d
2. Export Mobile Device Rule
3. Import Mobile Device Rule to new site
4. Configure page with imported rule
5. Assert mobile device rule on page"
Mobile Device Rules,,Test Group 4 - Device Detection,,,,,,,,,,
Mobile Device Rules,,LMDD - Verify Device iPhone,4a,Manual,,,,,,,"1. Go to the Left Product Menu > Content & Data > Web Content > Structures
2.  Add a new dummy structure with e.g. one text field
3. Add a Template associated to such structure: click on the top-left item ""Device"", under ""General Variables"", this will print: ${device}. On the right-side menu, make the template not cacheable
4. Save and create a web content from the structure from step 3, publish it
5. Go to the Welcome page and deploy a Web Content Display Widget onto the page
6. Configure the widget to display the web content from step 5
7. Visit the page with a mobile device, e.g. an iPhone or Android phone","1. Access site page with iPhone header (e.g. Mozilla/5.0 (iPhone; CPU OS 11_0 like Mac OS X) AppleWebKit/604.1.25 (KHTML, like Gecko) Version/11.0 Mobile/15A372 Safari/604.1)
2. Assert value of getScreenPhysicalSize()
3. Assert value of getScreenResolution()
4. Assert value of getOS()"
Mobile Device Rules,,LMDD - Verify Device Android,4b,Manual,,,,,,,"1. Go to the Left Product Menu > Content & Data > Web Content > Structures
2.  Add a new dummy structure with e.g. one text field
3. Add a Template associated to such structure: click on the top-left item ""Device"", under ""General Variables"", this will print: ${device}. On the right-side menu, make the template not cacheable
4. Save and create a web content from the structure from step 3, publish it
5. Go to the Welcome page and deploy a Web Content Display Widget onto the page
6. Configure the widget to display the web content from step 5
7. Visit the page with a mobile device, e.g. an iPhone or Android phone","1. Access site page with Android phone header (e.g. Mozilla/5.0 (Linux; Android 4.4.2; XMP-6250 Build/HAWK) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/30.0.0.0 Safari/537.36 ADAPI/2.0)
2. Assert value of getScreenPhysicalSize()
3. Assert value of getScreenResolution()
4. Assert value of getOS()"
Mobile Device Rules,,LMDD - Device Android Tablet,4c,Manual,,,,,,,"1. Go to the Left Product Menu > Content & Data > Web Content > Structures
2.  Add a new dummy structure with e.g. one text field
3. Add a Template associated to such structure: click on the top-left item ""Device"", under ""General Variables"", this will print: ${device}. On the right-side menu, make the template not cacheable
4. Save and create a web content from the structure from step 3, publish it
5. Go to the Welcome page and deploy a Web Content Display Widget onto the page
6. Configure the widget to display the web content from step 5
7. Visit the page with a mobile device, e.g. an iPhone or Android phone","1. Access site page with Android Tablet header (e.g. Mozilla/5.0 (Linux; Android 6.0; vivo 1713 Build/MRA58K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/53.0.2785.124 Mobile Safari/537.36)
2. Assert value of getScreenPhysicalSize()
3. Assert value of getScreenResolution()
4. Assert value of getOS()

"
Mobile Device Rules,,LMDD - Verify Device Windows PC,4d,Manual,,,,,,,"1. Go to the Left Product Menu > Content & Data > Web Content > Structures
2.  Add a new dummy structure with e.g. one text field
3. Add a Template associated to such structure: click on the top-left item ""Device"", under ""General Variables"", this will print: ${device}. On the right-side menu, make the template not cacheable
4. Save and create a web content from the structure from step 3, publish it
5. Go to the Welcome page and deploy a Web Content Display Widget onto the page
6. Configure the widget to display the web content from step 5
7. Visit the page with a mobile device, e.g. an iPhone or Android phone","1. Access site page with Device PC header (e.g. Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36)
2. Assert value of getScreenResolution()
3. Assert value of getOS()"
Mobile Device Rules,,Test Group 5 - Enterprise vs Lite Data Sets,,,,,,,,,,
Mobile Device Rules,,LMDD - Deploy LMDD Enterprise over LMDD Lite without uninstall/stopping Lite modules,5a,Manual,,,,,,,,"1. Deploy LMDD Lite
2. Add a mobile device family
3. Create a classification rule for the mobile device family
4. Assert list of available Operating Systems
5. Save the classification rule
6. Deploy LMDD Enterprise
7. Assert mobile device families have been preserved
8. Assert classification rule(s) have been preserved
9. Create a classification rule for the mobile device family
10. Assert list of available Operating Systems has been updated to include enterprise-only Operating Systems as well"
Mobile Device Rules,,LMDD - Deploy LMDD Enterprise over LMDD Lite after stopping/uninstalling Lite modules,5b,Manual,,,,,,,,"1. Deploy LMDD Lite
2. Add a mobile device family
3. Create a classification rule for the mobile device family
4. Stop and/or uninstall LMDD Lite
5. Deploy LMDD Enterprise
6. Assert mobile device families have been preserved
7. Assert classification rule(s) have been preserved
8. Create a new classification rule for the mobile device family
9. Assert list of available Operating Systems has been updated to include enterprise-only Operating Systems as well"
Mobile Device Rules,,LMDD - Stop/uninstall LMDD Enterprise when LMDD Lite is also available when enterprise Operating System is in use,5c,Manual,,3,,,,,https://issues.liferay.com/browse/LPS-86453,"1. Deploy LMDD Lite
2. Deploy LMDD Enterprise
3. Add a mobile device family
4. Add a classification rule
   1. Classification rule should use an enterprise Operating System
5. Stop/uninstall LMDD Enterprise
6. Enterprise properties can no longer be used.  For instance, device.getPointingMethod should no longer return a value. And thus rules matching to this shouldn’t work.  I believe hasQwertyKeyboard should also return false (e.g. it’s not available).
7. The enterprise data should be unloaded.
8. The lite data should be loaded only[a]"
Mobile Device Rules,,LMDD - Stop/uninstall LMDD Enterprise when LMDD is also available when lite Operating System is in use,5d,Manual,,,,,,,,"1. Deploy LMDD Lite
2. Deploy LMDD Enterprise
3. Add a mobile device family
4. Add a classification rule
   1. Classification rule should use an Operating System common to both Lite and Enterprise
5. Stop/uninstall LMDD Enterprise
6. Assert mobile device family is preserved
7. Assert mobile device family classification rule is preserved

"
Portal Cache,Portal Cache,,,,,,,,,,,
Portal Cache,,Test Group 1 - Portal Entity Cache Implement,,,,,,,,,,
Portal Cache,,Test notify entity portal cache removed,1a,Unit,-,5,,,,,EntityCacheImplTest#testNotifyPortalCacheRemovedPortalCacheName,"1. Activate entity cache
2. Assert portal cache present
3. Assert portal cache name
4. Notify portal cache removed 
5. Confirm portal caches is empty"
Portal Cache,,Test put and get null model result,1b,Unit,-,3,,,,,EntityCacheImplTest#testPutAndGetNullModel,"1. Set serialized to false
2. Put model in result
3. Get result
4. Assert model is returned by the result
5. Repeat test with serialized=true"
Portal Cache,,Test Group 2 - Portal Finder Cache Implement,,,,,,,,,,
Portal Cache,,Test notify finder portal removed portal cache name,2a,Unit,-,5,,,,,FinderCacheImplTest#testNotifyPortalCacheRemovedPortalCacheName,"1. Activate finder cache
2. Execute 1a Steps 2-5"
Portal Cache,,Test put empty list of invalid,2b,Unit,-,4,,,,,FinderCacheImplTest#testPutEmptyListInvalid,"1. Activate finder cache without serialized MultiVMPool[a]
2. Add result with KEY1 and empty list
3. Search for a result with KEY2
4. Assert that no result found
5. Repeat Steps 2-4 with finder cache with serialized MultiVMPool"
Portal Cache,,Test put empty list of valid,2c,Unit,-,4,,,,,FinderCacheImplTest#testPutEmptyListValid,"1. Execute 2b Steps 1-2 
2. Search for a result with KEY1
3. Assert that result found
4. Repeat Steps 1-3 with finder cache with serialized MultiVMPool"
Portal Cache,,Test keys collide,2d,Unit,-,3,,,,,FinderCacheImplTest#testTestKeysCollide,"1. Activate finder cache 
2. Generate cache KEY1 and KEY2
3. Get cache KEY1 and KEY2
4. Assert cache keys generator KEY1 and KEY2"
Portal Cache,,Test portal cache threshold,2e,Unit,-,3,,,,,FinderCacheImplTest#testThreshold,"1. Set threshold property value
2. Activate finder cache without serialized MultiVmPool
3. Add values to an array list
4. Search for a result with KEY1
5. Assert that result found
6. Repeat Steps 3-4
7. Assert that no result found"
Portal Cache,,Test Group 3 - Portal Cache API,,,,,,,,,,
Portal Cache,,Test portal cache serializable object wrapper,3a,Unit,-,5,,,,,SerializableObjectWrapperTest.java,1. com.liferay.portal.cache.io.SerializableObjectWrapper
Portal Cache,,Test Group 4 - Portal Cache Ehcache Implement,,,,,,,,,,
Portal Cache,,Ehcache portal cache - cache listener,4a,Unit,-,5,,,,,EhcachePortalCacheTest#testCacheListener,"1. Register local portal cache listener
2. Put portal cache KEY2 and VALUE2
3. Assert action count for local portal cache listener
4. Assert key value for local portal cache listener
5. Reset local portal cache listener key and value
6. Repeat Steps 3 - 5 for default portal cache listener
7. Repeat Steps 3 - 5 for default portal cache replicator
8. Add remote portal cache listener
9. Repeat Steps 1 - 5 for remote portal cache listener
10. Add portal cache listener scope all
11. Repeat Steps 1 - 5 for portal cache listener scope to all
12. Unregister portal cache listener
13. Put portal cache KEY1 and VALUE2
14. Repeat Steps 3 - 5 for local portal cache listener
15. Repeat Steps 3 - 5 for default portal cache replicator
16. Repeat Steps 3 - 5 for remoter portal cache listener"
Portal Cache,,Ehcache portal cache - get ehcache,4b,Unit,-,5,,,,,EhcachePortalCacheTest#testGetEhcache,"1. Seach ehcache
2. Assert the same results are found
"
Portal Cache,,Ehcache portal cache - get keys,4c,Unit,-,5,,,,,EhcachePortalCacheTest#testGetKeys,"1. Search portal cache keys
2. Assert result found for KEY1
3. Assert no result found for KEY2"
Portal Cache,,Ehcache portal cache - get name,4d,Unit,-,5,,,,,EhcachePortalCacheTest#testGetName,"1. Search portal cache name
2. Assert portal cache name is found"
Portal Cache,,Ehcache portal cache - put,4e,Unit,-,5,,,,,EhcachePortalCacheTest#testPut,"1. Add KEY1 and value  into a cache
2. Search for KEY1 value
3. Assert result found
4. Search for KEY2 value
5. Assert no result found
6. Add KEY2’s value 
7. Repeat Steps 2 - 4
8. Assert result found"
Portal Cache,,Ehcache portal cache - remove,4f,Unit,-,5,,,,,EhcachePortalCacheTest#testRemove,"1. Remove portal cache key1’s value1
2. Search for KEY1 value
3. Assert no result found
4. Search for KEY2 value
5. Assert no result found"
Portal Cache,,Ehcache portal cache - replace,4g,Unit,-,5,,,,,EhcachePortalCacheTest#testReplace,"1. Replace KEY_1’s VALUE_1 with VALUE_2
2. Assert KEY_1 has a value of VALUE_2
3. Assert KEY_2  has no value
4. Replace KEY_2 null value  with VALUE_2
5. Assert KEY_2 has a value of VALUE_2"
Portal Cache,,Test Group 5 - Portal Cache Test Util - MVCCPortal Cache,,,,,,,,,,
Portal Cache,,Test MVCCPortal cache - for hidden bridge,5a,Unit,-,4,,,,,MVCCPortalCacheTest#testForHiddenBridge,"1. Set serializable key = _KEY_1
2. Set value to _VERSION_1
3. Add key, value, and time to live
4. Search for key
5. Assert result found"
Portal Cache,,Test MVCCPortal cache - MVCCCache with advice,5b,Unit,-,4,,,,,MVCCPortalCacheTest#testMCCCacheWithAdvice,"1. Search for null _KEY_1 and _KEY_2
2. Assert no results found
3. Define thread
4. Add _KEY_1 and _VERSION_1
5. Start thread1
6. Wait until block thread count
7. Search for queue long
8. Assert thread count is 1
9. Repeat Steps 3 - 8 for thread2
10. Unblock/release cache
11. Join thread1 and thread2
12. Search for _KEY_1 and _KEY_2
13. Assert _KEY_1 result found
14. Assert _KEY_2 no result found"
Portal Cache,,Test MVCCPortal cache - MVCCCache without TTL (time to live),5c,Unit,-,3,,,,,MVCCPortalCacheTest#testMCCCacheWithoutTTL,"1. Set time to live to false
2. Check if a cache is not live
3. Assert false
4. If cache is live, add key, version, and time to live
5. Assert true
6. Search for keys version
7. Assert key1’s result found
8. Assert key2’s no result found

"
Portal Cache,,Test MVCCPortal cache - MVCCCache with TTL (time to live),5d,Unit,-,3,,,,,MVCCPortalCacheTest#testMCCCacheWithTTL,1. Repeat 1 - 8 for setting time to live to  true
Portal Cache,,Test Group 6 - Portal Cache Test Util - Transactional Portal Cache,,,,,,,,,,
Portal Cache,,Test transactional portal cache - concurrent transaction for MVCCPortal cache,6a,Unit,-,4,,,,,TransactionalPortalCacheTest#testConcurrentTransactionForMVCCPortalCache,"1. Set enable transactional cache to true
2. Set  read-only to true
3. Add KEY_1 with VALUE_1, and KEY_2 with VALUE_2
4. Assert cache listener and replicator keys and values
5. Assert cache listener and replicator action counts
6. Reset cache listener and replicator
7. Repeat Steps 2 - 5 with keys values set to null
8. Exchange KEY_1 value to VALUE_2 and KEY_2 value to VALUE_1
9. Repeat Steps 4 - 6 for updated keys values
10. Set  read-only to false
11. Repeat Steps 8 - 9"
Portal Cache,,Test transactional portal cache - concurrent transaction for  non MVCCPortal cache,6b,Unit,-,5,,,,,TransactionalPortalCacheTest#testConcurrentTransactionForNonmvccPortalCache,1. Execute  6a with concurrent transaction for non MVCCPortal cache
Portal Cache,,Test transactional portal cache - miscellaneous,6c,Unit,-,3,,,,,TransactionalPortalCacheTest#testMisc,"1. Set transactional cache to true
2. Start transactional portal cache helper
3. Add KEY_1 and its VALUE_1
4. Remove all transactional portal cache
5. Commit transactional portal cache helper
6. Set transactional cache to false
7. Create transactional life cycle listener with a null key and a null value
8. Commit transactional life cycle listener
9. Rollback transactional life cycle listener"
Portal Cache,,Test transactional portal cache - none transactional cache,6d,Unit,-,3,,,,,TransactionalPortalCacheTest#testNoneTransactionalCache,"1. Set transactional cache to false
2. Set portal cache value to true
3. Assert transactional portal cache helper is disabled
4. Set transactional cache to true
5. Set portal cache value to false
6. Assert transactional portal cache helper is disabled"
Portal Cache,,Test transactional portal cache - transactional cache with parameter validation,6e,Unit,-,3,,,,,TransactionalPortalCacheTest#testTransactionalCacheWithParameterValidation,"1. Set transactional cache to true
2. Set portal cache value to true
3. Add portal cache KEY_1, VALUE_1
4. Search for  key
5. Assert result found
6. Repeat Steps 3 - 4 with  null key
7. Search with null key
8. Assert error message “key is null”
9. Repeat Steps 3 - 5 with KEY_1, VALUE_2
10. Repeat Steps 3 - 4 with null value
11. Search with null value
12. Assert error message “value is null”
13. Repeat Steps 3 - 4 with KEY_1, VALUE_1, -1
14. Assert error message “Time to live is negative”
15. Repeat Steps 6 - 8 with null key is  removed"
Portal Cache,,Test transactional portal cache - transactional portal cache helper enabled,6f,Unit,-,3,,,,,TransactionalPortalCacheTest#testTransactionalPortalCachehelperEnabled,"1. Set transactional cache to false
2. Assert transactional portal cache helper is disabled
3. Set transactional cache to true
4. Start transactional portal cache helper
5. Assert transactional portal cache helper is enabled"
Portal Cache,,Test transactional portal cache - transactional portal cache with real MVCCPortal cache,6g,Unit,-,3,,,,,TransactionalPortalCacheTest#testTransactionalPortalCacheWithRealMVCCPortalCache,"1.  Set transactional cache to true
2. Start transactional portal cache helper
3. Add KEY_1 to transactional portal cache
4. Commit false transactional portal cache helper
5. Search for KEY_1
6. Assert result is found
7. Repeat Steps 2 - 6 for null model"
Portal Cache,,Test transactional portal cache - transaction lifecycle listener enabled with barrier,6h,Unit,-,3,,,,,TransactionalPortalCacheTest#testTransactionLifecycleListenerEnabledWithBarrier,"1.  Set enable transactional cache to true
2. Search transaction stack size
3. Assert zero value “0” (propagation is not supported)
4. Start parent transaction
5. Create transaction life cycle listener
6. Assert one value  “1”
7. Create child transaction
8. Repeat Steps 2 - 6 (propagation is nested)
9. Create grandchild transaction
10. Repeat Steps 2 - 6 (propagation is nested)"
Portal Cache,,Test transactional portal cache - transaction lifecycle listener enabled with exist transaction,6i,Unit,-,3,,,,,TransactionalPortalCacheTest#testTransactionLifecycleListenerEnabledWithExistTransaction,"1. Set enable transactional cache to true
2. Create transaction lifecycle listener
3. Search transaction stack size
4. Assert zero value “0”
5. Commit transaction lifecycle listener
6. Repeat Steps 3 - 4
7. Rollback transaction lifecycle listener
8. Repeat Steps 3 - 4"
Portal Cache,,Test transactional portal cache - transaction lifecycle listener enabled without barrier,6j,Unit,-,3,,,,,TransactionalPortalCacheTest#testTransactionLifecycleListenerEnabledWithoutBarrier,"1. Set enable transactional cache to true
2. Set PROPAGTION_REQUIRED to 0
3. Assert propagation is required 
4. Set PROPAGTION_SUPPORT to 1
5. Assert propagation is supported
6. Set PROPAGTION_MANDATORY  to 2
7. Assert propagation is mandatory
8. Set PROPAGTION_REQUIRED_NEW to 3
9. Assert new propagation is required"
Portal Cache,,Test Group 7 - Portal Cache Configuration,,,,,,,,,,
Portal Cache,,Portal cache - disabled cache table mapper tables (no test coverage),7a,Manual,,3,,,,,"1. Download and install  VisualVM
2. After visualVM installed, go to Tools > Plugins 
3. Click Available Plugins, look for MBeans and install
4. When your server started, start visualVM
5. Click on the server name, for example, tomcat
6. Click MBeans
7. Expand net.sf.ehcache > CacheConfiguration > MULTI_VM... and SINGLE_VM…
8. Go through the properties to verify your cache configuration override ","1. Disable table mapper cache by adding this property into portal-ext.properties
1. table.mapper.cacheless.mapping.table.names
2. Append your mapping table name to the list (e.g  see portal.impl.jar/portal.properties)
3. Restart the Liferay portal instance to delete the table mapper cache
4. Confirm unwanted table mapper cache is disabled[b]"
Portal Cache,,Portal cache - modify defaultCache configuration,7b,Manual,,3,,,,,"1. Download and install  VisualVM
2. After visualVM installed, go to Tools > Plugins 
3. Click Available Plugins, look for MBeans and install
4. When your server started, start visualVM
5. Click on the server name, for example, tomcat
6. Click MBeans
7. Expand net.sf.ehcache > CacheConfiguration > MULTI_VM... and SINGLE_VM…
8. Go through the properties to verify your cache configuration override ","1. Create a file, let call it “override-liferay-multi-vm.xml and override-liferay-single-vm.xml” 
2. Put the file in app server liferay directory, for example 
1. [Liferay Home]/tomcat-9.0.10/webapps/ROOT/WEB-INF/classes
3. Copy all content from “liferay-multi-vm.xml and liferay-single-vm.xml” 
4. Replace “override-liferay-multi-vm.xml and override-liferay-single-vm.xml”  content respectively with content from “liferay-multi-vm.xml and  liferay-single-vm.xml” to preserve default setting
5. Modify defaultCache cache configuration, for example, change
1. overflow to disk to true
2. maxElementsInMemory to any number
6. Save the file
7. Add these properties to portal-ext.properties and point them to a new file
1.  ehcache.single.vm.config.location=/override-liferay-multi-vm.xml
2.  ehcache.multi.vm.config.location=/override-liferay-single-vm.xml
8. Start the server
9. Assert no errors when the server start up


Related article: (Cache configuration)


Note: There a limitation that a developer should know. For a single vm cache, it allows you to store something which can not be serialized. In this case, if you enable overflow to disk, there will be a problem and here is an example of an  error: Error when enable overflow to disk"
Portal Cache,,Portal cache - modify cache configuration file,7c,Manual,,3,,,,,"1. Download and install  VisualVM
2. After visualVM installed, go to Tools > Plugins 
3. Click Available Plugins, look for MBeans and install
4. When your server started, start visualVM
5. Click on the server name, for example, tomcat
6. Click MBeans
7. Expand net.sf.ehcache > CacheConfiguration > MULTI_VM... and SINGLE_VM…
8. Go through the properties to verify your cache configuration override ","1. Repeat all steps in 7b to modify cache instead of defaultCache
2. Modify cache, see an example from step 5 in 7b
3. Continue with rest of the steps from 7b"
Portal Cache,,Portal cache - cache configuration with a module,7d,Manual,,4,,,,,"https://issues.liferay.com/browse/LRQA-53786
1. Download and install  VisualVM
2. After visualVM installed, go to Tools > Plugins 
3. Click Available Plugins, look for MBeans and install
4. When your server started, start visualVM
5. Click on the server name, for example, tomcat
6. Click MBeans
7. Expand net.sf.ehcache > CacheConfiguration > MULTI_VM... and SINGLE_VM…
8. Go through the properties to verify your cache configuration override ","1. Create a configuration file call “module-single-vm.xml” and “module-multi-vm.xml” 
2. Add “module-single-vm.xml” and “module-multi-vm.xml” into MODULE_ROOT/src/main/resources/META-INF
3. For example, in blogs module >  modules/apps/blogs/blogs-service/src/main/resources/META-INF
1. Add these files “module-single-vm.xml” and “module-multi-vm.xml
2. Modified property from the default liferay-multi-vm.xml or liferay-single-vm.xml and put it into files 3a based on the module, e.g
                <ehcache
        dynamicConfig=""true""
        monitoring=""off""
        name=""module-multi-vm""
        updateCheck=""false""
        xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
        xsi:noNamespaceSchemaLocation=""http://www.ehcache.org/ehcache.xsd""
>
        <cache
                eternal=""false""
                maxElementsInMemory=""1000""
                name=""com.liferay.blogs""
                overflowToDisk=""true""
                timeToIdleSeconds=""600""
        >
                        </cache>
</ehcache>
4. Save the file
5. Deploy the module
6. Assert no console errors"
Portal Cache,,Portal cache - serialization test,7e,Manual,,3,,,,,"1. Download and install  VisualVM
2. After visualVM installed, go to Tools > Plugins 
3. Click Available Plugins, look for MBeans and install
4. When your server started, start visualVM
5. Click on the server name, for example, tomcat
6. Click MBeans
7. Expand net.sf.ehcache > CacheConfiguration > MULTI_VM... and SINGLE_VM…
8. Go through the properties to verify your cache configuration override ","1. Repeat all steps in 7d to Enable overflowToDisk=""true"" in xml to test serialization
2. Assert OverflowToDisk property is set to true in a visualVM "
Portlet 3,Portlet 3,,,,,,,,,,,
Portlet 3,,Test Group 1- Usage ,,,,,,,,,,
Portlet 3,,WAR/WAB with portlet.xml/web.xml (handled by TCK),1a,Unit,-,,,,,,,"1. Deploy a WAR/WAB with portlet.xml/web.xml
2. Assert portlet is deployed and working with no errors"
Portlet 3,,WAR/WAB with pure annotations (implemented through CDI),1b,Unit,-,,,,,,,"1. Deploy a WAR/WAB with
   1. Pure annotations
   2. Empty beans.xml (required)
2. Assert portlet is deployed and working with no errors"
Portlet 3,,WAR/WAB with hybrid portlet.xml + annotations (implemented through CD,1c,Unit,-,,,,,,,"1. Deploy a WAR/WAB with
   1. Hybrid portlet.xml + annotations
   2. Empty beans.xml (required)
2. Assert portlet is deployed and working with no errors"
Portlet 3,,OSGi bundle with Declarative Services (Skinny WAR / no portlet.xml/no servlet.xml),1d,Manual,-,,,,,,https://issues.liferay.com/browse/LRQA-42958,"1. Assert that Portlet metadata generation is correct[a][b]
2. Assert portlet is deployed and working with no errors"
Portlet 3,,Test Group 2 - Deployment,,,,,,,,,,
Portlet 3,,WAR/WAB with portlet.xml (portlet.xml/servlet.xml) - handled by TCK,2a,Unit,-,,,,,,,"1. Deploy a WAR/WAB with portlet.xml/web.xml
2. Assert portlet is deployed with no errors
3. Assert no exceptions in console"
Portlet 3,,WAR/WAB with pure annotations (Implemented through CDI),2b,Unit,-,,,,,,,"1. Deploy a WAR/WAB with
   1. Pure annotations
   2. Empty beans.xml (required)
2. Assert portlet is deployed with no errors
3. Assert no exceptions in console"
Portlet 3,,WAR/WAB with hybrid portlet.xml + annotations (Implemented through CDI),2c,Unit,-,,,,,,,"1. Deploy a WAR/WAB with
   1. Hybrid portlet.xml + annotations
   2. Empty beans.xml (required)
2. Assert portlet is deployed with no errors
3. Assert no exceptions in console"
Portlet 3,,OSGi bundle with Declarative Services,2d,Unit,-,,,,,,,"1. Deploy portlet assembled using declarative services (LPS-75948)
2. Assert Portlet is deployed with no errors
3. Assert no exceptions in console"
Portlet 3,,OSGi bundle service with a low level OSGI API,2e,Unit,-,,,,,,,"1. Publish a Portlet service using low level OSGi API (completely missing)
2. Assert service is working with no errors
3. Assert no exceptions in console"
Portlet 3,,OSGi bundle with CDI (no test coverage at all currently),2f,Manual,-,5,,,,,https://issues.liferay.com/browse/LRQA-42958,"1. Deploy portlet jar assembled using CDI 
2. Assert Portlet is deployed with no errors"
Rolling Restarts,Rolling Restarts,,,,,,,,,,,
Rolling Restarts,,Test Group 1 - Fix Packs,,,,,,,,,,
Rolling Restarts,,Apply fix pack (LRQA-29630),1a,Functional,-,5,,,,,RollingRestartEE#InstallFixPackWithMultipleClusters,"1. Start a cluster of 3 Liferay servers - referred to as cluster1, cluster2, and cluster3.
   1. Start all servers on DXP GA1.
   2. Verify clustering is working on all 3 servers.
2. Take down cluster2 and apply the latest FP.
3. Restart cluster2 and assert the following:
   1. Test clustering still works between cluster2 and cluster1/cluster3 .
      1. Add portlet/content on cluster2 and assert it shows up in cluster1/cluster3.
   2. Assert a bug fix/feature exists on cluster 2 and is missing on cluster1/cluster3.[a]
4. Take down cluster1 and apply the latest FP.
5. Restart cluster1 and assert the following:
   1. Test clustering still works between cluster1 and cluster2/cluster3 .
      1. Add portlet/content on cluster1 and assert it shows up in cluster2/cluster3.
   2. Assert a bug fix/feature exists on cluster1/cluster2 and is missing on cluster3.[b]
6. Take down cluster3 and apply the latest FP.
7. Restart cluster3 and assert the following:
   1. Test clustering still works between cluster1, cluster2, and cluster3.
      1. Add portlet/content on cluster3 and assert it shows up in cluster1/cluster2.
   2. Assert a bug fix/feature exists on cluster1, cluster2, and cluster3.[c]"
Rolling Restarts,,Apply fix pack with database changes,1b,Manual,50,4,,,,,https://issues.liferay.com/browse/LRQA-42993,
Rolling Restarts,,Apply fix pack that update database indices,1c,Manual,50,3,,,,,https://issues.liferay.com/browse/LRQA-42994,
Rolling Restarts,,Apply fix pack with new OSGI configuration object (LRQA-29768),1d,Functional,50,4,,,,,RollingRestartEE#InstallFixPackWithNewOSGIConfiguration,"1. For this scenario, let's use the SPAConfiguration module which was changed between SP1 and FP8.
   1. In FP8, the request timeout and user notification timeout fields were added in System Settings. Set user notification timeout to a very low number to cause the yellow ""sorry this is taking too long"" alert to show up.
2. Start a cluster of 3 Liferay Servers connect them to standalone Elasticsearch cluster
   1. Start all servers on DXP SP1
   2. Verify clustering is working on both servers
3. Shut down a server and add a duplicate configuration file with the same contents, but different pid and name
4. Restart that server
5. Assert the configuration shows up in System Settings
6. Verify basic portal functionality
7. Verify that other nodes don't crash"
Rolling Restarts,,Revert fix pack,1e,Functional,-,5,,,,,RollingRestartEE#InstallFixPackWithMultipleClusters,"1. Start a cluster of 3 Liferay Servers - referred to as cluster1, cluster2, and cluster3.
   1. Start all servers on DXP GA1 with the latest FP.
   2. Verify clustering is working on all 3 servers.
2. Take down cluster2 and revert the FP.
3. Restart cluster2 and assert the following:
   1. Test clustering still works between cluster2 and cluster1/cluster3 .
      1. Add portlet/content on cluster2 and assert it shows up in cluster1/cluster3.
   2. Assert a bug fix/feature exists on cluster1/cluster3 and is missing on cluster 2.[d]
4. Take down cluster1 and revert the FP.[e]
5. Restart cluster1 and assert the following:
   1. Test clustering still works between cluster1 and cluster2/cluster3 .
      1. Add portlet/content on cluster1 and assert it shows up in cluster2/cluster3.
   2. Assert a bug fix/feature exists on cluster3 and is missing on cluster1/cluster2.[f]
6. Take down cluster3 and revert the FP.[g]
7. Restart cluster3 and assert the following:
   1. Test clustering still works between cluster1, cluster2, and cluster3.
      1. Add portlet/content on cluster3 and assert it shows up in cluster1/cluster2.
   2. Assert a bug fix/feature is missing on cluster1, cluster2, and cluster3.[h]"
Rolling Restarts,,Test Group 2 - Deployment,,,,,,,,,,
Rolling Restarts,,Deployment of new plugins/modules with database changes,2a,Manual,45,4,,,,,https://issues.liferay.com/browse/LRQA-42997,"1. Start a cluster of 3 Liferay Servers - referred to as cluster1, cluster2, and cluster3.
   1. Start all servers on DXP GA1 + latest FP.
   2. Verify clustering is working on all 3 servers.
2. Take down cluster2 and deploy 2 portlets that causes database changes[i][j][k][l].
3. Restart cluster2 and assert the following:
   1. Test clustering still works between cluster2 and cluster1/cluster3 .
      1. Add portlet/content on cluster2 and assert it shows up in cluster1/cluster3.
   2. Assert new portlet only exists on cluster2 and not on cluster1/cluster3.
4. Take down cluster1 and deploy the same 2 portlets that causes database changes.
5. Restart cluster1 and assert the following:
   1. Test clustering still works between cluster1 and cluster2/cluster3 .
      1. Add portlet/content on cluster1 and assert it shows up in cluster2/cluster3.
   2. Assert new portlet exists on on cluster/1cluster2 and not on cluster 3.
6. Take down cluster3 and deploy the same 2 portlets that causes database changes.
7. Restart cluster3 and assert the following:
   1. Test clustering still works between cluster1, cluster2, and cluster3.
      1. Add portlet/content on cluster3 and assert it shows up in cluster1/cluster2.
   2. Assert new portlet exists on cluster1, cluster2, and cluster3."
Rolling Restarts,,Deployment of new plugins/modules without database changes (LRQA-29631),2b,Manual,45,3,,,,,https://issues.liferay.com/browse/LRQA-42998,"1. Start a cluster of 3 Liferay Servers - referred to as cluster1, cluster2, and cluster3.
   1. Start all servers on DXP GA1 + latest FP.
   2. Verify clustering is working on all 3 servers.
2. Take down cluster2 and deploy 2 portlets that don’t cause database changes.
3. Restart cluster2 and assert the following:
   1. Test clustering still works between cluster2 and cluster1/cluster3 .
      1. Add portlet/content on cluster2 and assert it shows up in cluster1/cluster3.
   2. Assert new portlet only exists on cluster2 and not on cluster1/cluster3.
4. Take down cluster1 and deploy the same 2 portlets that don’t cause database changes.
5. Restart cluster1 and assert the following:
   1. Test clustering still works between cluster1 and cluster2/cluster3 .
      1. Add portlet/content on cluster1 and assert it shows up in cluster2/cluster3.
   2. Assert new portlet exists on on cluster/1cluster2 and not on cluster 3.
6. Take down cluster3 and deploy the same 2 portlets that don’t cause database changes.
7. Restart cluster3 and assert the following:
   1. Test clustering still works between cluster1, cluster2, and cluster3.
      1. Add portlet/content on cluster3 and assert it shows up in cluster1/cluster2.
   2. Assert new portlet exists on cluster1, cluster2, and cluster3."
Rolling Restarts,,Update of an existing plugin/module with database changes,2c,Manual,45,4,,,,,https://issues.liferay.com/browse/LRQA-42999,"1. Start a cluster of 3 Liferay Servers - referred to as cluster1, cluster2, and cluster3.
   1. Start all servers on DXP GA1 + latest FP.
   2. Verify clustering is working on all 3 servers.
2. Take down cluster2 and update a plugin that causes database changes.
3. Restart cluster2 and assert the following:
   1. Test clustering still works between cluster2 and cluster1/cluster3 .
      1. Add portlet/content on cluster2 and assert it shows up in cluster1/cluster3.
   2. Assert new portlet only exists on cluster2 and not on cluster1/cluster3.
4. Take down cluster1 and update a plugin that causes database changes.
5. Restart cluster1 and assert the following:
   1. Test clustering still works between cluster1 and cluster2/cluster3 .
      1. Add portlet/content on cluster1 and assert it shows up in cluster2/cluster3.
   2. Assert new portlet exists on on cluster/1cluster2 and not on cluster 3.
6. Take down cluster3 and update a plugin that causes database changes.
7. Restart cluster3 and assert the following:
   1. Test clustering still works between cluster1, cluster2, and cluster3.
      1. Add portlet/content on cluster3 and assert it shows up in cluster1/cluster2.
   2. Assert new portlet exists on cluster1, cluster2, and cluster3."
Rolling Restarts,,Update of an existing plugin/module without database changes,2d,Manual,45,3,,,,,https://issues.liferay.com/browse/LRQA-43000,"1. Start a cluster of 3 Liferay Servers - referred to as cluster1, cluster2, and cluster3.
   1. Start all servers on DXP GA1 + latest FP.
   2. Verify clustering is working on all 3 servers.
2. Take down cluster2 and update a plugin that doesn’t cause database changes.
3. Restart cluster2 and assert the following:
   1. Test clustering still works between cluster2 and cluster1/cluster3 .
      1. Add portlet/content on cluster2 and assert it shows up in cluster1/cluster3.
   2. Assert new portlet only exists on cluster2 and not on cluster1/cluster3.
4. Take down cluster1 and update a plugin that doesn’t cause database changes.
5. Restart cluster1 and assert the following:
   1. Test clustering still works between cluster1 and cluster2/cluster3 .
      1. Add portlet/content on cluster1 and assert it shows up in cluster2/cluster3.
   2. Assert new portlet exists on on cluster/1cluster2 and not on cluster 3.
6. Take down cluster3 and update a plugin that doesn’t cause database changes.
7. Restart cluster3 and assert the following:
   1. Test clustering still works between cluster1, cluster2, and cluster3.
      1. Add portlet/content on cluster3 and assert it shows up in cluster1/cluster2.
   2. Assert new portlet exists on cluster1, cluster2, and cluster3."
Rolling Restarts,,Disable bundle (LRQA-29773),2e,Manual,60,5,,,,,https://issues.liferay.com/browse/LRQA-43001,"1. Start a cluster of 2 Liferay Servers, referred to as cluster1 and cluster2.
   1. Start all servers on DXP GA1.
   2. Verify clustering is working on both servers.
2. Enable OpenID via System Settings
3. Assert that OpenID login is available in login iframe for cluster1 and cluster2
4. Deactivate Liferay Portal Security SSO OpenID in cluster1's App Manager
5. Assert that OpenID login is available in login iframe for cluster2 but not cluster1
6. Start 3rd node of cluster, referred to as cluster3
7. Assert that OpenID is enabled in System Settings and OpenID login is available in login iframe for cluster3
8. Deactivate Liferay Portal Security SSO OpenID in cluster3's App Manager
9. Assert that there were no console errors during these steps
10. Assert that CRUD operations still work on all nodes"
Rolling Restarts,,Test Group 3 - Configurations,,,,,,,,,,
Rolling Restarts,,Modified portal.properties,3a,Functional,45,3,,,,,RollingRestartEE#UpdatePortalPropertiesWithMultipleClusters,"1. Start a cluster of 3 Liferay servers - referred to as cluster1, cluster2, and cluster3.
   1. Start all servers on DXP GA1.
   2. Verify clustering is working on all 3 servers.
2. Take down cluster2 and update portal-ext.properties.
3. Restart cluster2 and assert the following:
   1. Test clustering still works between cluster2 and cluster1/cluster3 .
      1. Add portlet/content on cluster2 and assert it shows up in cluster1/cluster3.
4. Take down cluster1 and update with the same portal-ext.properties.
5. Restart cluster1 and assert the following:
   1. Test clustering still works between cluster1 and cluster2/cluster3 .
      1. Add portlet/content on cluster1 and assert it shows up in cluster2/cluster3.
6. Take down cluster3 and update with the same portal-ext.properties.
7. Restart cluster3 and assert the following:
   1. Test clustering still works between cluster1, cluster2, and cluster3.
      1. Add portlet/content on cluster3 and assert it shows up in cluster1/cluster2."
Rolling Restarts,,Test Group 4 - Changes to Application Servers/JVM,,,,,,,,,,
Rolling Restarts,,Update Java version (LRQA-29639),4a,Manual,30,3,,,,,https://issues.liferay.com/browse/LRQA-43009,"1. Start a cluster of 2 Liferay Servers using the same JDK minor version.
   1. Start all servers on DXP GA1 + latest FP
   2. Verify clustering is working on both servers.
2. Start 3rd cluster node using a different JDK minor version.
   1. Start server on DXP GA1 + latest FP
   2. Verify clustering is working on all servers."
Rolling Restarts,,Test Group 5 - Blue Green Deployment,,,,,,,,,,
Rolling Restarts,,Changes to classes that implement serializable (LRQA-30048),5a,Manual,60,4,,,,,https://issues.liferay.com/browse/LRQA-43010,1. DXP 7.0 FP8 updates a clustering class that implements serializable 
Rolling Restarts,,Test Group 6 - Elasticsearch,,,,,,,,,,
Rolling Restarts,,Remote Elasticsearch + X-Pack (LRQA-29769),6a,Functional,-,5,,,,,RollingRestartEE#InstallFixPackWithMultipleClusters,"1. Start a cluster of 3 Liferay Servers connect them to standalone Elasticsearch cluster.
   1. Start all servers on DXP GA1.
   2. Verify clustering is working on both servers.
2. Add assets
3. Shutdown Liferay cluster
4. Deploy X-Pack
5. Start cluster of 3 Liferay Servers
6. Verify basic portal functionality
7. Verify that search indices are still there
8. Verify X-Pack functionality"
Scheduler,Scheduler,,,,,,,,,,,
Scheduler,,Test Group 1 - Basic Configuration Properties,,,,,,,,,,
Scheduler,,Properties not verified,1a,Unit,-,4,,,,,SchedulerHelperPropertiesVerifyProcessTest#testNoVerify,"1. Set scheduler helper properties verify process to empty collections
1. auditSchedulerJobEnabled
2. Configure scheduler helper properties
3. Get configuration properties
4. Assert no properties should have been verified"
Scheduler,,Properties verified,1b,Unit,-,4,,,,,SchedulerHelperPropertiesVerifyProcessTest#testVerify,"1. Set scheduler helper properties verify process to true
1. auditSchedulerJobEnabled
2. Configure scheduler helper properties
3. Get configuration properties
4. Assert properties have been verified
5. Assert scheduler job is enabled"
Scheduler,,Disabled scheduler in the portal-ext.properties,1c,Manual,,3,,,,,,"1. To disable all scheduler classes defined in  liferay-portlet.xml. 
1. Set scheduler.enabled to false in portal-ext.properties. (To ensure a scheduler consistent behaviour, this property must have the same value among all the nodes of the cluster)
2. Assert all scheduler classes are disabled for all cluster nodes "
Scheduler,,Set maximum length in the portal-ext.properties to override the default settings,1d,Manual,,3,,,,,,"1. Set length of description, group name, and job name
1. scheduler.description.max.length=
2. scheduler.group.name.max.length=
3. scheduler.job.name.max.length=
2. Assert maximum length for description, group name, and job name"
Scheduler,,Set scheduler timeout in the portal-ext.properties,1e,Manual,,3,,,,,,"1. Enable scheduler timeout property
1. scheduler.event.message.listener.lock.timeout=
2. Assert scheduler is successfully timeout"
Scheduler,,Changeable memory scheduler quartz properties,1f,Manual,,3,,,,,,"1. To override memory scheduler default settings, change the following in the portal-ext.properties
1. memory.scheduler.org.quartz.scheduler.instanceId=AUTO
2. memory.scheduler.org.quartz.scheduler.instanceName=MemoryQuartzSchedulerEngineInstance
3. memory.scheduler.org.quartz.scheduler.jobFactory.class=org.quartz.simpl.PropertySettingJobFactory
4. memory.scheduler.org.quartz.threadPool.class=org.quartz.simpl.SimpleThreadPool
5. memory.scheduler.org.quartz.threadPool.threadCount=5
6. memory.scheduler.org.quartz.threadPool.threadPriority=5
2. Verify scheduler works after the default properties setting is changed"
Scheduler,,Memory Scheduler quartz property requires class extension,1g,Manual,,3,,,,,,"1. Extend class property to override or change this property
1. memory.scheduler.org.quartz.jobStore.class=org.quartz.simpl.RAMJobStore
2. Verify memory scheduler works after changes

"
Scheduler,,Persistent scheduler quartz properties require classes extension to modify,1h,Manual,,3,,,,,,"1. Extend each property class to override or change the following properties
1. persisted.scheduler.org.quartz.dataSource.ds.connectionProvider.class=com.liferay.portal.scheduler.quartz.internal.QuartzConnectionProvider
2. persisted.scheduler.org.quartz.jobStore.class=com.liferay.portal.scheduler.quartz.internal.PortalJobStore
3. persisted.scheduler.org.quartz.jobStore.dataSource=ds
2. Verify persisted scheduler works after changes"
Scheduler,,Persistent scheduler quartz properties require change in database,1i,Manual,,3,,,,,,"1. Modify database tables with ""QUARTZ_"" prefix to a new prefix ""NEW_""
2. Modify this prefix property with new prefix
1. persisted.scheduler.org.quartz.jobStore.tablePrefix=NEW_ 
3. Verify persisted scheduler works after changes

"
Scheduler,,Test Group 2 - Basic Functions (CRUD),,,,,,,,,,
Scheduler,,Delete the single and group jobs from the scheduler,2a,Unit,-,5,,,,,QuartzSchedulerEngineTest#testdelete1,"1. Identify the job or group you prefer to delete 
2. Delete the job and any associated triggers
3. Return true if the job was found and deleted
4. Otherwise return false if one or more jobs were not deleted"
Scheduler,,Initialize job state,2b,Unit,-,5,,,,,QuartzSchedulerEngineTest#testInitJobState,"1. Get scheduled jobs from the scheduler
2. Scheduler response returns default job number
3. Add the job given to the scheduler without trigger
4. Get scheduled job from the scheduler
5. Scheduler response returns default job number + 1
6. Initialize job state from scheduler engine
7. Get scheduled jobs from the scheduler
8. Scheduler response returns default job number"
Scheduler,,Pause and resume the scheduled jobs,2c,Unit,-,4,,,,,QuartzSchedulerEngineTest#testPauseAndResume1,"1. Get scheduled jobs from the scheduler
2. Scheduler response returns trigger state is normal
3. Pause job from the scheduler engine
4. Get the scheduled job from scheduler response
5. Scheduler response returns trigger state is paused
6. Resume job from the scheduler engine
7. Get the scheduled job from scheduler response
8. Scheduler response returns trigger state is normal"
Scheduler,,Schedule the jobs,2d,Unit,-,5,,,,,QuartzSchedulerEngineTest#testSchedule1,"1. Get scheduled jobs from the scheduler
2. Assert scheduler response returns default job number
3. Create trigger from the quartz trigger factory
4. Schedule job from the scheduler engine
5. Get scheduled jobs from the scheduler
6. Assert scheduler response returns default job number + 1"
Scheduler,,Suppress error from the scheduler,2e,Unit,-,3,,,,,QuartzSchedulerEngineTest#testSuppressError,"1. Get scheduled jobs from the scheduler
2. Get message from scheduler engine job state
3. Confirm jobState.getExceptions is not returning null
4. Suppress error from the scheduler engine
5. Get scheduled jobs from the scheduler
6. Get message from scheduler engine job state
7. Confirm jobState.getExceptions is returning null"
Scheduler,,Unschedule memory and persistent jobs,2f,Unit,-,5,,,,,QuartzSchedulerEngineTest#testUnschedule1,"1. Get scheduled jobs from the scheduler
2. All jobs and indicated triggers state are normal
3. Unschedule memory and persisted jobs from the scheduler engine
4. All jobs and the indicated Triggers state are removed from the scheduler"
Scheduler,,Update schedule,2g,Unit,-,5,,,,,QuartzSchedulerEngineTest#testUpdate1,"1. Get scheduled jobs from the scheduler
2. Create trigger
3. Update trigger from the scheduler engine
4. Existing triggers are updated based on the new trigger"
Scheduler,,"Test Group 3 - Basic trigger configuration (Interval, cron, timezone)",,,,,,,,,,
Scheduler,,Trigger daily schedule every two days,3a,Unit,-,,,,,,QuartzTriggerFactoryTest#testDailyEveryTwoDaysTrigger,"1. Schedule a job to be executed every 2 days

"
Scheduler,,Trigger daily schedule every weekday,3b,Unit,-,,,,,,QuartzTriggerFactoryTest#testDailyEveryWeekdayTrigger,1. Schedule a job to be executed every day
Scheduler,,Trigger monthly schedule on day 12 of every two months,3c,Unit,-,,,,,,QuartzTriggerFactoryTest#testMonthlyDay12OfEveryTwoMonthsTrigger,1. Schedule a job to be executed on day 12 of every 2 months
Scheduler,,Trigger monthly schedule on third tuesday of every three months,3d,Unit,-,,,,,,QuartzTriggerFactoryTest#testMonthlyThirdTuesdayOfEveryThreeMonthsTrigger,"1. Schedule a job to be executed on 3rd Tuesday of every 3 months

"
Scheduler,,Trigger weekly schedule every sunday,3e,Unit,-,,,,,,QuartzTriggerFactoryTest#testWeeklyEverySundayTrigger,1. Schedule a job to be executed every week on Sunday
Scheduler,,Trigger weekly schedule on monday and wednesday,3f,Unit,-,,,,,,QuartzTriggerFactoryTest#testWeeklyMondayAndWednesdayTrigger,"1. Schedule a job to be executed every week on Monday and Wednesday

"
Scheduler,,Trigger yearly schedule every two years on january 12,3g,Unit,-,,,,,,QuartzTriggerFactoryTest#testYearlyEveryTwoYearsJanuary12Trigger,1. Schedule a job to be executed every 2 years on January 12.
Scheduler,,Trigger yearly schedule every two years on the third Sunday of March,3h,Unit,-,,,,,,QuartzTriggerFactoryTest#testYearlyEveryTwoYearsThirdSundayOfMarchTrigger,1. Schedule a job to be executed every 2 years on the 3rd Sunday of March
Scheduler,,Trigger schedule with PDT,3i,Manual,,5,,,,,,"1. Schedule a job to be executed every day at 2pm Pacific Daylight Time
2. Assert trigger at correct time"
Scheduler,,Trigger schedule on UTC,3j,Manual,,4,,,,,,"1. Schedule a job to be executed every Sunday at 3am Coordinated Universal Time
2. Assert trigger at correct time"
Scheduler,,Test Group 4 - Delete Cluster Schedule Jobs (memory clustered and persistence),,,,,,,,,,
Scheduler,,Delete memory clustered jobs on master,4a,Unit,-,5,,,,,ClusterSchedulerEngineTest#testDeleteOnMaster,"1. Reset mock cluster master executor (master: true, memoryClusterJobs: 0, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 4, persistentJobs: 4)
3. Start cluster scheduler engine
4. Get scheduled jobs from cluster scheduler engine
5. Delete memory clustered jobs by job name and group name 
6. Assert  memory clustered jobs is empty"
Scheduler,,Delete persistent jobs on master,4b,Unit,-,5,,,,,ClusterSchedulerEngineTest#testDeleteOnMaster,"1. Repeat steps 4a(1 - 6)
2. Delete persisted jobs by job name and  group name 
3. Assert  memory clustered jobs is empty"
Scheduler,,Delete memory clustered jobs on slave,4c,Unit,-,5,,,,,ClusterSchedulerEngineTest#testDeleteOnSlave,"1. Reset mock cluster master executor (master: false, memoryClusterJobs: 4, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 0, persistentJobs: 4)
3. Start  cluster scheduler engine
4. Get scheduled jobs from cluster scheduler engine
5. Assert  memory clustered jobs is empty
6. Delete memory clustered jobs by job name and group name 
7. Assert  memory clustered jobs is empty"
Scheduler,,Delete non existing group memory clustered jobs on slave,4d,Unit,-,4,,,,,ClusterSchedulerEngineTest#testDeleteOnSlave,"1. Repeat steps 4c (1 - 3)
2. Delete memory clustered job with not existing  group
3. Assert  memory clustered jobs is empty"
Scheduler,,Get scheduler jobs,4e,Unit,-,5,,,,,ClusterSchedulerEngineTest#testGetSchedulerJobs,"1. Reset mock cluster master executor (master: true, memoryClusterJobs: 0, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 4, persistentJobs: 2)
3. Start cluster scheduler engine
4. Get the schedule jobs from cluster scheduler engine
5. Assert scheduler response size is 6"
Scheduler,,Test Group 5 - Clustering State Changes,,,,,,,,,,
Scheduler,,Master to slave with log disabled,5a,Unit,-,,,,,,ClusterSchedulerEngineTest#testMasterToSlave,"1. Reset mock cluster master executor (master: true, memoryClusterJobs: 0, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 4, persistentJobs: 2)
3. Start cluster scheduler engine
4. Get the schedule jobs from cluster scheduler engine
5. Assert scheduler jobs size
6. Reset mock cluster master executor (master: false, memoryClusterJobs: 4, persistentJobs: 2)
7. Get log records
8. Assert log records is empty
9. Get scheduled jobs
10. Assert scheduler returns empty
11. Assert memory clustered jobs size"
Scheduler,,Master to slave with log enabled,5b,Unit,-,,,,,,ClusterSchedulerEngineTest#testMasterToSlave,"1. Repeat steps from 5a(1 - 3)
2. Clear memory clustered jobs
3. Get scheduled jobs from cluster scheduler engine
4. Assert scheduler jobs size
5. Assert memory clustered jobs return empty
6. Reset all log level 
7. Reset mock cluster master executor (master: false, memoryClusterJobs: 4, persistentJobs: 2)
8. Get log records (0)
9. Assert load 4  memory clustered jobs from master
10. Get log records (1)
11. Assert 4 memory clustered jobs stopped running on this node
12. Get log records (2)
13. Assert unable  to notify slave
14. Get scheduled jobs
15. Assert scheduled jobs return empty"
Scheduler,,Slave to master with log disabled,5c,Unit,-,,,,,,ClusterSchedulerEngineTest#testSlaveToMaster,"1. Reset mock cluster master executor (master: false, memoryClusterJobs: 4, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 0, persistentJobs: 0)
3. Start cluster scheduler engine
4. Get scheduled jobs from cluster scheduler engine
5. Assert memory clustered jobs size is 4
6. Pause cluster scheduler engine
7. Reset mock cluster master executor (master: true, memoryClusterJobs: 0, persistentJobs: 0)
8. Get cluster master token transition listener
9. Get log records
10. Assert log records is empty
11. Assert cluster master is executed
12. Get scheduled jobs
13. Assert trigger state is paused
14. Assert memory cluster jobs is empty"
Scheduler,,Slave to master with log enabled,5d,Unit,-,,,,,,ClusterSchedulerEngineTest#testSlaveToMaster,"1. Repeat steps 2a(1-3)
2. Assert cluster master is not executed
3. Get scheduled jobs
4. Assert memory clustered jobs size is 4
5. Reset mock cluster master executor (master: true, memoryClusterJobs: 0, persistentJobs: 0)
6. Get cluster master token transition listener
7. Assert log records size is 2
8. Get log records(0)
9. Assert “4 memory clustered jobs started running on this node” message
10. Get log records(1)
11. Assert “unable to notify slave” message
12. Assert cluster master is executed
13. Get scheduled jobs
14. Assert memory cluster jobs is empty"
Scheduler,,Test Group 6 - Pause and  Resume,,,,,,,,,,
Scheduler,,Pause and resume memory clustered jobs by job and group names on master,6a,Unit,-,,,,,,ClusterSchedulerEngineTest#testPauseAndResumeOnMaster,"1. Reset mock cluster master executor (master: true, memoryClusterJobs: 0, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 4, persistentJobs: 4)
3. Start cluster scheduler engine
4. Get scheduled job by job name and group name
5. Confirm trigger state is normal
6. Pause cluster scheduler engine 
7. Assert trigger state is paused
8. Set cluster invoke thread local enable to false
9. Resume cluster scheduler engine 
10. Assert trigger state is back to normal"
Scheduler,,Pause and resume memory clustered jobs by group name on master,6b,Unit,-,,,,,,ClusterSchedulerEngineTest#testPauseAndResumeOnMaster,"1. Repeat steps 6a(1-3)
2. Get scheduled job by  group name
3. Confirm trigger state is normal
4. Pause cluster scheduler engine 
5. Assert trigger state is paused
6. Set cluster invoke thread local enable to false
7. Resume cluster scheduler engine 
8. Assert trigger state is back to normal"
Scheduler,,Pause and resume persistent jobs by job and group names on master,6c,Unit,-,,,,,,ClusterSchedulerEngineTest#testPauseAndResumeOnMaster,"1. Repeat steps 6a(1-3)
2. Get scheduled job by job name and  group name
3. Confirm trigger state is normal
4. Pause cluster scheduler engine 
5. Assert trigger state is paused
6. Set cluster invoke thread local enable to false
7. Resume cluster scheduler engine 
8. Assert trigger state is back to normal"
Scheduler,,Pause and resume persistent job by group name on master,6d,Unit,-,,,,,,ClusterSchedulerEngineTest#testPauseAndResumeOnMaster,"1. Repeat steps 6a(1-3)
2. Get scheduled job by group name
3. Confirm trigger state is normal
4. Pause cluster scheduler engine 
5. Assert trigger state is paused
6. Set cluster invoke thread local enable to false
7. Resume cluster scheduler engine 
8. Assert trigger state is back to normal"
Scheduler,,Pause and resume memory clustered job by job and group  names on slave,6e,Unit,-,,,,,,ClusterSchedulerEngineTest#testPauseAndResumeOnSlave,"1. Reset mock cluster master executor (master: false, memoryClusterJobs: 4, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 0, persistentJobs: 4)
3. Start cluster scheduler engine
4. Get memory clustered job by job name and group name
5. Assert trigger state is normal
6. Pause cluster scheduler engine 
7. Assert trigger state is paused
8. Set cluster invoke thread local enable to false
9. Get and clear thread locals
10. Resume cluster scheduler engine 
11. Assert trigger state is back to normal"
Scheduler,,Pause and resume memory clustered job by group name on slave,6f,Unit,-,,,,,,ClusterSchedulerEngineTest#testPauseAndResumeOnSlave,"1. Repeat steps 6e(1-3)
2. Get memory clustered job group name
3. Assert trigger state is normal
4. Pause cluster scheduler engine 
5. Assert trigger state is paused
6. Set cluster invoke thread local enable to false
7. Get and clear thread locals
8. Resume cluster scheduler engine 
9. Assert trigger state is back to normal"
Scheduler,,Pause and resume memory clustered with not existing job on slave,6g,Unit,-,,,,,,ClusterSchedulerEngineTest#testPauseAndResumeOnSlave,"1. Repeat steps 6e(1-3)
2. Get memory clustered job
3. Assert no memory clustered job is returned
4. Pause cluster scheduler engine 
5. Assert no memory clustered job is paused"
Scheduler,,Pause and resume memory clustered with not existing group on slave,6h,Unit,-,,,,,,ClusterSchedulerEngineTest#testPauseAndResumeOnSlave,"1. Repeat steps 6e(1-3)
2. Get memory clustered job
3. Assert no group existed in memory clustered job
4. Pause cluster scheduler engine 
5. Assert no group existed in memory clustered job"
Scheduler,,Test Group 7 - Clustering Schedule,,,,,,,,,,
Scheduler,,Schedule memory clustered jobs on master,7a,Unit,-,,,,,,ClusterSchedulerEngineTest#testScheduleOnMaster,"1. Reset mock cluster master executor (master: true, memoryClusterJobs: 0, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 1, persistentJobs: 1)
3. Start cluster scheduler engine
4. Get trigger job name
5. Schedule cluster scheduler engine
6. Get scheduled jobs
7. Assert  memory clustered job is empty
8. Assert cluster request is not null
9. Assert cluster request is multicast
10. Assert local cluster request is skipped"
Scheduler,,Schedule persistent jobs on master,7b,Unit,-,,,,,,ClusterSchedulerEngineTest#testScheduleOnMaster,"1. Repeat steps 7a(1- 6)
2. Assert scheduled jobs size
3. Assert  memory clustered job is empty"
Scheduler,,Schedule jobs on slave,7c,Unit,-,,,,,,ClusterSchedulerEngineTest#testScheduleOnSlave,"1. Reset mock cluster master executor (master: false, memoryClusterJobs: 1, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 0, persistentJobs: 0)
3. Start cluster scheduler engine
4. Get scheduled jobs
5. Assert no job is scheduled
6. Assert memory clustered jobs size is 1
7. Reset mock cluster master executor (master: false, memoryClusterJobs: 2, persistentJobs: 0)
8. Get trigger
9. Schedule cluster scheduler engine
10. Get scheduled jobs
11. Assert no job is scheduled
12. Assert memory clustered jobs size is 2"
Scheduler,,Shutdown cluster scheduler,7d,Unit,-,,,,,,ClusterSchedulerEngineTest#testShutdown,"1. Start cluster scheduler engine
2. Assert cluster scheduler engine is started
3. Shutdown cluster scheduler engine
4. Assert cluster scheduler engine is shutdown"
Scheduler,,Shutdown clustering with a scheduled job,7e,Manual,,,,,,,,"1. Schedule a job on the clusterings
2. Shutdown master or slave
3. Assert shutdown clustering node has not affected scheduled job
4. Assert scheduled job is persisted on the other nodes"
Scheduler,,Restart clustering with a scheduled job,7f,Manual,,,,,,,,"1. Schedule a job on the clusterings
2. Shutdown master or slave
3. Assert restarting clustering node has not affected scheduled job
4. Assert scheduled job is persisted"
Scheduler,,Add node to a clustering with a scheduled job,7g,Manual,,,,,,,,"1. Add clustering node to cluster with a scheduled job
2. Assert clustering node is successfully added 
3. Assert the job previously scheduled is added to a new clustering node [a][b]"
Scheduler,,Remove node from clustering with a scheduled job,7h,Manual,,,,,,,,"1. Remove clustering node from the cluster with a scheduled job
2. Assert clustering node is successfully removed 
3. Assert clustering node has not affected scheduled job on other nodes

"
Scheduler,,Test Group 8 - Suppress Error (memory clustered and persistence),,,,,,,,,,
Scheduler,,Suppress memory clustered jobs error on master,8a,Unit,-,,,,,,ClusterSchedulerEngineTest#testSupressErrorOnMaster,"1. Reset mock cluster master executor (master: true, memoryClusterJobs: 0, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 1, persistentJobs: 1)
3. Start cluster scheduler engine
4. Get scheduled jobs
5. Assert suppress error value is null
6. Assert memory clustered jobs is empty
7. Launch cluster scheduler engine suppress error
8. Get scheduled jobs
9. Assert suppress error value is true
10. Assert memory clustered jobs is empty"
Scheduler,,Suppress persistent jobs error on master,8b,Unit,-,,,,,,ClusterSchedulerEngineTest#testSupressErrorOnMaster,1. Repeat steps from 8a(1-10) for persistent jobs
Scheduler,,Suppress error on slave,8c,Unit,-,,,,,,ClusterSchedulerEngineTest#testSupressErrorOnSlave,"1. Reset mock cluster master executor (master: true, memoryClusterJobs: 1, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 0, persistentJobs: 0)
3. Start cluster scheduler engine
4. Get memory clustered job
5. Assert suppress error value is null"
Scheduler,,Test Group 9 - Thread Local,,,,,,,,,,
Scheduler,,Thread local persists when portal is starting,9a,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Set enable cluster invoke thread local to false
2. Set initializing plugin context lifecycle thread local to false
3. Set destroying plugin context lifecycle thread local to false
4. Set clusterable thread local storageType.PERSISTED
5. Assert get and clear thread locals return false"
Scheduler,,Thread local memory clustered when portal is starting,9b,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Repeat steps 9a(1-3)
2. Set clusterable thread local storageType.MEMORY_CLUSTERED
3. Assert get and clear thread locals return false
4. Start cluster scheduler engine"
Scheduler,,Thread local persisted when portal is started,9c,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,1. Repeat steps 9a(1-5) for persisted threadlocal when portal is started
Scheduler,,Thread local memory clustered when portal is started,9d,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Repeat steps 9a( 1-3)
2. Set clusterable thread local storageType.MEMORY_CLUSTERED
3. Assert get and clear thread locals return true"
Scheduler,,Thread local persists when plugin is starting,9e,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Set enable cluster invoke thread local to false
2. Set initializing plugin context lifecycle thread local to true
3. Set destroying plugin context lifecycle thread local to false
4. Set clusterable thread local storageType.PERSISTED
5. Assert get and clear thread locals return false

"
Scheduler,,Thread local memory clustered when plugin is starting,9f,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Repeat steps 9e(1-3)
2. Set clusterable thread local storageType.MEMORY_CLUSTERED
3. Assert get and clear thread locals return false

"
Scheduler,,Thread local persisted when plugin is destroying,9g,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Set enable cluster invoke thread local to false
2. Set initializing plugin context lifecycle thread local to false
3. Set destroying plugin context lifecycle thread local to true
4. Set clusterable thread local storageType.PERSISTED
5. Assert get and clear thread locals return false"
Scheduler,,Thread local memory clustered when plugin is destroying,9h,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Repeat steps 9g(1-3)
2. Set clusterable thread local storageType.MEMORY_CLUSTERED
3. Assert get and clear thread locals return false"
Scheduler,,Thread local persisted when cluster invoke is disabled,9i,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Set enable cluster invoke thread local to false
2. Set initializing plugin context lifecycle thread local to false
3. Set destroying plugin context lifecycle thread local to false
4. Set clusterable thread local storageType.PERSISTED
5. Assert get and clear thread locals return false"
Scheduler,,Thread local persisted when cluster invoke is enabled,9j,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Set enable cluster invoke thread local to true
2. Repeat steps 9i(2-5)"
Scheduler,,Thread local memory clustered  when cluster invoke is disabled,9k,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Repeat steps 9i(1-3)
2. Set clusterable thread local storageType.MEMORY_CLUSTERED
3. Assert get and clear thread locals return true"
Scheduler,,Thread local memory clustered  when cluster invoke is enabled,9l,Unit,-,,,,,,ClusterSchedulerEngineTest#testThreadLocal,"1. Set enable cluster invoke thread local to true
2. Set initializing plugin context lifecycle thread local to false
3. Set destroying plugin context lifecycle thread local to false
4. Set clusterable thread local storageType.MEMORY_CLUSTERED
5. Assert get and clear thread locals return false"
Scheduler,,Test Group 10 - Clustering Unschedule job,,,,,,,,,,
Scheduler,,Unschedule memory clustered on master,10a,Unit,-,,,,,,ClusterSchedulerEngineTest#testUnscheduleOnMaster,"1. Reset mock cluster master executor (master: true, memoryClusterJobs: 0, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 4, persistentJobs: 4)
3. Start cluster scheduler engine
4. Get scheduled job
5. Assert trigger state is normal
6. Assert memory clustered jobs is empty
7. Unschedule cluster scheduler engine
8. Get scheduled job
9. Assert trigger state is unscheduled
10. Assert memory clustered jobs is empty"
Scheduler,,Unschedule memory clustered  jobs by group name on master,10b,Unit,-,,,,,,ClusterSchedulerEngineTest#testUnscheduleOnMaster,"1. Repeat steps 10a(1-4)
2. Check if object is equal to getJobName
1. Assert trigger state is unscheduled
3. Otherwise, assert trigger state is normal
4. Assert memory clustered jobs is empty
5. Unschedule cluster scheduler engine
6. Get scheduled job
7. Assert trigger state is unscheduled
8. Assert memory clustered jobs is empty"
Scheduler,,Unschedule persistent jobs on master,10c,Unit,-,,,,,,ClusterSchedulerEngineTest#testUnscheduleOnMaster,1. Repeat steps 1a(1-10) for persisted jobs by job name and group name
Scheduler,,Unschedule persistent jobs by group name on master,10d,Unit,-,,,,,,ClusterSchedulerEngineTest#testUnscheduleOnMaster,1. Repeat steps 10b(1-8) for persisted jobs by group name
Scheduler,,Unschedule memory clustered jobs on slave,10e,Unit,-,,,,,,ClusterSchedulerEngineTest#testUnscheduleOnSlave,"1. Reset mock cluster master executor (master: false, memoryClusterJobs: 0, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 0, persistentJobs: 4)
3. Start cluster scheduler engine
4. Assert get scheduled job returns  null
5. Get memory clustered job
6. Assert trigger state is normal
7. Unschedule cluster scheduler engine
8. Assert get scheduled job returns  null
9. Assert get memory clustered job returns null"
Scheduler,,Unschedule memory clustered jobs by group name on slave,10f,Unit,-,,,,,,ClusterSchedulerEngineTest#testUnscheduleOnSlave,"1. Repeat steps 10e(1- 3)
2. Get memory clustered job
3. Assert trigger state is normal
4. Unschedule cluster scheduler engine
5. Get scheduled jobs
6. Assert scheduler responses is empty
7. Assert get memory clustered jobs is empty"
Scheduler,,Test Group 11 - Update Cluster schedule jobs,,,,,,,,,,
Scheduler,,Update memory clustered jobs on master,11a,Unit,-,,,,,,ClusterSchedulerEngineTest#testUpdateOnMaster,"1. Reset mock cluster master executor (master: true, memoryClusterJobs: 0, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 0, persistentJobs: 1)
3. Start cluster scheduler engine
4. Get scheduled job
5. Assert trigger content is equal to _DEFAULT_INTERVAL , which is set to 20
6. Assert memory clustered jobs is empty
7. Get trigger and set interval equals to _DEFAULT_INTERVAL * 2
8. Update cluster scheduler engine
9. Get scheduled job
10. Assert trigger content expected interval  _DEFAULT_INTERVAL * 2 =  40
11. Assert memory clustered jobs is empty"
Scheduler,,Update persistent jobs on master,11b,Unit,-,,,,,,ClusterSchedulerEngineTest#testUpdateOnMaster,1. Repeat steps 11a(1-11) for persisted jobs by job name and group name on master
Scheduler,,Update on slave without exception,11c,Unit,-,,,,,,ClusterSchedulerEngineTest#testUpdateOnSlave,"1. Reset mock cluster master executor (master: false, memoryClusterJobs: 1, persistentJobs: 0)
2. Reset jobs mock scheduler engine (memoryClusterJobs: 0, persistentJobs: 0)
3. Start cluster scheduler engine
4. Assert get scheduled jobs is null
5. Get memory clustered job
6. Assert trigger content is equal to _DEFAULT_INTERVAL, which is set to 20
7. Get trigger and set interval equals to _DEFAULT_INTERVAL * 2
8. Update cluster scheduler engine
9. Assert get scheduled jobs is null
10. Get memory clustered job
11. Assert trigger content expected interval  _DEFAULT_INTERVAL * 2 =  40"
Scheduler,,Update on slave with not existing group name,11d,Unit,-,,,,,,ClusterSchedulerEngineTest#testUpdateOnSlave,"1. Repeat steps 11c(1-3)
2. Get trigger and set interval equals to _DEFAULT_INTERVAL * 2
3. Update cluster scheduler engine
4. Assert “Unable to  update trigger for memory clustered job” message"
Scheduler,,Update on slave with not existing job name,11e,Unit,-,,,,,,ClusterSchedulerEngineTest#testUpdateOnSlave,"1. Repeat steps 11c(1-3)
2. Get trigger and set interval equals to _DEFAULT_INTERVAL * 2
3. Update cluster scheduler engine
4. Assert “Unable to  update trigger for memory clustered job” message

"
Scheduler,,Test Group 12 - Modules,,,,,,,,,,
Scheduler,,Undeploy module,12a,Manual,,4,,,,,,"1. Go to Control Panel > Apps > App Manager
2. Search for Scheduler
3. Uninstall  liferay ce portal scheduler
4. Assert liferay portal scheduler,  liferay portal scheduler multiple, and liferay portal scheduler quartz are uninstalled.
5. In console, assert liferay portal scheduler,  liferay portal scheduler multiple, and liferay portal scheduler quartz are blacklisted.
6. Assert no job is scheduled after the scheduler module(s) is/ are undeployed."
Scheduler,,Test Group 13 - Rolling restart with scheduler,,,,,,,,,,
Scheduler,,Rolling restart with scheduled job,13a,Manual,,4,,,,,,"1. Schedule a job on multiple clustering servers
2. Verify clustering scheduled job is working on all node servers
3. Take down 1 server from the clustering
4. Verify clustering scheduled job still works on the running servers
5. Restart the server you take down
6. Verify clustering scheduled job persisted and still worked all on servers"
Scheduler,,Test Group 14 - Plugins with scheduler,,,,,,,,,,
Scheduler,,Spring xml with a scheduled job,14a,Manual,,5,,,,,,"1. Schedule a job with a Spring xml plugin
2. Verify job is  successfully scheduled

"
Scheduler,,Ext plugin with a scheduled job,14b,Manual,,3,,,,,,"1. Schedule a job with an Ext plugin
2. Verify job is  successfully scheduled"
Scheduler,,Hook plugin with a scheduled job,14c,Manual,,2,,,,,,"1. Schedule a job with a hook plugin
2. Verify job is  successfully scheduled"
Scheduler,,OSGi Portlet with a scheduled job,14d,Manual,,5,,,,,,"1. Schedule a job with a portlet jar
2. Verify job is  successfully scheduled"
Scripting Engine,Scripting Engine,,,,,,,,,,,
Scripting Engine,,Test Group 1 - Groovy functionality,,,,,,,,,,
Scripting Engine,,Testcase 1a - Groovy sample script functionality,1a,Manual,,5,,,,,https://issues.liferay.com/browse/LRQA-53783,"1. Navigate to Control Panel → Configuration → Server Administration
2. Navigate to Script tab
3. Execute the following script:
   1. out.println(""This is a test; "" + ""this is a string."");
4. Assert no exceptions are logged
5. Assert output under script field"
Scripting Engine,,Testcase 1b - Access to Liferay classes,1b,Manual,,5,,,,,GroovyScript#ExecuteScriptWithLiferayClasses,"1. Navigate to Control Panel → Configuration → Server Administration
2. Navigate to Script tab
3. Execute the following script:
import com.liferay.fragment.service.FragmentCollectionLocalServiceUtil;
Import com.liferay.counter.kernel.service.CounterLocalServiceUtil;


fragmentCollectionId = CounterLocalServiceUtil.increment();


fragmentCollection = FragmentCollectionLocalServiceUtil.createFragmentCollection(fragmentCollectionId);


fragmentCollection.setName(“Test Fragment Collection Name”);


out.println(fragmentCollection.getName());
        

4. Assert no exceptions are logged
5. Assert successful execution
6. Assert “Test Fragment Collection Name” is displayed in output"
Scripting Engine,,Testcase 1c - Access to predefined variables,1c,Manual,,4,,,,,GroovyScript#ExecuteScriptWithPredefinedVariables,"1. Navigate to Control Panel → Configuration → Server Administration
2. Navigate to Script tab
3. Execute the following script:
import com.liferay.portal.kernel.util.*


company = PortalUtil.getCompany(actionRequest)
out.println(""Current Company:${company.getName()}\n"")


out.println(""User Info:"")
userInfo.each { 
        k,v -> out.println(""${k}:${v}"") 
}
        4. Assert no exceptions are logged
5. Assert successful execution
6. Assert current instance name is displayed
7. Assert current user information is displayed"
Scripting Engine,,Testcase 1d - Embedded HTML,1d,Manual,,3,,,,,GroovyScript#ExecuteScriptWithEmbeddedHTML,"1. Navigate to Control Panel → Configuration → Server Administration
2. Navigate to Script tab
3. Execute the following script:
   out.println(
“””
<div class=”embedded-html-test”>
    Test Embedded HTML
</div>
“””);
        4. Assert no exceptions are logged
5. Assert successful execution
6. Assert the html is present in the script output including the added class"
Service Builder,Service Builder,,,,,,,,,,,
Service Builder,,Test Group 1 - Entity attribute configurations,,,,,,,,,,
Service Builder,,Persistence disabled,1a,Manual,,,,,,,,"1. Add entity in modules/util/portal-tools-service-builder-test-service/service.xml
   1. persistence: false
   2. remote-service: false
2. Add some columns to entity
3. Build Service
4. Assert no persistence code is generated (LPS-98680)
5. Compile Java
6. Assert code can be compiled successfully
7. Set persistence to true for the entity
8. Build Service
9. Assert persistence code is generated
10. Compile Java
11. Assert code can be compiled successfully"
Service Builder,,Enable all boolean entity attributes,1b,Manual,,,,,,,,"1. Create a sample service.xml
   1. mvcc-enabled: true
2. Create service builder sample entry
   1. external-reference-code: true
   2. local-service: true
   3. uuid: true
   4. uuid-accessor: true
   5. dynamic-update-enabled: true
3. Add some columns to entity
4. Build Service
5. Assert service builder executes successfully
6. Compile Java
7. Assert code is compiled successfully"
Service Builder,,Disable all boolean entity attributes,1c,Manual,,,,,,,,"1. Create service builder sample entry
   1. remote-service: false
   2. persistence: false
   3. cache-enabled: false
2. Add some columns to entity
3. Build Service
4. Assert service builder executes successfully
5. Compile Java
6. Assert code is compiled successfully"
Service Builder,,Versioning improvements (LPS-93045),1d,Integration,,,,,,,portal-tools-service-builder-test-service,"1. Create a sample entity
   1. local-service: true
   2. remote-service: false
   3. versioned: true
2. Add some columns
3. Add some finders
4. Build service
5. Assert finder methods are generated for head version (findBy<FinderName>_Head...)
6. Compile
7. Assert code is compiled successfully"
Service Builder,,Remote Service,1e,Integration,,,,,,,regular portal usage,"1. Add entity in modules/util/portal-tools-service-builder-test-service/service.xml
   1. local-service: true
   2. remote-service: true
2. Add some columns to entity
3. Build Service
4. Assert [Entity]Service classes generated
5. Compile Java
6. Assert code can be compiled successfully"
Service Builder,,Cache enabled,1f,Manual,,,,,,,No portal usage!?,"1. Add entity in modules/util/portal-tools-service-builder-test-service/service.xml
   1. cache-enabled: true
2. Add some columns to entity
3. Build Service
4. Compile Java
5. Assert code can be compiled successfully"
Service Builder,,Duplicate name,1g,Manual,,,,,,,,"1. Add 2 duplicate entities in modules/util/portal-tools-service-builder-test-service/service.xml with the same name
2. Build Service
3. Assert failure due to duplicate entity name[a]"
Service Builder,,Max length of entity name,1h,Manual,,,,,,,,"1. Add entity with name length over ???[b] characters
2. Build Service
3. Assert name length check"
Service Builder,,Test Group 2 - Column configurations,,,,,,,,,,
Service Builder,,String-based primary key,2a,Manual,,,,,,,"portal-impl counter uses String PK, but no persistence","1. Create a service builder sample entity
2. Add some columns to the entry
   1. Add a column with type ""String""
   2. Set ""primary"" to ""true""
3. Build Service
4. Assert service builder executes successfully
5. Compile Java
6. Assert code compiles successfully
7. Run the generated tests
8. Assert tests execute successfully"
Service Builder,,Int-based primary key,2b,Manual,,,,,,,No portal usage,"1. Create a service builder sample entity
2. Add some columns to the entry
   1. Add a column with type ""Int""
   2. Set ""primary"" to ""true""
3. Build Service
4. Assert service builder executes successfully
5. Compile Java
6. Assert code compiles successfully
7. Run the generated tests
8. Assert tests execute successfully"
Service Builder,,Compound primary keys,2c,Integration,,,,,,,"Portal Impl ""OrgGroupRole","7. Create a service builder sample entity
8. Add some columns to the entry
   1. For two of the columns, set ""primary"" to ""true""
9. Build Service
10. Assert service builder executes successfully
11. Compile Java
12. Assert code compiles successfully
13. Run generated tests
14. Assert tests execute successfully"
Service Builder,,Blob column type,2d,Integration,,,,,,,DLContent in document-library-content-service module,"1. Create a service builder sample entity
2. Add some columns to the entry
   1. For one of the columns, set the type to ""Blob"" 
3. Build Service
4. Assert service builder runs successfully
5. Compile Java
6. Assert code compiles successfully
7. Run generated tests
8. Assert tests execute successfully"
Service Builder,,Eager Blob column,2e,Integration,,,,,,,EagerBlobEntity in service builder test,"9. Create a service builder sample entity
10. Add some columns to the entry
   1. For one of the columns, set the type to ""Blob""
   2. Set “lazy” to “false” for the Blob column
11. Build Service
12. Assert service builder runs successfully
13. Compile Java
14. Assert code compiles successfully
15. Run generated tests
16. Assert tests execute successfully"
Service Builder,,Null conversions (LPS-81704),2f,Manual,,,,,,,,"1. Create a service builder sample entity
2. Add some columns to the entity (""convert-null"" as a column attribute is set to ""true"" by default)
3. Add a finder column that uses the added columns
4. Build Service
5. Assert service builder runs successfully
6. View <Entity>PersistenceImpl.java
7. Locate the finder method generated by service builder
8. Assert that the column entity is initialized with the empty string ("""") and not null"
Service Builder,,UAD (User Associated Data) Anonymize,2g,Integration,,,,,,,Used in portal modules,"1. Create a column with uad-anonymize-field-name set
2. Build Service
3. Deploy module
4. Execute anonymization
5. Assert column value replacement"
Service Builder,,UAD Non-Anonymizable,2h,Integration,,,,,,,Used in portal modules,"1. Create a column with ""uad-nonanonymizable"" set to ""true""
2. Build Service
3. Deploy module
4. Execute anonymization
5. Assert column value not replaced"
Service Builder,,Test Group 3 - Service builder configurations,,,,,,,,,,
Service Builder,,DS dependency-injector,3a,Integration,,,,,,,Used in portal modules,"1. Generate a sample service.xml
   1. Configure service-builder element to have the attribute dependency-injector set to ds
2. Build Service
3. Assert service builder runs successfully
4. Compile Java
5. Assert code compiles successfully"
Service Builder,,Spring dependency-injector,3b,Integration,,,,,,,Used by Portal-Impl,"1. Generate a sample service.xml
   1. Configure service-builder element to have the attribute dependency-injector set to spring
2. Build Service
3. Assert service builder runs successfully
4. Compile Java
5. Assert code compiles successfully"
Service Builder,,Test Group 4 - Finder configurations,,,,,,,,,,
Service Builder,,FinderPaths are private and instanced (LPS-89457),4a,Manual,,,,,,,,"1. Add a sample entity to service.xml
   1. Set local-service and remote-service to false
2. Define a few columns
3. Define a finder method for a non-primary column
4. Build service
5. View <Entity>PersistenceImpl.java
6. Search for definition of FinderPath variables
7. Assert FinderPaths are private and instanced"
Service Builder,,FinderPaths are initialized in afterPropertiesSet method (LPS-89568),4b,Manual,,,,,,,,"1. Add a sample entity to service.xml
   1. Set local-service and remote-service to false
2. Define a few columns
3. Define a finder method for a non-primary column
4. Build service
5. View <Entity>PersistenceImpl.java
6. Search for definitions of FinderPath variables
7. Assert FinderPaths are private and instanced
8. Assert FinderPath variables are initialized in the afterPropertiesSet method"
Service Builder,,Single Column,4c,Integration,,,,,,,regular portal usage,"1. Add finder to service.xml with only one finder-column
2. Build Service
3. Assert finder code generated

"
Service Builder,,Multiple Columns,4d,Integration,,,,,,,regular portal usage,"1. Execute 4d to add a single finder code
2. Add 2 more <finder-column>s to the same finder
3. Build Service
4. Assert finder code now includes second column"
Service Builder,,Return type: Entity,4e,Integration,,,,,,,regular portal usage,"1. Add finder to an entity in service.xml with return-type set to Entity Name
2. Build Service
3. Compile Java
4. Assert successful"
Service Builder,,Return type: Collection,4f,Integration,,,,,,,regular portal usage,"1. Add finder to an entity in service.xml with return-type set to ""Collection""
2. Build Service
3. Compile Java
4. Assert successful"
Service Builder,,Return type: Unique only,4g,Integration,,,,,,,regular portal usage,"1. Add finder to an entity in service.xml with: 
   1. ""unique"" attribute set to ""true""
   2. ""return-type"" attribute set to Entity Name
2. Build Service
3. Compile Java
4. Assert successful"
Service Builder,,Return type: No db-index,4h,Manual,,,,,,,,"1. Create entity with 2 columns
2. Add a finder that uses both columns
3. Build Service
4. Assert create index in generated indexes.sql
5. Delete indexes.sql[d]
6. Set finder to
   1. db-index=""false""
7. Build Service
8. Assert the index is not added to indexes.sql"
Service Builder,,Where with arrayable-operator/arrayable-pagination (LPS-89228),4i,Integration,,,,,,,portal-tools-service-builder-test-service/service.xml,"1. Add an entity that includes some columns (e.g. groupId, entryId)
2. Create a finder with attributes:
   1. where: entryId > 0
   2. finder-column arrayable-operator=""OR"" arrayable-pagination=""true"" name=""groupId""
3. Build service
4. Assert expected SQL generated in [Entity]PersistenceImpl"
Service Builder,,Where with matching substring (LPS-62084),4j,Manual,,,,,,,broken at head,"1. Add an entity that includes two columns with the same substring (e.g. name, nickname)
2. Create a finder with attributes:
   1. where: nickname is not NULL
   2. finder-column name: name
3. Build service
4. View generated _FINDER_COLUMN string in [Entity]PersistenceImpl
5. Assert expected sql query"
Service Builder,,comparator,4k,Integration,,,,,,,modules/apps/blogs/blogs-service/service.xml,"1. Add an entity that includes some columns (e.g. groupId, entryId)
2. Create a finder with finder-column attributes:
   1. comparator=""!=""
3. Build Service
4. View generated _FINDER_COLUMN string in [Entity]PersistenceImpl
5. Assert expected sql query"
Service Builder,,Rename finder column (LPS-79796),4l,Manual,,,,,,,,"1. Add an entity that includes some columns (e.g. groupId, entryId)
2. Add a new column with a finder
<column name=""columnToRename"" type=""String"" />

<finder name=""ColumnToRename"" return-type=""Sample"">
   <finder-column name=""columnToRename""/>
</finder>
        3. Build Service
4. Modify column name
<column name=""renamedColumn"" type=""String"" />

<finder name=""ColumnToRename"" return-type=""Sample"">
   <finder-column name=""renamedColumn""/>
</finder>
        5. Build Service
6. Assert index removed
   1. Removing index IX_BA4F5FD3 because column ""columnToRename"" does not exist
6. Assert column successfully renamed"
Service Builder,,Test Group 5 - Generated code,,,,,,,,,,
Service Builder,,Getter and setter methods are not duplicated between BaseModelWrapper and <Entity>Model / <Entity>Wrapper classes (LPS-88823),5a,Manual,,,,,,,,"<Entity>Model / <Entity>Wrapper classes (LPS-88823)
1. Update service.xml to use 7.2.0 Service Builder DTD
2. View an <Entity>Model class
3. Assert methods implemented defined in BaseModel interface with the @Override annotation in the <Entity>Model class
4. Build service
5. Assert that <Entity>Model class no longer defines methods duplicated from the BaseModel class
6. Assert that the <Entity>Wrapper class now extends BaseEntryWrapper class
7. Assert new BaseModelWrapperClass now contains methods removed from <Entity>Model and <Entity>Wrapper classes"
Service Builder,,Changes to indexes.sql persist,5b,Manual,,,,,,,,"1. Modify index in indexes.sql
2. Build Service
3. Assert manually created indexes are still present"
Service Builder,,Entity references in the service.xml create service references in the ServiceBaseImpl classes,5c,Integration,,,,,,,regular portal usage,"1. Create an entity with reference entity defined (with package-path)
2. Build Service
3. Assert reference entity BeanReference generated"
Service Builder,,Mapping tables between Entities generates many to many relationship,5d,Integration,,,,,,,regular portal usage,"1. Create a column with ""entity"" and ""mapping-table"" defined
2. Build Service
3. Assert many to many getter generated

"
Service Builder,,Persistence Tests,5e,Integration,,,,,,,regular portal usage,"1. Create an entity with persistence enabled[e]
2. Build Service
3. Assert Persistence tests are generated"
Service Builder,,Indexable Annotations,5f,Integration,,,,,,,regular portal usage,"1. Create service builder with DS dependency injector
2. Add an entity with local service enabled[f]
3. Build Service
4. Assert @Indexable attributes added to LocalService methods"
Service Builder,,Test Group 6 - AOP annotations,,,,,,,,,,
Service Builder,,"Ensure portal functionality with AOP refactor (see LPS-86406, LPS-90701)",6a,Manual,,,,,,,,"1. Start up portal
2. Assert portal starts up successfully with no exceptions"
Service Builder,,Ensure functionality of AOP annotations,6b,Integration,,,,,,,com.liferay.portal.aop.test.AopServiceManagerTest,"1. Start up portal
2. Ensure services with AOP annotations function properly"
Service Builder,,Test Group 7 - Persistence configuration,,,,,,,,,,
Service Builder,,fetchByPrimaryKeys method not generated for new services generated with 7.2 service builder DTD (LPS-90523),7a,Manual,,,,,,,,"1. Create a sample service builder entity
   1. Configure service.xml to use 7.2.0 service builder DTD
   2. Enable local and remote services
   3. Add some columns
   4. Add some finders
2. Generate services
3. Assert fetchByPrimaryKeys method is not present"
Service Builder,,fetchByPrimaryKeys method removed from existing services with PersistenceImpl method getBadColumnNames (LPS-90523),7b,Manual,,,,,,,,"1. Upgrade service.xml from 7.1.0 service builder DTD to 7.2.0[g]
2. Build services on a module with PersistenceImpl method getBadColumnNames (see LVEntryPersistenceImpl in modules/utils/portal-tools-service-builder-test-service)
3. Assert fetchByPrimaryKeys method is removed from the entity's persistence interface"
Service Builder,,Test Group 8 - Exceptions,,,,,,,,,,
Service Builder,,Custom Exception,8a,Integration,,,,,,,regular portal usage,"1. Create a service builder service.xml with exceptions defined
2. Build Service
3. Assert generated exception classes"
Service Builder,,Test Group 9 - Version Compatibility,,,,,,,,,,
Service Builder,,6.2 DTD,9a,Manual,,,,,,,,"1. Configure service.xml to use 6.2.0 service builder DTD
2. Run Build Service with the latest service builder code on master
3. Compile and deploy module on latest 6.2 EE release bundle
4. Assert no deployment errors"
Service Builder,,7.0 DTD,9b,Functional,,,,,,,gradle-plugins-service-builder,"1. Configure service.xml to use 7.0.0 service builder DTD
2. Run Build Service with the latest service builder code on master
3. Compile and deploy module on latest 7.0 DXP release bundle
4. Assert no deployment errors"
Service Builder,,7.1 DTD,9c,Integration,,,,,,,portal-tools-service-builder-test-service,"1. Configure service.xml to use 7.1.0 service builder DTD
2. Run Build Service with the latest service builder code on master
3. Compile and deploy module on latest 7.1 DXP release bundle
4. Assert no deployment errors"
Service Builder,,7.2 DTD,9d,Integration,,,,,,,regular portal usage,"1. Configure service.xml to use 7.2.0 service builder DTD
2. Run Build Service with the latest service builder code on master
3. Compile and deploy module on latest 7.2 DXP release bundle
4. Assert no deployment errors"
Service Builder,,Test Group 10 - Database Compatibility,,,,,,,,,,
Service Builder,,Oracle,10a,Integration,,,,,,,Running CI tests on Oracle DB,"1. Deploy modules with generated SB persistence code on Oracle DB
2. Assert no deployment errors"
Service Builder,,IBM DB2,10b,Integration,,,,,,,Running CI tests on DB2,"1. Deploy modules with generated SB persistence code on IBM DB2
2. Assert no deployment errors"
Service Builder,,Sybase,10c,Integration,,,,,,,Running CI tests on Sybase,"1. Deploy modules with generated SB persistence code on SAP DB
2. Assert no deployment errors"
Service Builder,,SQLServer,10d,Integration,,,,,,,Running CI tests on SQLServer,"1. Deploy modules with generated SB persistence code on SQL Server
2. Assert no deployment errors"
Service Builder,,Test Group 11 - Model Hints,,,,,,,,,,
Service Builder,,Required with hint collection,11a,Integration,,,,,,,Portal Impl Usage (portal-modal-hints.xml),"1. Create a model
2. Add a field with required validator and hint collection
<field name=""hostname"" type=""String"">
        <hint-collection name=""HOSTNAME"" />
        <validator name=""required"" />
</field>
        3. Build Service
4. Assert expected data type and validation"
Service Builder,,Test Group 12 - JDK 11 Support,,,,,,,,,,
Service Builder,,Generate with JDK 11,12a,Manual,,,,,,,,"1. Navigate to portal-tools-service-builder-test-service module
2. Build Service with JDK 11
3. Compile Java with JDK 11
4. Assert compiles successfully"
Service Builder,,Test Group 13 - Non-Liferay Database,,,,,,,,,,
Service Builder,,Declarative Services,13a,Manual,,,,,,,blade samples?,"1. Register a database with missing liferay tables as an OSGi service (com.liferay.portal.spring.extender.internal.jdbc.DataSourceUti)
2. Declare database source in module MANIFEST.MF
   1. Embed Data source provider SPI
3. Build Service
4. Deploy module
5. Assert successful connection to data source"
Service Builder,,"JDBC (Docs 7.1, 7.2)",13b,Integration,,,,,,,external-data-source-test-controller-test,"1. Create a database with missing liferay tables
2. Define data source with jdbc.ext (instead of jdbc.default) properties in portal-ext.properties
3. Create a ext-sprint.xml in src/main/resources/META-INF/spring/parent of a SB module (7.1 FP3+)
   1. Add a Spring Bean for the external database JDBC properties
   2. Add an alias for the bean
4. In service.xml, set for Entity: 
   1. data-source: created alias
   2. table: database table
   3. columns: db-name attribute
5. Build service
6. Deploy module
7. Assert successful connection to data source"
Service Builder,,JNDI (Sample),13c,Manual,,,,,,,,1. Execute 13b with JNDI bean
Service Builder,,Test Group 14 - Custom Finder,,,,,,,,,,
Service Builder,,Dynamic Query (Docs),14a,Integration,,,,,,,regular portal usage,"1. Create custom finder methods using Dynamic Query API in [Entity]FinderImpl class
2. Build service
3. Assert [Entity]FinderBaseImpl, and [Entity]Finder generated
4. Compile Java
5. Assert successful compile

"
Service Builder,,Custom Finder with manual SQL,14b,Integration,,,,,,,regular portal usage,1. Execute 14a with methods that use manually created sql to join tables
Service Builder,,Actionable Dynamic Queries,14c,Integration,,,,,,,regular portal usage,1. Execute 14a with Actionable Dynamic Query
Service Builder,,Test Group 15 - Build parameters (Docs),,,,,,,,,,
Service Builder,,apiDirName (Linux),15a,Manual,,,,,,,,"1. Build service with apiDirName parameter set to non-default value (with a Linux/Unix file system path)
2. Assert service API files placed in the correct directory

"
Service Builder,,apiDirName (Windows),15b,Manual,,,,,,,,"1. Build service with apiDirName parameter set to non-default value (with a Windows file system path)
2. Assert service API files placed in the correct directory"
Service Builder,,Test Group 16 - Column Order (Docs),,,,,,,,,,
Service Builder,,Ascending/Descending,16a,Integration,,,,,,,regular portal usage,"1. Create an entity with order > order-column attribute
2. Set order-by: desc
3. Build Service
4. Assert generated code to return in descending order
5. Modify order-by: asc
6. Assert generated code to return in ascending order"
Service Builder,,Case sensitive,16b,Integration,,,,,,,regular portal usage,"1. Create an entity with order > order column sorted by ""name"" and non-case-sensitive
2. Build service
3. Assert generated code to return without checking case"
Service Builder,,Test Group 17 - Service Builder update,,,,,,,,,,
Service Builder,,Core update,17a,Integration,,,,,,,service-builder-jdk8,"1. Modify core Service Builder module code
2. Build Service
3. Assert no code changes made to generated classes

"
Service Builder,,Test Group 18 - Build Change Tracking,,,,,,,,,,
Service Builder,,Enable Change Tracking,18a,Manual,,,,,,,,"1. Flag to turn on in service.xml
2. Build Service
3. Model will implement CTModel
4. (Service will fail if MVCC is not enabled)"
Setup Wizard,Setup Wizard,,,,,,,,,,,
Setup Wizard,,Test Group 1 - Initial Setup Wizard setup,,,,,,,,,,
Setup Wizard,,Enabling Setup Wizard,1a,Functional,-,3,,,,,SetupWizard#HypersonicToMySQL,"1. Set setup.wizard.enabled=true
2. Start Portal, assert the setup wizard is visible
          
3. Finish Configuration and restart
4. Assert Setup Wizard does not start again
5. Assert the following property is set:
   1. setup.wizard.enabled=false"
Setup Wizard,,Disabling Setup Wizard,1b,Functional,-,4,,,,,Most functional tests cover this,"1. Set setup.wizard.enabled=false
2. Start Portal, assert the setup wizard is not visible"
Setup Wizard,,Test Group 2 - Configuring Setup Wizard,,,,,,,,,,
Setup Wizard,,Portal Config,2a,Functional,-,5,,,,,https://issues.liferay.com/browse/LRQA-53929,"1. Change Portal Name to something other than “Liferay”
2. Change Language to something other than “English”
3. Finish Configuration
4. Verify that the Portal Name and language changes after restart
5. Verify the following properties in portal-setup-wizard.properties:
   1. company.default.locale=[new language]
   2. company.default.name=[new portal name]"
Setup Wizard,,Add Sample Data,2b,Functional,-,4,,,,,SetupWizardHSQL#HSQLtoHSQLLportal1SampleDataEnabled,"1. Verify add.sample.data=true is writtent to portal-setup-wizard.properties
2. Enable Add Sample Data for all databases
3. Verify sample data is populated after restart"
Setup Wizard,,Modify Administrator User,2c,Functional,-,4,,,,,SetupWizardHSQL#ViewConfiguredSetupWizardValue,"1. Change First Name to something other than “Test”
2. Change Last Name to something other than “Test”
3. Change Email to something other than “test@liferay.com”
4. Finish Configuration
5. Verify that the admin name and email changes after restart
6. Verify the following properties in portal-setup-wizard.properties:
   1. admin.email.from.address=[new email]
   2. admin.email.from.name=[new name]
   3. default.admin.email.address.prefix=[new email prefix]
   4. default.admin.first.name=[new first name]
   5. default.admin.last.name=[new last name]"
Setup Wizard,,Changing Database,2d,Functional,-,4,,,,,SetupWizard#HypersonicToMySQL,"1. Click “Change” under Default Database
2. Select a database under “Database Type”
3. Adjust remaining database fields as needed
4. Finish Configuration
5. Verify that the new database is pointed to after restart
6. Verify the following properties in portal-setup-wizard.properties:
   1. jdbc.default.driverClassName=[new property]
   2. jdbc.default.password=[new property]
   3. jdbc.default.url=[new property]
   4. jdbc.default.username=[new property]"
Setup Wizard,,Verify if empty string is allowed for all fields,2e,Functional,-,3,,,,,SetupWizard#HypersonicWithSpecialContent,"1. One at a time, set the following fields to blank
   1. Portal Name
   2. First Name
   3. Last Name
   4. Email
   5. JDBC Driver Class Name
   6. JDBC Default URL
2. Assert results
   1. Assert the following non-required fields allow for blank fields:
      1. Portal Name
      2. JDBC Username
      3. JDBS Password
   2. Assert the following required fields do not allow for blank fields:
      1. First Name
      2. Last Name
      3. Email
      4. JDBC Driver Class Name
      5. JDBC Default URL"
Setup Wizard,,Verify if special characters is allowed for all fields,2f,Functional,-,3,,,,,SetupWizard#HypersonicWithSpecialContent,"1. One at a time, set the following fields to !@#$%^&*()-_+=|`~{}[];:'"",<.>/?
   1. Portal Name
   2. First Name
   3. Last Name
   4. Email
2. Assert results
   1. Assert the following fields allow for special characters:
      1. Portal Name
      2. First Name
      3. Last Name
   2. Assert the following fields do not allow for special characters:
      1. Email"
Setup Wizard,,Test Group 3 - Selecting different databases,,,,,,,,,,
Setup Wizard,,Default Database Hypersonic,3a,Functional,-,3,,,,,SetupWizardHSQL#HSQLtoHSQLLportal1SampleDataDisabled,"1. Select HSQL
2. Verify restart is needed
3. Restart app server
4. Assert no errors on startup
5. Assert able to login into portal"
Setup Wizard,,MySQL,3b,Functional,-,5,,,,,SetupWizardMySQL.testcase,"1. Select MySQL
2. Verify restart is needed
3. Restart app server
4. Assert no errors on startup
5. Assert able to login into portal"
Setup Wizard,,MySQL with Sample Data,3c,Functional,-,4,,,,,SetupWizardHSQL#HSQLtoMySQLSampleDataEnabled,"1. Execute 3b but with ""Sample Data"" checkbox enabled
2. Assert Sample Data added to the portal
3. Assert portal functionality"
Setup Wizard,,MariaDB,3d,Functional,-,4,,,,,SetupWizardHSQL#HSQLtoMariaDB,"1. Select MariaDB
2. Verify restart is needed
3. Restart app server
4. Assert no errors on startup
5. Assert able to login into portal"
Setup Wizard,,MariaDB with Sample Data,3e,Functional,-,3,,,,,SetupWizardHSQL#HSQLtoMariaDBSampleDataEnabled,"1. Execute 3d but with ""Sample Data"" checkbox enabled
2. Assert Sample Data added to the portal
3. Assert portal functionality"
Setup Wizard,,PostgreSQL,3f,Functional,-,4,,,,,SetupWizardHSQL#HSQLtoPostgreSQL,"1. Select PostgreSQL
2. Verify restart is needed
3. Restart app server
4. Assert no errors on startup
5. Assert able to login into portal"
Setup Wizard,,PostgreSQL with Sample Data,3g,Functional,-,3,,,,,SetupWizardHSQL#HSQLtoPostgreSQLSampleDataEnabled,"1. Execute 3f but with ""Sample Data"" checkbox enabled
2. Assert Sample Data added to the portal
3. Assert portal functionality"
Setup Wizard,,Oracle,3h,Functional,-,5,,,,,SetupWizardHSQLEE#HSQLtoOracle,"1. Select Oracle
2. Verify restart is needed
3. Restart app server
4. Assert no errors on startup
5. Assert able to login into portal"
Setup Wizard,,Oracle with Sample Data,3i,Functional,-,3,,,,,SetupWizardHSQLEE#HSQLtoOracleSampleDataEnabled,"1. Execute 3h but with ""Sample Data"" checkbox enabled
2. Assert Sample Data added to the portal
3. Assert portal functionality"
Setup Wizard,,SQL Server,3j,Manual,,5,,,,,https://issues.liferay.com/browse/LRQA-53782,"1. Select SQL Server
2. Verify restart is needed
3. Restart app server
4. Assert no errors on startup
5. Assert able to login into portal"
Setup Wizard,,SQL Server with Sample Data,3k,Manual,,3,,,,,https://issues.liferay.com/browse/LRQA-53782,"1. Execute 3j but with ""Sample Data"" checkbox enabled
2. Assert Sample Data added to the portal
3. Assert portal functionality"
Setup Wizard,,Sybase,3l,Functional,-,4,,,,,SetupWizardHSQLEE#HSQLtoSybase,"1. Select SQL Server
2. Verify restart is needed
3. Restart app server
4. Assert no errors on startup
5. Assert able to login into portal"
Setup Wizard,,Sybase with Sample Data,3m,Functional,-,3,,,,,SetupWizardHSQLEE#HSQLtoSybaseSampleDataEnabled,"1. Execute 3l but with ""Sample Data"" checkbox enabled
2. Assert Sample Data added to the portal
3. Assert portal functionality"
Setup Wizard,,DB2,3n,Functional,-,4,,,,,SetupWizardHSQLEE#HSQLtoDB2,"1. Select DB2
2. Verify restart is needed
3. Restart app server
4. Assert no errors on startup
5. Assert able to login into portal"
Setup Wizard,,DB2 with Sample Data,3o,Functional,-,3,,,,,SetupWizardHSQLEE#HSQLtoDB2SampleDataEnabled,"1. Execute 3n but with ""Sample Data"" checkbox enabled
2. Assert Sample Data added to the portal
3. Assert portal functionality"
Upgrades,Upgrades,,,,,,,,,,,
Upgrades,,Test Group 1 - Performance/Large Database,,,,,,,,,,
Upgrades,,Upgrade large number of the most common elements from 6.1.30 (<=7.1),1a,Manual,60,3,,,,,,"1. Use a real large database.
   1. https://drive.google.com/drive/folders/1XfZTsTCsrxRV0MpVNJitbDxjzJFPxuhB[a]
2. Upgrade to latest portal (only 7.1 or earlier)
3. Assert none of verifyProcess takes hours to complete (we have removed 60% of them for 7.1). Please keep in mind the following verify processes as they have taken a long time in the past:
   1. VerifyPermission
4. Assert none of the upgradePrcess takes hour to complete.
5. Verify no errors are thrown in the upgrade process such as:
   1. OutOfMemory errors
   2. SQLSyntaxErrorException: ORA-01795: maximum number of expressions in a list is 1000
6. Verify upgraded content is intact and functional (regenerate the index prior to do this)
7. Add/update/delete basic content from each component after upgrade and make sure no errors are thrown:
   1. Create a new journal article based on an existing structure.
   2. Create a new version of a journal article based on an existing journal article.
   3. Create a new DLFileEntry in an existing Folder.
   4. Add a new page in an existing site adding a few portlets on it.
   5. Change the configuration for an existing instance of a portlet.
   6. Add a new portlet instance in an existing page."
Upgrades,,Upgrade large number of the most common elements from 6.2.10,1b,Manual,60,5,,,,,https://issues.liferay.com/browse/LRQA-50579,"1. Start 6.2.10 Latest SP on Oracle 11.2
2. Add war from https://grow.liferay.com/documents/20147/391899/create-all-the-things-6.2-portlet.war 
3. Add Create All Things portlet to a page
4. Populate all possible asset types with 500+ assets each
5. Verify upgraded content is intact and functional (regenerate the Search index prior to do this)
6. Add/update/delete basic content from each component after upgrade and make sure no errors are thrown:
   1. Create a new journal article based on an existing structure.
   2. Create a new version of a journal article based on an existing journal article.
   3. Create a new DLFileEntry in an existing Folder.
   4. Add a new page in an existing site adding a few portlets on it.
   5. Change the configuration for an existing instance of a portlet.
   6. Add a new portlet instance in an existing page."
Upgrades,,Upgrade large number of the most common elements from 7.0,1c,Manual,60,5,,,,,"https://issues.liferay.com/browse/LRQA-50579
Database dump created for LPS-91601 on 7.0 SP10 
Download Link. Use this database to Skip steps 1-4.","1. Start 7.0 DXP Latest SP on SQL Server 2017
2. Add jar from https://github.com/yasuflatland-lf/liferay-dummy-factory/tree/7.0.x
3. Navigate to Control Panel > Apps folder > Dummy Factory
4. Populate all possible asset types with 500+ assets each
5. Upgrade to new version of DXP
6. Verify upgraded content is intact and functional (regenerate the Search index prior to do this)
7. Add/update/delete basic content from each component after upgrade and make sure no errors are thrown:
   1. Create a new journal article based on an existing structure.
   2. Create a new version of a journal article based on an existing journal article.
   3. Create a new DLFileEntry in an existing Folder.
   4. Add a new page in an existing site adding a few portlets on it.
   5. Change the configuration for an existing instance of a portlet.
   6. Add a new portlet instance in an existing page."
Upgrades,,Upgrade large number of the most common elements from 7.1 ,1d,Manual,60,4,,,,,https://issues.liferay.com/browse/LRQA-50579,"1. Start 7.1 DXP Latest SP on MariaDB 10.2
2. Add jar from https://github.com/yasuflatland-lf/liferay-dummy-factory/tree/master 
3. Execute steps from 1c"
Upgrades,,Test Group 2 - Common Paths (should use more variety of objects),,,,,,,,,,
Upgrades,,Direct upgrade from latest 6.1 CE release  (<=7.1),2a,Manual,-,2,,,,,"Automation removed due to low priority
Pre-upgrade steps:Create the following assets in legacy portal- Web Content- Document & Media Document file, version, workflow status, and size- Message Boards Thread- Wiki Page- Blogs Entry- Site PageCreate roles per usersCreate a web content structurePost-upgrade steps:Search for the assets after the upgradeAdd/update/delete basic content from each component after upgrade and make sure no errors are thrown (do this in the corresponding test in group 5?)Create one web content with an old structure (will be covered by test case 5b)Activate staging (will be covered by test case 5c, 5d)Log in with a user with a role which can see specific sites and verify that he can see those sites (will be covered by test case 3b)",
Upgrades,,Direct upgrade from latest 6.1 EE release  (<=7.1),2b,Functional,-,4,,,,,"PortalSmokeUpgrade.testcase
Pre-upgrade steps:Create the following assets in legacy portal- Web Content- Document & Media Document file, version, workflow status, and size- Message Boards Thread- Wiki Page- Blogs Entry- Site PageCreate roles per usersCreate a web content structurePost-upgrade steps:Search for the assets after the upgradeAdd/update/delete basic content from each component after upgrade and make sure no errors are thrown (do this in the corresponding test in group 5?)Create one web content with an old structure (will be covered by test case 5b)Activate staging (will be covered by test case 5c, 5d)Log in with a user with a role which can see specific sites and verify that he can see those sites (will be covered by test case 3b)",
Upgrades,,Direct upgrade from latest 6.2 CE release,2c,Functional,-,2,,,,,"PortalSmokeUpgrade.testcase
Pre-upgrade steps:Create the following assets in legacy portal- Web Content- Document & Media Document file, version, workflow status, and size- Message Boards Thread- Wiki Page- Blogs Entry- Site PageCreate roles per usersCreate a web content structurePost-upgrade steps:Search for the assets after the upgradeAdd/update/delete basic content from each component after upgrade and make sure no errors are thrown (do this in the corresponding test in group 5?)Create one web content with an old structure (will be covered by test case 5b)Activate staging (will be covered by test case 5c, 5d)Log in with a user with a role which can see specific sites and verify that he can see those sites (will be covered by test case 3b)",
Upgrades,,Direct upgrade from latest 6.2 EE release,2d,Functional,-,5,,,,,"PortalSmokeUpgrade.testcase
Pre-upgrade steps:
Create the following assets in legacy portal
- Web Content
- Document & Media Document file, version, workflow status, and size
- Message Boards Thread
- Wiki Page
- Blogs Entry
- Site Page
Create roles per users
Create a web content structure
Post-upgrade steps:
Search for the assets after the upgrade
Add/update/delete basic content from each component after upgrade and make sure no errors are thrown (do this in the corresponding test in group 5?)
Create one web content with an old structure (will be covered by test case 5b)
Activate staging (will be covered by test case 5c, 5d)
Log in with a user with a role which can see specific sites and verify that he can see those sites (will be covered by test case 3b)
",
Upgrades,,Direct upgrade from latest 7.0 CE release,2e,Functional,-,3,,,,,"PortalSmokeUpgrade.testcase
Pre-upgrade steps:
Create the following assets in legacy portal
- Web Content
- Document & Media Document file, version, workflow status, and size
- Message Boards Thread
- Wiki Page
- Blogs Entry
- Site Page
Create roles per users
Create a web content structure
Post-upgrade steps:
Search for the assets after the upgrade
Add/update/delete basic content from each component after upgrade and make sure no errors are thrown (do this in the corresponding test in group 5?)
Create one web content with an old structure (will be covered by test case 5b)
Activate staging (will be covered by test case 5c, 5d)
Log in with a user with a role which can see specific sites and verify that he can see those sites (will be covered by test case 3b)
",
Upgrades,,Direct upgrade from latest 7.0 DXP release,2f,Functional,-,5,,,,,"PortalSmokeUpgrade.testcase
Pre-upgrade steps:Create the following assets in legacy portal- Web Content- Document & Media Document file, version, workflow status, and size- Message Boards Thread- Wiki Page- Blogs Entry- Site PageCreate roles per usersCreate a web content structurePost-upgrade steps:Search for the assets after the upgradeAdd/update/delete basic content from each component after upgrade and make sure no errors are thrown (do this in the corresponding test in group 5?)Create one web content with an old structure (will be covered by test case 5b)Activate staging (will be covered by test case 5c, 5d)Log in with a user with a role which can see specific sites and verify that he can see those sites (will be covered by test case 3b)",
Upgrades,,Direct upgrade from latest 7.1 CE release,2g,Functional,-,3,,,,,"PortalSmokeUpgrade.testcase
Pre-upgrade steps:
Create the following assets in legacy portal
- Web Content
- Document & Media Document file, version, workflow status, and size
- Message Boards Thread
- Wiki Page
- Blogs Entry
- Site Page
Create roles per users
Create a web content structure
Post-upgrade steps:
Search for the assets after the upgrade
Add/update/delete basic content from each component after upgrade and make sure no errors are thrown (do this in the corresponding test in group 5?)
Create one web content with an old structure (will be covered by test case 5b)
Activate staging (will be covered by test case 5c, 5d)
Log in with a user with a role which can see specific sites and verify that he can see those sites (will be covered by test case 3b)
",
Upgrades,,Direct upgrade from latest 7.1 DXP release,2h,Functional,-,5,,,,,"PortalSmokeUpgrade.testcase
Pre-upgrade steps:
Create the following assets in legacy portal
- Web Content
- Document & Media Document file, version, workflow status, and size
- Message Boards Thread
- Wiki Page
- Blogs Entry
- Site Page
Create roles per users
Create a web content structure
Post-upgrade steps:
Search for the assets after the upgrade
Add/update/delete basic content from each component after upgrade and make sure no errors are thrown (do this in the corresponding test in group 5?)
Create one web content with an old structure (will be covered by test case 5b)
Activate staging (will be covered by test case 5c, 5d)
Log in with a user with a role which can see specific sites and verify that he can see those sites (will be covered by test case 3b)
",
Upgrades,,Direct upgrade from latest 7.2 CE release,2i,Functional,-,3,,,,,"PortalSmokeUpgrade.testcase

Pre-upgrade steps:
Create the following assets in legacy portal
- Web Content
- Document & Media Document file, version, workflow status, and size
- Message Boards Thread
- Wiki Page
- Blogs Entry
- Site Page
Create roles per users
Create a web content structure
Post-upgrade steps:
Search for the assets after the upgrade
Add/update/delete basic content from each component after upgrade and make sure no errors are thrown (do this in the corresponding test in group 5?)
Create one web content with an old structure (will be covered by test case 5b)
Activate staging (will be covered by test case 5c, 5d)
Log in with a user with a role which can see specific sites and verify that he can see those sites (will be covered by test case 3b)
",
Upgrades,,Direct upgrade from latest 7.2 DXP release,2j,Functional,-,5,,,,,"PortalSmokeUpgrade.testcase
Pre-upgrade steps:
Create the following assets in legacy portal
- Web Content
- Document & Media Document file, version, workflow status, and size
- Message Boards Thread
- Wiki Page
- Blogs Entry
- Site Page
Create roles per users
Create a web content structure
Post-upgrade steps:
Search for the assets after the upgrade
Add/update/delete basic content from each component after upgrade and make sure no errors are thrown (do this in the corresponding test in group 5?)
Create one web content with an old structure (will be covered by test case 5b)
Activate staging (will be covered by test case 5c, 5d)
Log in with a user with a role which can see specific sites and verify that he can see those sites (will be covered by test case 3b)
",
Upgrades,,Test Group 3 - Permissions Persistence,,,,,,,,,,
Upgrades,,User group pages permission,3a,Manual,30,3,,,,,"https://issues.liferay.com/browse/LRQA-42909
Pre-upgrade steps:
1. Set up Liferay legacy portal 
2. Setup user groups/roles/permissions as defined in each test
Post-upgrade steps:
1. Connect Master to the same database
2. Upgrade the database with the upgrade tool
3. Start the app server
4. Perform the corresponding assertion checks per test","1. Start Liferay 6.1.30
2. Create the following regular roles:
   1. A role that allows a user to add, edit, and delete Message Board threads and categories in all sites
   2. A role that allows a user to add, edit, and delete Web Content in all sites
   3. A role that allows a user to add, edit, and delete Wiki pages in all sites
   4. A role that allows a user to add, edit, and delete Documents in all sites
   5. A role that allows a user to add, edit, and delete Blog entries in all sites
   6. A role that allows a user to manage Site memberships in all sites
3. Create three user groups
   1. One user group should be assigned the Administrator role
   2. One user group should be assigned the MB, Calendar, Wiki, Document, and Blog roles
   3. One user group should be assigned the Site membership role
4. Create at least eight users and assign two users to each user group, leaving two more users without a user group
5. Create at least two sites and make sure they both contains MB, Calendar, Wiki, Doc, and Blog assets
6. Assign one user who is not assigned a user group to each site
7. Upgrade to 7.1 and assert all permissions and roles persist [details to be added later]
8. Repeat steps 1-7 using 6.2.10.21"
Upgrades,,Roles assignment,3b,Manual,30,4,,,,,"https://issues.liferay.com/browse/LRQA-42910
Pre-upgrade steps:
1. Set up Liferay legacy portal 
2. Setup user groups/roles/permissions as defined in each test
Post-upgrade steps:
1. Connect Master to the same database
2. Upgrade the database with the upgrade tool
3. Start the app server
4. Perform the corresponding assertion checks per test","1. Start Liferay 6.1.30
2. Create the following roles:
   1. A site role that allows a user to add, edit, and delete Message Board threads and categories
   2. A site role that allows a user to add, edit, and delete Web Content
   3. A site role that allows a user to add, edit, and delete Wiki pages
   4. A site role that allows a user to add, edit, and delete Documents
   5. A site role that allows a user to add, edit, and delete Blog entries
   6. A site role that allows a user to manage Site memberships
   7. Create one regular role
   8. Create one organization role
3. Create several users and assign at least two users to each of the created site roles, one user to the created regular role plus one user to the regular admin role and one user to the organization admin role
4. Create at least two sites and make sure they both contains MB, Calendar, Wiki, Doc, and Blog assets.  Make sure at least one user with each site role is assigned to each site.
5. Upgrade to 7.1 and assert all permissions and roles persist [details to be added later]
6. Repeat steps 1-5 using 6.2.10.21[c][d]"
Upgrades,,Portlet permissions,3c,Functional,-,4,,,,,"PortletsPermissionsUpgrade.testcase
Pre-upgrade steps:
1. Set up Liferay legacy portal 
2. Setup user groups/roles/permissions as defined in each test
Post-upgrade steps:
1. Connect Master to the same database
2. Upgrade the database with the upgrade tool
3. Start the app server
4. Perform the corresponding assertion checks per test","1. Start Liferay 6.1.30
2. Create two sites with the following portlets and assets:
   1. Message Boards
   2. Web Content
   3. Wiki
   4. Documents
   5. Blogs
3. Modify each of the above portlets so that site members have additional permissions
4. Create several users and assign them to each site (no additional roles)
5. Upgrade to 7.1 and assert all permissions and roles persist [details to be added later]
6. Repeat steps 1-5 using 6.2.10.21"
Upgrades,,Test Group 4 - Site and Page Management,,,,,,,,,,
Upgrades,,"Personal, private, organization and user group sites",4a,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Site settings,4b,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Site memberships,4c,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Portlet configuration,4d,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Page configurations,4e,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Test Group 5 - Asset Persistence,,,,,,,,,,
Upgrades,,Draft articles,5a,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Structures and templates,5b,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Staged assets,5c,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Staged site pages with nested portlets,5d,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Assets display in nested portlets,5e,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Tagged and categorized assets,5f,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Deleted assets,5g,Manual,,,,,,,Delegate to other product teams,
Upgrades,,DDL record with populated web content fields,5h,Manual,,,,,,,Delegate to other product teams,
Upgrades,,DDL record with nested required fields,5i,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Creating Forms,5j,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Updating Forms,5k,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Workflow,5l,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Polls,5m,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Calendar,5n,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Message Boards,5o,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Documents and Media,5p,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Blogs,5q,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Notifications,5r,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Comments,5s,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Attachments,5t,Manual,,,,,,,Delegate to other product teams,
Upgrades,,Test Group 6 - User and System Management,,,,,,,,,,
Upgrades,,Organizations,6a,Functional,-,5,,,,,OrganizationUpgrade#AddUserandSuborganizationAfterUpgrade,"1. Assert that an organization can be added after running an upgrade
2. Add organization1 with Organization role of Organization administrator
3. Click Details and Change avatar picture
4. Click Organization Site and Add Public and Private Community Site pages
5. Add a message board thread to public site:
   1. Public Site - MB Thread Organization 1 Subject
   2. Public Site - MB Thread Organization 1 Body
6. Add a message board thread to private site:
   1. Private Site - MB Thread Organization 1 Subject
   2. Private Site - MB Thread Organization 1 Body
7. Add categorization tag: “org1”
8. Add address: org1 street, org1 city, California, 11111, US
9. Add phone number: 111-111-1111
10. Add 10 additional email addresses: org1@liferay.com, org2@liferay.com, etc.
11. Add website: https://www.liferay.com/ type: intranet
12. Add Services Monday to Friday 7:00 to 17:00, Sat 9:00 to 15:00
  

13. Add comment: “comments on Organization 1”
14. Add reminder query: “reminder query Organization 1”
15. Include steps to add User1 from testcase 6c - Users
16. Upgrade
17. Assert steps from testcase 6b
18. Assert able to delete org 1
19. Assert Parent org1 still present"
Upgrades,,Organizations (TS and 6.1.10 on MySQL),6b,Functional,-,4,,,,,OrganizationUpgrade#AddUserandSuborganizationAfterUpgrade,"1. Assert that an organization can be added after running an upgrade
2. Assert that a sub org can be added after upgrade
3. Assert a sub org can be added to an existing org after upgrade
4. Assert users can be added to orgs and suborgs, both pre[f] and post upgrade
5. Assert users are still added to orgs/suborgs post upgrade
6. Assert orgs and sub orgs can be modified
7. Assert orgs and sub orgs can be removed"
Upgrades,,Users,6c,Functional,-,5,,,,,UserUpgrade#ViewAndEditUserAfterUpgrade,"1. Add User1
2. Include details for User1
  
3. Add an avatar image
4. Assign to Organization1
5. Create a site and assign user to site
6. Assign Regular Role > Power User
7. Assign Organization Role > Organization Adminstrator for Organization 1 
8. Open personal public site and add a blog
9. Open personal private site and add at least two documents
  

   10. Go back to User > Edit > Categorization
   11. Add a tag “tag1”
   12. Click Addresses > Add address info:
  

   13. Add Phone Number: 555-555-5555
   14. Associate 10 different emails to user: test1@liferay.com, test2@liferay.com, etc.
   15. Add Website URL: https://www.google.com/ with type: Other
   16. Add Instant Messenger for Skype: OrgUser1Skype
   17. Edit Organization User 1 > Announcements  
   18. Check Email for General, News, and Test
  

   19. Click Display Settings and modify time zone to PST and Greeting with “Welcome Organization User1! This is a 6.1.30 edit!”
  

   20. Click Comments
   21. Add comment “This is a 6.1.30 comment!”
   22. Close Liferay instance
   23. Start Upgrade Process by following steps outlined here: https://github.com/liferay/liferay-qa-ee/blob/liferay-qa-docs/references/pages/upgrade-tool.markdown
   24. Assert information added is present in 7.1
   25. Assert that user is able to reset their password
   26. Edit the information for User 1 in each tab
   27. Delete the information for User 1 in each tab
   28. Delete User
   29. Edit Organization 1
   30. Delete Org 1
   31. Assert Parent Organization still present
   32. Edit Parent Org
   33. Delete Parent Org"
Upgrades,,System settings,6d,Functional,-,5,,,,,PortalConfigurationUpgrade#ViewPortalConfigurationAfterUpgrade,"Change system settings for different components
Assert that system settings did not change "
Upgrade Enhancments,Upgrade Enhancements,,,,,,,,,,,
Upgrade Enhancments,,Test Group 1 - Module Upgrade Framework,,,,,,,,,,
Upgrade Enhancments,,Revert fix packs with micro schema version changes (LPS-76926),1a,Functional,-,5,,,,,PatchingTool#RevertFixPack,"1. Start the latest release bundle (e.g. DXP 7.0 GA1)
2. Shutdown the portal, then install the latest fix pack
3. Delete the contents of osgi/state folder
4. Assert from patching tool logs that the latest fix pack was installed successfully using:
patching-tool info
5. Startup portal
6. Shutdown the portal
7. Revert the installed fix pack
                patching-tool revert
8. Delete the contents of osgi/state folder
9. Install FP40
10. Assert from patching tool logs that the fix pack was installed successfully using:
patching-tool info
  

11. Startup portal
12. Assert that rollback to an earlier fix pack succeeds without some components failing to start
13. Assert that portal can start without unsatisfied references. In Gogo shell, execute:
                ds:unsatisfied

"
Upgrade Enhancments,,Revert modules with micro schema version changes,1b,Functional,-,4,,,,,UpgradeEnhancment#RemoveModulesWithSchemaVersionChange,"1. Start up a master bundle
2. Modify a module to add an upgrade process which implements a micro change in the schema version. We will use chat service, updating the schema version to 1.0.2
3. Deploy the new version of the module.
4. Check that chat portlet works.
5. Revert to the old version of the module (1.0.1[a][b][c][d])[e][f][g]
6. Assert that rollback of the module does not cause some components to fail.
7. Assert that portal can start without unsatisfied references. In Gogo shell, execute:
                Ds:unsatisfied
8. Asset that there are no unsatisfied dependencies with release because of the schema version. In Gogo shell, execute:
   1. Dm wtf"
Upgrade Enhancments,,Changes in minor version won’t allow you to revert the module,1c,Functional,-,4,,,,,UpgradeEnhancment#RemoveModulesWithSchemaVersionChange,"1. Start up a master bundle
2. Modify a  module to add an upgrade process which implements a minor change in the schema version. We will use chat service, updating the schema version to 1.1.0 
3. Deploy the new version of the module.
4. Check that chat portlet works.
5. Revert to the old version of the module (1.0.1)
6. Assert that rollback of the module causes some components to fail to start
7. Asset that there is an unsatisfied dependency with release because of the schema version. In Gogo shell, execute:
   1. Dm wtf[h]"
Upgrade Enhancments,,Changes in major version won’t allow you to revert the module,1d,Functional,-,4,,,,,UpgradeEnhancment#RemoveModulesWithSchemaVersionChange,"1. Start up a master bundle
2. Modify a  module to add an upgrade process which implements a major change in the schema version. We will use chat service, updating the schema version to 2.0.0 
3. Deploy the new version of the module.
4. Check that chat portlet works.
5. Revert to the old version of the module (1.0.1)
6. Assert that rollback of the module causes some components to fail to start
7. Asset that there is an unsatisfied dependency with release because of the schema version. In Gogo shell, execute:
   1. Dm wtf[i]"
Upgrade Enhancments,,Revert PR changes to latest fix pack,1e,Functional,30,5,,,,,batch > revertable-changes-jdk8,"1. Start the portal with the PR code
2. Execute in gogo shell: dm wtf
3. Assert there is no unsatisfied dependency with release:
4. Shutdown portal
5. Startup the latest portal release version (e.g. 7.1SP1) with the latest fix pack and pointed to the previous database.
6. Execute in gogo shell: dm wtf
7. Asset that there is an unsatisfied dependency with release because of the schema version.
8. Assert no unsatisfied dependencies"
Upgrade Enhancments,,Test Group 2 - Core Upgrade Framework,,,,,,,,,,
Upgrade Enhancments,,Latest schema version is set in the Core after an upgrade to 7.1,2a,Manual,30,5,,,,,https://issues.liferay.com/browse/LRQA-42923,"1. Start the latest release bundle (e.g. DXP 7.0 SP7)
2. Upgrade to the latest version of portal (e.g. DXP 7.1) using the upgrade tool
1. Navigate to the tools/portal-tools-db-upgrade-client directory in the latest version of portal (e.g. DXP 7.1), and execute the following:
java -jar com.liferay.portal.tools.db.upgrade.client.jar -s
2. Assert that the upgrade process finished successfully
3. Startup the portal[j][k]
3. Browse the Liferay portal database Release_ table and check that the core’s schemaVersion field matches the latest upgrade process version (e.g., 1.1.2)
Reference: https://github.com/liferay/liferay-portal/blob/master/portal-impl/src/com/liferay/portal/upgrade/v7_1_x/PortalUpgradeProcessRegistryImpl.java"
Upgrade Enhancments,,Track that we can run the upgrade process for the Core from the latest failing point,2b,Manual,30,5,,,,,https://issues.liferay.com/browse/LRQA-42924,"1. Start 7.1 bundle
2. Shutdown
3. Verify schema version in the class[l][m]
4. Modify Release_ in database to 1.1.1 for the schema version to simulate that the [n]upgrade process failed at 1.1.2 (which implies it failed for UpgradeRepository)
        UPDATE release_ set schemaVersion = '1.1.1' where servletContextName = 'portal';
5. Execute Upgrade Client and verify the following
   1. Logging ie “upgradeRepository is completed”
   2. schema version is at latest one
6. Assert that portal starts without errors"
Upgrade Enhancments,,Core schema version does not match with the latest major and minor version,2c,Manual,30,4,,,,,https://issues.liferay.com/browse/LRQA-42929,"1. Start 7.1 bundle
2. Shutdown
3. Modify the Release_ table to set the portal schemaVersion to a lower minor version (e.g. 1.0.2)
4. Start up the portal
5. Assert that the portal does not start and assert logging in console “You must first upgrade the portal core to the required schema version 1.1.0”
6. Repeat steps above, this time modify the Release_ table to set the portal schemaVersion to a lower major version (e.g. 0.1.2)
7. Assert logging displays “You must first upgrade the portal core to the required schema version 1.1.0”"
Upgrade Enhancments,,Core schema version does not match with the latest micro version,2d,Manual,30,3,,,,,https://issues.liferay.com/browse/LRQA-42930,"1. Start 7.1 bundle
2. Shutdown
3. Modify the Release_ table to set the portal schemaVersion to a different micro version
(e.g. 1.1.0, 1.1.3)
4. Start up the portal
5. Assert that portal starts without errors"
Upgrade Enhancments,,Test Group 3 - Non supported upgrade paths in 7.1+,,,,,,,,,,
Upgrade Enhancments,,Direct upgrades from 6.0.x > 7.1  (LPS-76929),3a,Functional,-,4,,,,,UpgradeEnhancement#DirectUpgradeFromArchive6012,"1. Perform a direct upgrade from 6.0.x to 7.1 using the upgrade tool
Ex:  PortalSmokeUpgrade#ViewPortalSmokeArchive6012
2. Assert that upgrade is not supported and the following message is logged: “You must first upgrade to Liferay Portal 6100."
Upgrade Enhancments,,Direct upgrades from 6.1.x > 7.2  (LPS-88381),3b,Functional,-,4,,,,,UpgradeEnhancement#DirectUpgradeFromArchive6130,"3. Perform a direct upgrade from 6.1.x to 7.1 using the upgrade tool
4. Assert that upgrade is not supported and the following message is logged: “You must first upgrade to Liferay Portal 6200."
Upgrade Enhancments,,Indirect upgrades from 6.0.x > 7.0 > 7.1,3c,Manual,60,3,,,,,https://issues.liferay.com/browse/LRQA-42932,"1. Create a web content on a 6.0.12 bundle
2. Perform an upgrade from 6.0.12 to 7.0 GA1, then from 7.0 GA1 to master using the upgrade tool
3. Assert successful upgrades
4. Verify upgraded content is intact and functional
5. Add/update/delete new basic content after upgrade and make sure no errors are thrown
Two upgrade process, one for core and one for module. The upgrade process for core is more strict. We can restart from the latest failing point because we have an attached schema version in the release table for the module. (https://github.com/liferay/liferay-portal/blob/master/portal-impl/src/com/liferay/portal/upgrade/v7_1_x/PortalUpgradeProcessRegistryImpl.java)"
Upgrade Enhancments,,Test Group 4 - Upgrade Not Required for GA change (7.2+),,,,,,,,,,
Upgrade Enhancments,,Upgrade from GA to HEAD,4a,Functional,-,4,,,,,UpgradeEnhancement#UpgradeWithoutExecutingUpgradeToolFromArchive7210,"1. Start portal on the first GA release (e.g 7.2 GA1)
2. Login
3. Start portal with the same database on development HEAD for the same version (e.g. 7.2.x) without executing an upgrade
4. Assert portal starts without errors, upgrade not required"
Upgrade Enhancments,,Upgrade from GA to GA,4b,Functional,-,5,,,,,UpgradeEnhancement#UpgradeWithoutExecutingUpgradeToolFromArchive7211,"1. Start portal on the first GA release (e.g 7.2 GA1)
2. Login
3. Start portal with the same database on latest GA (e.g. 7.2 GA2) without executing an upgrade
4. Assert portal starts without errors, upgrade not required"
User Tracker,User Tracker,,,,,,,,,,,
User Tracker,,Test Group 1 - UserTracker Activities,,,,,,,,,,
User Tracker,,Track user simultaneous logins (See Cluster Test Plan  - Test Group 5),1a,Functional,,5,,,,,Clustering#ValidateLiveUsers,"1. Add the following properties into portal-ext.properties
1. live.users.enabled=true
2. Check to make sure “auth.simultaneous.logins”  is set to “true” by default in portal.properties
3. Start up portal instances
4. Login simultaneously into portal instances
5. Go to Control Panel > Users > Monitoring
6. Assert live users"
User Tracker,,Track user clicks in memory (See Cluster Test Plan for clustering setup),1b,Manual,,3,,,,,,"1. Check to make sure “session.tracker.memory.enabled” is set to “true” by default in portal.properties
2. Add “live.users.enabled=true” properties into portal-ext.properties
3. Start up Liferay portal instances
4. Sign in into multiple portal instances
5. Go to Control Panel > Users > Monitoring
6. View Live users
7. Assert the memory usage (User clicks)"
User Tracker,,Track user clicks in the database after a user’s session is invalidated (See Cluster Test Plan for clustering setup),1c,Manual,,3,,,,,,"1. Set “session.tracker.persistence.enabled” to true in portal-ext.properties (It is set to false by default in portal.properties.)
2. Add “live.users.enabled=true” properties into portal-ext.properties
3. Start up Liferay portal instances
4. Sign in
5. Add contents or do anything in the live Liferay portal instance
6. Logout
7. Navigate to the database and generate usage reports 
8. Assert user’s data is persistence"
User Tracker,,Convert tracked paths to friendly URLs (See Cluster Test Plan for clustering setup),1d,Manual,,3,,,,,,"1. Set “session.tracker.friendly.paths.enabled” to “true” in portal-ext.properties (It is set to false by default in portal.properties.)
2. Add “live.users.enabled=true” properties into portal-ext.properties
3. Start up Liferay portal instances
4. Sign in
5. Navigate around the portal
6. Go to Control Panel > Users > Monitoring
7. Assert tracked path is converted to friendly URL"